![](https://cdn.nlark.com/yuque/0/2023/png/406504/1703576606847-25ecf964-6da7-4bc6-ae2d-657333db4fbf.png)

模块化RAG结构脱离了传统的初级RAG框架，即索引、检索和生成，为整个过程提供了更大的多样性和灵活性。一方面，它整合了各种方法以扩展功能模块，例如在相似性检索中加入搜索模块，以及在检索器中应用微调方法。此外，特定问题的出现导致了RAG模块的重构，以及像这样的迭代方法。模块化RAG范式正成为RAG领域的主流，允许通过串行管道或跨多个模块的端到端训练方法。三种RAG范式的比较如图3所示。

## 新模块
+ **搜索模块：**与初级/高级RAG中查询与语料库之间的相似性检索不同，针对特定场景的搜索模块在过程中纳入了对（附加）语料库的直接搜索，使用由LLM生成的代码、查询语言（例如SQL、Cypher）或其他自定义工具。搜索的数据源可以包括搜索引擎、文本数据、表格数据或知识图谱。
+ **记忆模块：**利用LLM本身的记忆能力指导检索，其原理涉及寻找与当前输入最相似的记忆。Self-mem迭代地使用检索增强生成器创建一个无限的记忆池，结合“原始问题”和“双重问题”。检索增强的生成模型可以使用自己的输出来增强自身，在推理过程中使文本更接近于数据分布，使用模型自己的输出而非训练数据。
+ **额外生成模块：**在检索到的内容中，冗余和噪声是常见问题。额外生成模块不是直接从数据源检索，而是利用LLM生成所需上下文。与直接检索相比，LLM生成的内容更可能包含相关信息。
+ **任务适应模块：**专注于将RAG转变为适应各种下游任务，UPRISE自动从预构建的数据池中检索给定零样本任务输入的提示，增强跨任务和模型的通用性。PROMPTAGATOR利用LLM作为少样本查询生成器，并基于生成的数据创建特定任务的检索器。通过利用LLM的泛化能力，PROMPTAGATOR能够仅使用少量示例创建特定任务的端到端检索器。
+ **对齐模块：**查询与文本之间的对齐一直是影响RAG有效性的关键问题。在模块化RAG时代，研究人员发现在检索器中添加一个可训练的Adapter模块可以有效缓解对齐问题。PRCA利用强化学习训练一个由LLM奖励驱动的上下文适配器，位于检索器和生成器之间。它通过在带标签的自回归策略内的强化学习阶段最大化奖励来优化检索到的信息。AAR提出了一个通用插件，它从已知来源LLM中学习LM偏好，以协助未知或未共同微调的LLM。RRR设计了一个基于强化学习的模块，用于重写查询，以使查询与语料库中的文档对齐。
+ **验证模块：**在现实世界场景中，不能总是保证检索到的信息是可靠的。检索到无关数据可能导致LLM出现幻觉。因此，在检索文档后可以引入额外的验证模块，以评估检索到的文档与查询之间的相关性。这增强了RAG的鲁棒性。

## 新模式
模块化RAG的组织方式灵活，允许根据特定问题上下文在RAG过程中替换或重新配置模块。对于由检索和生成（在某些文献中称为阅读或合成）两个模块组成的初级RAG，该框架提供了适应性和丰富性。当前研究主要探索两种组织范式，涉及增加或替换模块，以及调整模块之间的组织流程。

### 添加或替换模块
添加或替换模块的策略包括维持检索-阅读的结构，同时引入附加模块以增强特定功能。RRR提出了重写-检索-阅读过程，利用LLM性能作为强化学习中重写器模块的奖励。这允许重写器调整检索查询，提高阅读器的下游任务性能。类似地，像生成-阅读这样的方法可以选择性地替换模块，其中LLM生成模块替换了检索模块。背诵-阅读将外部检索转变为从模型权重中检索，最初让LLM记住与任务相关的信息，并生成输出，用于处理知识密集型自然语言处理任务。

### 调整模块间流程
在调整模块间流程的领域中，强调增强语言模型与检索模型之间的互动。DSP引入了示范-搜索-预测框架，将上下文学习系统视为一个显式程序而不是终端任务提示，以解决知识密集型任务。ITER-RETGEN利用生成的内容指导检索，迭代执行“检索增强生成”和“生成增强检索”，在检索-阅读-检索-阅读的流程中。Self-RAG遵循决策-检索-反思-阅读过程，引入了一个主动判断的模块。这种自适应和多样化的方法允许在模块化RAG框架内动态组织模块。

