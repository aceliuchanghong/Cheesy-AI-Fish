在 RAG（检索式增强生成）的背景下，“R”代表检索，其在 RAG 流程中的作用是从庞大的知识库中检索出前 k 个相关文档。然而，打造一个高质量的检索器并非易事。在本章中，我们围绕三个关键问题组织讨论：1) 如何获取准确的语义表示？2) 如何匹配查询和文档的语义空间？3) 如何使检索器的输出与大型语言模型的偏好相匹配？

## 如何获取准确的语义表示？
在 RAG 中，语义空间是查询和文档被映射的多维空间。进行检索时，它是在语义空间内进行度量的。如果语义表达不准确，那么它对 RAG 的影响是致命的。本节将介绍两种帮助我们构建准确语义空间的方法。

### 块优化
在处理外部文档时，第一步是进行分块，以获得细粒度特征。然后将这些块进行嵌入。然而，嵌入过大或过小的文本块可能无法取得良好效果。因此，寻找语料库中文档的最佳块大小至关重要，以确保搜索结果的准确性和相关性。

选择分块策略时，需要考虑的重要因素包括：被索引内容的特性、所使用的嵌入模型及其最佳块大小、用户查询的预期长度和复杂性，以及在特定应用中如何使用检索结果。

例如，对于较长或较短的内容，应选择不同的分块模型。此外，不同的嵌入模型在不同块大小下的表现也不同；例如，句子转换器更适合单个句子，而文本嵌入-ada-002 更适合包含 256 或 512 个标记的块。此外，用户输入问题文本的长度和复杂性，以及应用程序的特定需求（如语义搜索或问答）都将影响分块策略的选择。这可能直接与所选 LLM 的标记限制相关，并可能需要您调整块大小。

事实上，通过灵活应用多种分块策略，才能实现准确的查询结果；没有最好的，只有最合适的。

当前在 RAG 中的研究采用了多种块优化方法，以提高检索效率和准确性。

1. 诸如滑动窗口技术之类的技术通过多次检索聚合全局相关信息，实现分层检索。
2. Small2big 技术在搜索过程中使用小文本块，并向语言模型提供更大的相关文本块进行处理。
3. 摘要嵌入技术对文档摘要执行 Top K 检索，提供完整的文档上下文。
4. 元数据过滤技术利用文档元数据进行过滤。
5. 图索引技术将实体和关系转化为节点和连接，显著提高了多跳问题情境下的相关性。

这些方法的融合导致了检索结果的改善和 RAG 性能的提升。

### 微调嵌入模型
在确定了块的适当大小后，我们需要通过嵌入模型在语义空间中嵌入这些块和查询，因此嵌入是否能有效代表语料库至关重要。如今，出现了许多优秀的嵌入模型，比如UAE、Voyage、BGE，它们已经在大规模语料库上进行了预训练，但在应用于特定领域时，它们可能无法准确代表特定领域语料库的信息。此外，针对特定任务的嵌入模型微调对于确保模型理解用户查询与内容相关性至关重要，而未经微调的模型可能无法满足特定任务的需求。因此，对嵌入模型进行微调对于下游应用来说是必不可少的。

嵌入模型微调方法有两个基本范式：

1. 领域知识微调：为了使嵌入模型正确理解领域特定信息，我们需要构建领域特定数据集来微调嵌入模型。然而，微调嵌入模型与普通语言模型不同，主要在于使用的数据集不同。在当前微调嵌入模型的主要方法中，使用的数据集包括三个部分：查询、语料库和相关文档。嵌入模型根据查询在语料库中查找相关文档，然后使用查询的相关文档是否命中作为模型的评估指标。

在数据集构建、模型微调和评估过程中，这三个组成部分的每一个都可能出现许多挑战。在 LlamaIndex中，专门为嵌入模型的微调过程引入了一系列关键类和函数，显著简化了这一程序。通过准备领域知识的语料库并利用它提供的方法，我们可以轻松获得针对期望领域量身定制的专业嵌入模型。

2. 下游任务的微调：使嵌入模型适应下游任务同样重要。在下游任务中使用 RAG 时，一些工作通过利用 LLM 的能力对嵌入模型进行了微调。PROMPTAGATOR利用大型语言模型（LLM）作为少量样本查询生成器，并基于生成的数据创建特定任务的检索器，缓解了一些领域由于数据稀缺而难以进行监督微调的问题。LLM-Embedder使用大型语言模型为来自多个下游任务的数据输出奖励值，通过对数据集进行硬标记和从 LLM 得到的软奖励，用两种不同的监督信号对检索器进行微调。

这在一定程度上通过领域知识注入和下游任务微调改善了语义表示。然而，这种方法训练的检索器对大型语言模型来说并不直观有用，因此一些工作已经通过从 LLM 获得的反馈信号直接对嵌入模型进行监督微调。

## 如何匹配查询和文档的语义空间
在 RAG 应用中，一些检索器使用相同的嵌入模型来编码查询和文档，而另一些则使用两个模型分别编码查询和文档。此外，用户的原始查询可能存在表达不佳和缺乏语义信息的问题。因此，使用户查询和文档的语义空间对齐非常必要。本节介绍了实现这一目标的两个关键技术。

### 查询重写
使查询和文档的语义对齐最直观的方法是重写查询。如 Query2Doc和 ITERRETGEN所述，利用大型语言模型的内在能力，通过引导生成一个伪文档，然后将原始查询与这个伪文档合并形成一个新的查询。在 HyDE中，通过使用文本指标建立查询向量，使用这些指标生成一个相关但可能并不存在的“假设”文档，它只需要捕捉相关模式。RRR引入了一种新框架，它颠倒了检索和阅读的顺序，专注于查询重写。这种方法使用大型语言模型生成查询，然后使用网络搜索引擎检索上下文，最后使用小型语言模型作为训练重写器服务于冻结的大型语言模型。STEP-BACKPROMPTING方法可以使大型语言模型进行抽象推理，提取高级概念和原则，并基于此进行检索。最后，多查询检索方法涉及使用大型语言模型生成多个搜索查询，这些查询可以并行执行，检索结果一起输入，这对于依赖多个子问题的单个问题非常有用。

### 嵌入转换
如果有像重写查询这样的粗粒度方法，那么也应该有更细粒度的、专门针对嵌入操作的实现。在 LlamaIndex中，可以在查询编码器后连接一个适配器，并微调适配器以优化查询嵌入的表示，将其映射到更适合特定任务的潜在空间。当查询和外部文档的数据结构不同时，例如非结构化查询和结构化外部文档，使查询与文档对齐非常重要。SANTA提出了两种预训练方法，使检索器意识到结构化信息：1) 使用结构化数据和非结构化数据之间的自然对齐关系进行对比学习进行结构化意识预训练。2) 遮蔽实体预测，设计以实体为中心的遮蔽策略，并要求语言模型填写遮蔽的实体。

## 如何使检索器的输出与大型语言模型的偏好对齐
在 RAG 流程中，即使我们采用上述技术来提高检索命中率，最终效果也可能不会提升，因为检索到的文档可能不是大型语言模型（LLM）所需的。因此，本节介绍了两种方法来使检索器的输出与大型语言模型的偏好对齐。

#### LLM 监督训练
许多工作利用来自大型语言模型的各种反馈信号来微调嵌入模型。AAR通过一个编码器-解码器架构的语言模型为预训练的检索器提供监督信号。通过确定语言模型偏好的文档，通过 FiD 交叉注意力得分，然后对检索器进行微调，使用困难负采样和标准交叉熵损失。

最终，微调后的检索器可以直接用于增强未见目标语言模型，在目标任务中表现更好。在最后，有人提出大型语言模型可能更偏好关注可读性而非信息丰富的文档。

REPLUG使用检索器和大型语言模型计算检索到的文档的概率分布，然后通过计算 KL 散度进行监督训练。这种简单有效的训练方法通过使用语言模型作为监督信号来增强检索模型的性能，无需任何额外操作。

UPRISE同样使用冻结的大型语言模型来微调 Prompt Retriever。但语言模型和检索器都将 Prompt-Input 对作为输入，然后使用大型语言模型给出的分数来监督检索器的训练，相当于使用大型语言模型来标记数据集。

Atlas提出了四种微调受监督嵌入模型的方法，其中，注意力蒸馏使用语言模型在输出过程中生成的交叉注意力得分进行蒸馏。EMDR2 使用期望最大化算法进行训练，将检索到的文档作为潜在变量。困惑度蒸馏直接使用模型生成的 token 的困惑度作为指标进行训练。

LOOP 引入了一种基于文档删除对语言模型预测的影响的新损失函数，为更好地适应特定任务提供了有效的训练策略。

#### 插入适配器
然而，由于使用 API 实现嵌入功能或本地计算资源不足等因素，微调嵌入模型可能具有挑战性。因此，一些工作选择外部附加适配器以进行对齐。

PRCA通过上下文提取阶段和奖励驱动阶段训练适配器，并基于基于 token 的自回归策略优化检索器的输出。TokenFiltering方法计算交叉注意力得分，选择得分最高的输入 token 以有效过滤 token。RECOMP 提出了提取式和生成式压缩器，通过选择相关句子或综合文档信息生成摘要，以实现多文档查询焦点摘要。此外，一种新颖的方法 PKG，通过指令式微调将知识注入白盒模型，并直接替换检索器模块，用于基于查询直接输出相关文档。



