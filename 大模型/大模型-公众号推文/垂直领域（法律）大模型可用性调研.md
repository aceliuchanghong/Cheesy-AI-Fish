以阅读理解任务为切入点，进行大模型和传统模型效果的比对。

## 相关概述
> 任务形式：给定一段案情描述，提出几个相关问题，根据案情描述作答。问题形式包括：
>
> + 片段抽取问题（81%）：从案情中直接抽取部分片段作答
>     - <font style="color:#067d17;background-color:#ffffff;">刘×3什么时候出生？  ->    2002年9月24日</font>
> + YES/NO问题（12%）：根据案情描述对问题做出肯定/否定回答，只能是YES/NO
>     - <font style="color:#067d17;background-color:#ffffff;">彭0是否需要支付抚养费？  ->   YES</font>
> + UNK问题（7%）：提出的问题根据案情描述无法做出答复，答案为空
>     - <font style="color:#067d17;background-color:#ffffff;">原、被告因何离婚？</font>
>

### 传统 vs LLMs
传统解决思路，一般为Encoder-Decoder框架，将问题和上下文一并输入模型，输出以下几个logits

    1. 是否为UNK问题：二分类，决定该问题是否能够作答，超过阈值则为UNK问题
    2. 是否YES/NO问题：二分类，决定该问题是否YES/NO问题
    3. 片段抽取问题：指针网络，输出概率最大的Top2索引位置当做起止点

> 实际实现过程，通常将UNK和YES/NO问题以及抽取问题看做四分类问题，根据该标签决定是否对起止点索引进行分析和输出。
>

![](https://cdn.nlark.com/yuque/0/2023/png/406504/1684910396297-ea733791-389a-4448-96cd-7efe137809f8.png)

在利用通用开源大模型（LLMs）解决阅读理解任务时，只需要根据任务书写合适的Prompt即可，进一步提升大模型在任务上的效果时，可以通过各类微调方法提升其效果。

![](https://cdn.nlark.com/yuque/0/2023/png/406504/1684985856603-473a35f3-7269-41f8-b030-ed57be12acd0.png)

### 任务
以2019 CAIL 阅读理解任务数据集为例，分析传统方法和大模型的差异性。其中传统方法和大模型的选择如下：

1. 【Bert】2019 CAIL 比赛[Top3的方案](https://github.com/NoneWait/cail2019)（备注：冠亚军方案暂未找到开源实现）【简称：T3】
2. 【Bert】解决阅读理解的[通用方法](https://github.com/circlePi/2019Cail-A-Bert-Joint-Baseline-for-Machine-Comprehension/tree/master/2019Cail%20mrc)【简称：COM】
3. 【Albert】20年上海交通大学Encoder-Decoder框架阅读理解[模型](https://www.researchgate.net/publication/341369190_Machine_Reading_Comprehension_The_Role_of_Contextualized_Language_Models_and_Beyond)【简称：SJ】
4. [ChatGLM-base](https://github.com/THUDM/ChatGLM-6B/tree/main)：清华开源ChatGLM模型【简称：GLM_BASE】
5. 【ChatGLM】[LAW-GPT](https://github.com/LiuHC0428/LAW-GPT)：基于ChatGLM模型在通用法律对话数据上利用Lora方式微调得到模型【简称：GLM_LAW】
6. 【LLaMA】[LawGPT](https://github.com/pengxiao-song/LaWGPT)：基于LLaMA模型在法律问答数据上利用Lora方式微调得到模型【简称：LLA_LAW】

针对上述任务，采用的评估指标是：

+ F1：(2 * precision * recall) / (precision + recall)
    - precision = 预测答案&真实答案的相同子集个数 / 预测答案长度
    - recall = 预测答案&真实答案的相同子集个数 / 真实答案长度

采用的数据集分别如下：

![](https://cdn.nlark.com/yuque/0/2023/png/406504/1684982217232-0877b5b2-913b-4ad4-b6f4-be4ff888b74e.png)

+ 训练数据：[big_train_data.json](https://github.com/china-ai-law-challenge/CAIL2019/tree/master/%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3/data)
+ 测试数据(同一任务不同数据)：[2019_cail_test_ground_truth.json](https://github.com/china-ai-law-challenge/CAIL2019/tree/master/%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3/data)、[2020_cail_train.json](https://github.com/china-ai-law-challenge/CAIL2020/blob/master/ydlj/data/train.json)

## 任务实验
### 标准阅读理解
利用2019 CAIL 阅读理解数据集，分别进行模型训练，训练设置如下：

    1. T3模型将数据集进行切分<font style="color:rgb(31, 35, 40);"> </font>[**BERT-wwm-ext**](https://github.com/ymcui/Chinese-BERT-wwm)，进行八折交叉验证，每一折上训练一个模型，epoch=5，最终结果通过投票方式决定，参数和阈值为默认值。（比赛记录F1分数81.595；离线训练F1分数80.4）
    2. COM方法参数为默认值，模型采用[bert-base-Chinese](https://huggingface.co/bert-base-chinese)，未进行参数调优，epoch=6。
    3. SJ模型为针对应英文 SQuAD1/2 数据集设计的阅读理解框架，训练采用[bert-base-chinese](https://huggingface.co/bert-base-chinese)，参数默认，epoch=5
    4. GLM_BASE：清华ChatGLM模型，使用Prompt直接生成预测结果
    5. GLM_LAW：法律领域对话语料进行Lora微调后的ChatGLM模型，使用Prompt直接生成结果
    6. LLA_LAW：法律领域对话数据基于Chinese-LLAMA进行微调后生成的模型，使用Prompt生成结果

> 1. Prompt模板为：
>     1. <font style="color:#067d17;background-color:#ffffff;">阅读理解，仔细阅读给定的文本和问题，按照如下步骤思考，但答案中不要输出思考的过程。</font><font style="color:#0037a6;background-color:#ffffff;">\n</font><font style="color:#067d17;background-color:#ffffff;">1. 第一步，思考给出的问题是否能够根据给定的文本进行作答。如果不能作答，则直接输出"NONE"，并结束思考步骤，能够作答情况下，思考下一步</font><font style="color:#0037a6;background-color:#ffffff;">\n</font><font style="color:#067d17;background-color:#ffffff;">2. 第二步，如果给定的问题是判断题，那么根据给定的文本对问题进行回答，输出格式只能为"YES"和"NO"。如果不是判断题，思考下一步</font><font style="color:#0037a6;background-color:#ffffff;">\n</font><font style="color:#067d17;background-color:#ffffff;">3. 第三部，抽取给定文本的合适片段，作为问题的答案，输出格式为已有内容的子串。结束思考过程。</font><font style="color:#0037a6;background-color:#ffffff;">\n</font><font style="color:#067d17;background-color:#ffffff;">```{description}```</font><font style="color:#0037a6;background-color:#ffffff;">\n</font><font style="color:#067d17;background-color:#ffffff;">问题：{question}</font><font style="color:#0037a6;background-color:#ffffff;">\n</font>
> 2. GLM_BASE、GLM_LAW、LLA_LAW模型未进行进一步特定任务的微调，直接生成结果是过长的字符串，添加了对结果的后置处理逻辑
>     1. ![](https://cdn.nlark.com/yuque/0/2023/png/406504/1685325253049-9a699283-0ead-4772-b15c-a9245a98792b.png)
>     2. 处理逻辑包括：所有原文的最长子串查找、通过规则判定问题类型（时间、金额、是否、原因等），根据规则对生成结果进行截取或替换
>

|  | **T3** | **COM** | **SJ** | **GLM_BASE** | **GLM_LAW** | **LLA_LAW** |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| F1 | 80.4 | 74.1 | 71.1 | 82.9 | 79.8 | 58.0 |


通过上述的结果可以看出：

+ 传统方法在解决抽取式阅读理解过程中，是输出句子中起止点索引，所以保证了截取的句子一定是原文；大模型是生成式的，生成内容可能包含原文含义，但在标点、括号、文字上可能存在差异（如上截图中中英文括号问题）。自由问答和选择题（分类）场景下，大模型能够发挥更好的效果，对于完形填空或抽取式场景下，可能会存在一定的影响。
+ T3相比COM和SJ效果较好，一方面是集成学习的方式，另一方面是针对数据集进行挖掘分析后，整体方案进行了优化；
+ GLM_LAW相比GLM_BASE进行了Lora微调，但微调的数据集是法律领域对话数据集，和当前任务数据格式存在一定差异，使其在法律领域的对话问答等自由生成场景下效果有提升。

![GLM_LAW](https://cdn.nlark.com/yuque/0/2023/png/406504/1685327408374-c9a36c98-6db3-4f23-9b83-759cefd681a2.png)

![GLM_BASE](https://cdn.nlark.com/yuque/0/2023/png/406504/1685327420785-f2be44f0-ce32-4478-a370-a7c9dbf5993d.png)

法律场景下，大模型针对对话问答等自由生成任务更加适配，对于抽取式任务，可能会由于生成不完全一致的内容。

### Prompt对模型效果影响
大模型的效果对于Prompt是敏感的，不同的Prompt产生的效果是不同的，针对上述的任务，假定我们已知问题的类型，分别设计不同的Prompt如下，而非对所有问题使用上述同一个Prompt：

> 1. <font style="color:#067d17;background-color:#ffffff;">判断题，根据给定的描述内容，对问题进行判断，如果问题正确则输出YES，如果问题错误则输出NO，答案格式为"YES"或"NO"。  
</font><font style="color:#067d17;background-color:#ffffff;">```{description}```  
</font><font style="color:#067d17;background-color:#ffffff;">问题：{question}</font>
> 2. <font style="color:#067d17;background-color:#ffffff;">判断题，根据给定的内容描述，对问题进行判断，如果问题能够根据上下文做出回答，则输出HAVE；如果不能根据上下文得到问题的答案，则输出NONE。  
</font><font style="color:#067d17;background-color:#ffffff;">答案格式为"HAVE" 或 "NONE"  
</font><font style="color:#067d17;background-color:#ffffff;">```{description}```  
</font><font style="color:#067d17;background-color:#ffffff;">问题：{question}</font>
> 3. <font style="color:#067d17;background-color:#ffffff;">阅读理解。根据给定的内容，抽取合适的片段，作为问题的答案。除了找到的片段外，不要有额外的输出内容。  
</font><font style="color:#067d17;background-color:#ffffff;">```{description}```  
</font><font style="color:#067d17;background-color:#ffffff;">问题：{question}</font>
>

上述的Prompt引入了问题类型的先验知识，无需模型去判断该问题的类型。保持其他不变的情况下，GLM_BASE和GLM_LAW的模型效果如下：

| **** | **GLM_BASE** | **GLM_LAW** |
| :---: | :---: | :---: |
| 所有问题同一个Prompt | 82.9 | 79.8 |
| 不同的问题设计不同的Prompt | 83.1 | 83.8 |


仅改变模型输入Prompt的情况下，GLM_BASE效果提升有限，但GLM_LAW模型效果提升明显，由统一的Prompt拆分为具体任务下分别的Prompt，是对任务的一个简化。一方面说明将任务进行简单化对于模型的效果是有提升的；另一方面通过利用对话领域数据进行Lora微调后，GLM_LAW对于简单法律领域简单任务的理解能力高于GLM_BASE。

### 模型的可迁移性
为了比较传统模型和大模型的可迁移性，利用上述的T3、GLM_BASE和GLM_LAW模型，对2020 CAIL 阅读理解数据集进行预测。

2020 CAIL 阅读理解数据和2019 CAIL 阅读理解数据任务形式是一致的，即：YES/NO、UNK和SPAN抽取问答三种类型，但数据来源、分布均存在差异。

> Prompt对所有问题采用同一个
>

| **** | **T3** | **GLM_BASE** | **GLM_LAW** |
| :---: | :---: | :---: | :---: |
| 2019 CAIL 阅读理解数据 | 80.4 | 82.9 | 79.8 |
| 2020 CAIL 阅读理解数据 | 64.1 | 79.4 | 78.3 |


三个模型在新的数据集上效果如上表

+ T3模型效果下降最为明显，T3模型针对特定的数据集进行优化设计；GLM_BASE和GLM_LAW模型效果略有下降，但相比T3下降不明显；
+ 大模型在解决同一类问题上，对数据的依赖程度低于传统模型，换句话说，大模型的Few-shot和Zero-shot能力要强于传统模型。

## 调研总结
法律阅读理解任务上，通过对比传统模型（T3、COMM、SJ）和大模型（GLM_BASE、GLM_LAW）的效果，有如下的结论：

+ 生成式任务：大模型相比传统模型，在任务类型上更擅长生成式任务，例如对话问答。
+ 简化任务：Prompt能够直接影响模型的效果，通过将任务进行拆分简化的情况下，模型的效果可以得到提升
+ 可迁移性：大模型通过前期的通用语料学习，具备较强的Few-shot和Zero-shot能力，针对新的任务数据同样具备较好的结果。



从模型的建模流程上看：

1. 为了得到较好的效果，需要做非常多数据处理、特征工程、模型集成等工作
2. 单一任务形式，模型无法在不同任务，甚至同一任务不同数据集上保持效果；大模型通过不同的Prompt形式自由的切换不同的任务或数据集
3. 传统模型是通过特征工程等要求用户向模型对齐的；相对而言，大模型是通过自然语言对齐用户的
4. 对输出格式具有严格要求的任务场景（抽取式任务）下，大模型由于是生成式模型，可能由于标点、空格、括号等无法和原文保持一致。

## 调研工作记录
- [x] CAIL2019相似案例匹配任务的调研，包括数据、格式、获取等
- [x] 调研学习CAIL2019比赛前三开源实现
- [x] 基于baseline开源大模型（ChatGPT、ChatGLM）调研探索
    - [x] 暂无较好方法突破长文本限制，大模型效果不佳
    - [x] 传统模型通过多头输入方式缓解长文本问题
- [x] 对CAIL2019阅读理解任务的调研，包括数据格式、量级、获取、处理
- [x] CAIL2019比赛头部开源实现模型寻找、代码阅读
- [x] 调研已有开源法律大模型LAW-GPT、LaWGPT
- [x] 法律相关数据统一处理，便于后续模型训练、验证和评估
- [x] 阅读理解模型进行训练
- [x] 利用已有大模型调研，对法律数据推理输出结果
- [x] 利用训练完毕的传统模型，对法律数据进行推理，并对结果进行统一评估分析
- [x] 梳理大模型在法律领域调研方案

## 参考文献
+ LaWGPT：[https://github.com/pengxiao-song/LaWGPT](https://github.com/pengxiao-song/LaWGPT)
+ LAW-GPT：[https://github.com/LiuHC0428/LAW-GPT](https://github.com/LiuHC0428/LAW-GPT)
+ LAW-AI：[https://github.com/lvwzhen/law-cn-ai](https://github.com/lvwzhen/law-cn-ai)
+ Top3 2019 阅读理解方案：[https://github.com/NoneWait/cail2019](https://github.com/NoneWait/cail2019)
+ <font style="color:rgb(17, 17, 17);">Machine Reading Comprehension: The Role of Contextualized Language Models and Beyond</font>

  


