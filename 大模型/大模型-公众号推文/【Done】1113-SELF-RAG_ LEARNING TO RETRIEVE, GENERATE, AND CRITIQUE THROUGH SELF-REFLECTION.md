### 论文概述
这篇论文介绍了一种新的框架——Self-Reflective Retrieval-Augmented Generation（SELF-RAG），它通过检索和自我反思提高语言模型的质量和事实性。SELF-RAG训练一个任意的语言模型，在推理阶段使用特殊的“反思”标记来生成和反思检索到的段落以及自己的生成结果。实验表明，SELF-RAG在多种任务上显著优于最先进的语言模型和检索增强模型，特别是在开放领域的问答、推理和事实验证任务中表现出色，并且相对于这些模型，SELF-RAG在改善事实性和引用准确性方面有显著提升。

![](https://cdn.nlark.com/yuque/0/2023/png/406504/1699873797605-d83f3c2d-e586-4dea-a074-fd9991c9d808.png)

### 方法描述
该论文提出了一种名为SELF-RAG的文本生成模型，它能够通过使用反射令牌来评估自己的输出，并在推理过程中实现自适应控制。SELF-RAG包含两个主要组件：批评者（critic）和生成器（generator）。批评者用于评估每个生成段落的质量，并根据需要决定是否需要检索外部文档以增强生成。生成器负责生成文本并使用反射令牌来调整其行为以满足不同的任务需求。

在训练阶段，该模型使用监督学习数据收集技术来训练批评者和生成器。对于批评者，他们使用prompt GPT-4生成反射令牌，并将其与人类评价进行比较，从而创建了监督学习数据集。对于生成器，他们使用已经生成的输出以及批评者的预测结果来创建更精确的训练数据集。

在推理阶段，SELF-RAG会动态地决定何时需要检索文档，并且可以设置阈值来进行硬性控制。当需要检索时，模型会在多个段落中进行并行处理，并使用反射令牌来强制执行软约束或硬控制。例如，在某些情况下，模型可能会选择完全支持它的信息的段落而不是部分支持的信息。

SELF-RAG是一种基于反射令牌的文本生成模型，它可以自动评估自己的输出并在推理过程中实现自适应控制。这种方法可以帮助模型更好地满足不同任务的需求，并提高生成质量。

![](https://cdn.nlark.com/yuque/0/2023/png/406504/1699873822200-71e29d11-7ee5-4497-b8b9-6c0a8b45edfa.png)

![](https://cdn.nlark.com/yuque/0/2023/png/406504/1699873822200-884c8ef9-f588-448d-b5d9-6c88b6d3b14b.png)

### 论文实验
本文主要介绍了研究人员在多个下游任务上对SELF-RAG框架的实验结果，并与多种基线进行了比较。实验涉及了关闭集任务和开放域生成任务，并使用了多个评价指标来衡量模型的性能。

在关闭集任务方面，研究人员使用了两个数据集：一个关于公共卫生的事实验证数据集（PubHealth）和一个多选题推理数据集（ARC-Challenge）。他们使用准确率作为评价指标，在测试集上进行了评估。在开放域生成任务方面，研究人员使用了两个问答数据集：PopQA和TriviaQA-unfiltered，以及一个生成任务数据集（Bio generations）和一个长篇问答任务数据集（ASQA）。他们使用FactScore、正确率、流畅度和引用精度等指标来评估模型的性能。

对于自我反思和强化学习方法，研究人员将它们与其他无检索的预训练语言模型（如LLama27B和Alpaca）以及具有检索功能的方法（如RAG和SAIL）进行了比较。他们在所有任务中都观察到了SELF-RAG的优势，包括在PopQA、PubHealth、ASQA和Bio generations任务中的显著改进。此外，研究人员还分析了不同参数设置的影响，包括自适应阈值、权重调整和数据规模等因素。

总的来说，该研究证明了SELF-RAG框架的有效性，并提供了有关如何优化其性能的见解。

![](https://cdn.nlark.com/yuque/0/2023/png/406504/1699873843174-60363eaf-1228-48f9-bcce-3046906f4a31.png)

### 文章优点
+ 该论文提出了一种新的框架——Self-Reflective Retrieval-augmented Generation（SELF-RAG），通过需求检索和自我反思来提高预训练模型的质量和事实准确性。
+ SELF-RAG可以灵活地调整检索频率以满足不同下游应用的需求，并可以根据用户偏好定制模型的行为。
+ 在六个任务上的实验结果表明，SELF-RAG在性能和事实准确性方面显著优于具有更多参数或使用传统检索增强生成方法的预训练模型。

### 文章不足
+ 虽然SELF-RAG能够显著提高模型的事实准确性和性能，但它仍然可能生成不完全支持引用的输出。因此，作者希望明确的自我反思和细粒度的归因可以帮助用户验证模型输出中的事实错误。

### 方法创新点
+ SELF-RAG引入了反思令牌，用于指示是否需要检索以及其生成质量。
+ SELF-RAG还提供了每个段落的引文，并对其输出是否得到支持进行了自评，从而更容易进行事实验证。
+ SELF-RAG训练了一个任意的生成器LM，使其能够生成文本并预测扩展模型词汇表中的下一个标记，包括反思令牌和检索到的段落。

### 未来展望
+ 在将来的研究中，作者计划进一步探索如何利用反射令牌实现更高级别的控制和指导，例如对生成过程的特定部分进行强制约束。
+ 此外，作者还将研究如何更好地集成SELF-RAG与其他自然语言处理技术，如对话系统和知识图谱等，以提高其在实际应用场景中的效果。

