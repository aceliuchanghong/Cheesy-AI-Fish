> **<font style="color:rgb(0, 0, 0);">链接：</font>**[<font style="color:rgb(0, 0, 0);">https://arxiv.org/pdf/2404.03302.pdf</font>](https://arxiv.org/pdf/2404.03302.pdf)
>
> **<font style="color:rgb(0, 0, 0);">标题：</font>**<font style="color:rgb(0, 0, 0);">How Easily do Irrelevant Inputs Skew the Responses of Large Language Models?</font>
>
> **<font style="color:rgb(0, 0, 0);">概述：</font>**<font style="color:rgb(0, 0, 0);">这篇论文探讨了大型语言模型（LLMs）在处理外部知识库信息时存在的问题。作者构建了一个框架来构造高质量的无关信息，并进行了详细的分析和实验。结果表明，当前的LLMs仍然难以区分高度相关的相关信息，并容易被这些无关但误导性的内容所干扰。此外，目前解决无关信息问题的方案也存在局限性，不能有效提高LLMs对干扰的鲁棒性。该研究对于改进LLMs的性能具有一定的指导意义。</font>
>

在人工智能领域，大型语言模型（Large Language Models，LLMs）因其强大的知识处理能力和广泛的应用场景而备受关注。然而，这些模型在处理信息时，往往会受到无关信息的干扰，导致输出结果的准确性和可靠性受到影响。本文将深入探讨一篇关于LLMs对无关信息鲁棒性的研究论文，分析其动机、方法、实验和创新点，并指出其存在的不足。

![](https://cdn.nlark.com/yuque/0/2024/png/406504/1712625392387-6ab295a1-1f8f-4b55-a077-7d17af4b691f.png)

大型语言模型在完成各种知识密集型任务时表现出色，但其有效性受到参数记忆限制的影响，有时会输出不准确或幻觉性的回答。为了解决这一问题，研究者们尝试通过外部知识库的信息检索来增强LLMs的能力。然而，现有的检索系统并不完美，往往会检索到包含无关信息的高排名段落。这些无关信息可能在语义上与上下文相关，但却与问题的答案无关，甚至会导致模型产生错误的推理和回答。

研究者提出了一个框架，用于构建从语义上不相关、部分相关到与问题直接相关的高质量无关信息。这一框架的关键在于模拟现实世界中检索系统可能返回的结果，以便更真实地评估LLMs对无关信息的鲁棒性。可以将信息分为三类：

1. 语义不相关信息（Unrelated Information）：选择与问题主题无关，但在检索系统中可能因为高相似性得分而被检索到的信息。
2. 部分相关信息（Partially Related Information）：包含与问题主题部分重叠的信息，但不提供问题的答案。
3. 相关信息（Related Information）：与问题高度相关，但并不提供正确答案的信息，可能通过误导性的联系来干扰模型。

研究者们采用了多项选择题的形式来评估LLMs对无关信息的处理能力。他们使用了两个评估指标：

+ 误表述比率（Misrepresentation Ratio，MR）：衡量LLMs因受到无关信息影响而改变正确回答内容的比例。
+ 不确定比率（Uncertainty Ratio，UR）：衡量LLMs在回答中表述“不确定”的比例。

通过这些指标，研究者们能够量化无关信息对LLMs生成答案的影响，并评估模型对干扰的抵抗力。

实验部分，研究者使用了四个不同的LLMs，并在多种条件下测试了它们对无关信息的处理能力。实验结果表明：

1. 语义相关性的影响：与不相关信息相比，LLMs更容易被高度语义相关的无关信息所误导。
2. 无关信息数量的影响：无关信息数量的增加会降低LLMs识别真正相关信息的能力，使它们更容易分心。
3. 问题格式的影响：LLMs在自由形式的问题格式下表现出更强的鲁棒性。
4. 现有策略的局限性：当前用于提高LLMs对无关信息识别能力的策略在实际应用中效果有限，有时甚至会产生负面影响。

实验结果显示，随着无关信息相关性的增加，不同模型的效果均有所下降。特别是对于开源模型Llama2-7B，其表现不如闭源模型。此外，随着无关信息数量的增加，LLMs更倾向于选择无关答案。

在问题格式方面，自由式问答形式的问题受答案无关片段影响最小，其次是是非性问答，而多项选择式问题受影响最大。这表明问题格式对于LLMs处理无关信息的能力有显著影响。

## 详细论文解读
<font style="color:rgb(0, 0, 0);">本文提出了一种构建高质量无关信息的方法，并通过详细分析了大型语言模型（LLM）在不同场景下的性能表现，为改善检索增强型生成（RAG）系统的效率和效果提供了有价值的见解。 具体来说，该方法首先针对某些特定任务，如数学问题求解，添加指令到提示中，使LLM能够自动验证问题描述中的无关信息。然后，将这种方法与链式思维（CoT）提示相结合，以进一步提高模型的性能。然而，这种研究主要关注于无关的信息在算术推理中的作用，而在RAG应用中，无关信息往往来自于检索结果。 因此，本文提出了另一种构建高质量无关信息的方法，即使用人工构建的数据集来训练模型，使其能够识别并过滤掉一些可能被现有高级RAG系统所忽略的相关但无关的信息。同时，通过对不同场景下LLM的性能进行全面分析，本文揭示了LLM与无关信息交互的一些规律，从而为进一步优化RAG系统的效率和效果提供了指导。</font>

### <font style="color:rgb(0, 0, 0);">方法改进</font>
<font style="color:rgb(0, 0, 0);">本文的主要贡献在于提出了一种新的构建高质量无关信息的方法，并通过详细的实验分析了其在各种场景下的性能表现。相比于以往的研究，该方法更加全面、细致地考虑了无关信息对模型性能的影响，并提供了一些实用的技术手段来帮助RAG系统更好地应对这一挑战。</font>

### **<font style="color:rgb(0, 0, 0);">解决的问题</font>**
<font style="color:rgb(0, 0, 0);">本文主要解决了两个问题：一是如何构建高质量的无关信息，以帮助RAG系统更好地过滤掉无关的内容；二是如何评估模型在面对不同场景下的性能表现，以便更好地理解模型与无关信息之间的关系，并为改进RAG系统的效率和效果提供指导。这些问题都是当前RAG系统面临的实际挑战，而本文提出的解决方案可以为其带来一定的改进和提升。</font>

### **<font style="color:rgb(0, 0, 0);">论文实验</font>**
<font style="color:rgb(0, 0, 0);">本文主要介绍了作者在评估语言模型（LLM）对无关信息的干扰方面所做的实验，并分析了其结果。作者采用了三个实体为中心的实体相关问题答案集（POPQA）和一个广泛使用的实体相关问题答案集（ENTITYQUESTIONS），以及三种语言模型（GPT-3.5 Turbo、GPT-4 Turbo和Gemini Pro）和一种开源语言模型（Llama2-7B）。作者使用了多种评估指标来衡量语言模型在面对不同级别的无关信息时的表现。</font>

<font style="color:rgb(0, 0, 0);">首先，作者将无关信息分为三个级别：完全不相关的无关信息、部分相关的无关信息和相关但误导性的无关信息。然后，作者使用不同的方法构造这些无关信息，包括从相同的实体关系中选择与问题主题无关的信息作为完全不相关的无关信息，从相同的关系中选择另一个实体和对象作为部分相关的无关信息，以及通过连接实体和对象来创建误导性的无关信息。最后，作者使用相似度分数来测量问题和无关信息之间的语义相关性，并使用两种评价指标——误代表率和不确定性比率——来评估语言模型在面对不同级别的无关信息时的表现。</font>

<font style="color:rgb(0, 0, 0);">作者发现，当面临高度相关的无关信息时，语言模型更容易被误导。随着无关信息数量的增加，语言模型更易于分心。此外，作者还发现，即使提供了明确的相关信息，语言模型仍然可能受到无关信息的影响，这是一个在现实世界中的RAG系统部署中可能会更加严重的问题。最后，作者还研究了不同类型的问题格式对语言模型表现的影响，并发现在自由问答和真假问答等非多项式选择题格式下，语言模型比多项式选择题格式更容易受到无关信息的干扰。</font>

![](https://cdn.nlark.com/yuque/0/2024/png/406504/1712625392442-9e75a363-cffa-4348-8723-61527d140f6b.png)

### **<font style="color:rgb(0, 0, 0);">论文总结</font>**
+ <font style="color:rgb(0, 0, 0);">本文研究了大型语言模型在面对复杂场景中的挑战，并提出了一种构建无关信息的框架。</font>
+ <font style="color:rgb(0, 0, 0);">通过实验验证了当前解决方案的局限性，为后续的研究提供了指导方向。</font>
+ <font style="color:rgb(0, 0, 0);">结果具有一定的理论价值和实际应用意义，有助于提高RAG系统的可靠性和真实性。</font>

### **<font style="color:rgb(0, 0, 0);">方法创新点</font>**
+ <font style="color:rgb(0, 0, 0);">提出了一种构建无关信息的框架，包括从不相关到部分相关再到相关的不同程度的信息。</font>
+ <font style="color:rgb(0, 0, 0);">采用了多种评估方法来测试LMM在面对不同条件下的表现，如CoT方法、"忽略"指令以及提供示例等。</font>
+ <font style="color:rgb(0, 0, 0);">在实验中还使用了相似度分数作为衡量指标，使得结果更加客观和准确。</font>

### **<font style="color:rgb(0, 0, 0);">未来展望</font>**
+ <font style="color:rgb(0, 0, 0);">可以进一步探索如何更好地引导LMM识别和过滤掉无关信息，提高其准确性。</font>
+ <font style="color:rgb(0, 0, 0);">对于更复杂的场景，可以尝试引入更多的策略和技术手段，如强化学习等。</font>
+ <font style="color:rgb(0, 0, 0);">同时也可以考虑将该研究扩展到其他领域，如自然语言推理、文本分类等。</font>

