大型语言模型（LLM），如GPT-4，展现了在生成类似人类的文本方面的惊人能力。最新的研究不再仅限于文本生成，而是将LLM视为智能代理和自主代理的核心控制器，它们不仅能够撰写文字，还能进行推理、行动和学习。

LLM有潜力成为人工通用智能系统。它们正迅速从被动的语言处理系统转变为能够独立推理和完成任务的主动、目标导向型智能代理。

这一进展标志着人工智能领域的重大转变，并承诺将彻底改变人类与机器的互动方式。

## <font style="color:#2F4BDA;">什么是大型语言模型（LLM）代理？</font>
LLM代理是一种利用大型语言模型（LLM）作为核心计算引擎的人工智能系统。它们不仅能够生成文本，还包括进行对话、完成任务、推理，并能表现出一定程度的自主行为。

LLM代理通过精心设计的提示来驱动，这些提示编码了角色、指令、权限和上下文，以塑造代理的响应和行动。

LLM代理的一个主要优势是它们能够表现出不同程度的自主性。根据设计阶段赋予的能力，代理可以表现出从纯粹反应性到高度主动性的行为。

通过适当的提示和知识获取，LLM代理能够在多种应用中半自主地协助人类，从对话式聊天机器人到目标驱动的工作流程和任务自动化。

它们的灵活性和语言建模强项开启了为自然语言提示量身定制的AI伙伴的新可能性，并能在人类监督下进行协作。

为了增强自主能力，LLM代理需要访问知识库、记忆和推理工具。提示工程为代理提供了高级分析、项目规划、执行、回顾过去的努力、迭代改进等高级技能。有了足够的知识和提示，代理可以在人类监督下管理相对自给自足的工作流程。

这最终通过精心设计的提示来指导代理的行为，编码角色、指令和权限。用户通过提供与AI的输出相应的互动提示来高效指导代理。精心设计的提示允许无缝的人工智能协作。

![](https://cdn.nlark.com/yuque/0/2023/png/406504/1701348521232-a0e9fa8f-a9ae-4d88-81aa-221fb4fb66ea.png)

## <font style="color:#2F4BDA;">LLM代理的核心能力</font>
+ LLM代理利用LLM的固有语言能力理解指令、上下文和目标，从而能够基于人类提示进行自主或半自主操作。
+ LLM代理可以利用一系列工具——如计算器、API、搜索引擎——来收集信息并采取行动完成指定任务。它们的能力远超语言处理。
+ LLM代理能展现链式思考、思维树等提示工程概念，通过逻辑联系来推进问题的结论和解决方案。它们的推理能力不仅限于文本理解。
+ LLM代理能够根据上下文和目标生成特定用途的定制文本——如电子邮件、报告、市场营销材料——并将这些融入它们的语言生成技能中。
+ 代理可以是完全自主的或半自主的，需要不同程度的用户互动。
+ 代理可以结合不同的AI系统，例如将大型语言模型与图像生成器结合，实现多方面的能力。

## <font style="color:#2F4BDA;">从LLM到代理的演变——快速回顾</font>
大型语言模型（LLM）最初是专注于统计语言建模的被动系统。早期的LLM，如GPT-2，能够令人印象深刻地生成或总结文本，但缺乏目标、身份或代理性的概念。它们只是没有行动动机的模型。

随着时间的推移，用户意识到通过精心的提示工程可以从LLM中获得更类似于人类的响应。人格和身份被编码进提示中，以塑造LLM的语气、观点和知识。更高级的提示技术使LLM能够计划、反思，并展示初步的推理能力。

这促使基于LLM的代理的兴起，它们被有意设计用于模拟对话或完成特定任务。像ChatGPT这样的对话代理采用了人格，以参与惊人地类似于人类的对话。目标导向型代理利用LLM的推理能力来执行工作流程。

随着提示工程实践的成熟，这两种代理类型都获得了巨大的益处。提示配方使预定义结构优化了一致性和效率。模块化组件和元素提供了更大的定制化。

通过给代理配备外部记忆、知识整合和工具整合，极大地扩展了它们的能力。多代理协调进一步释放了新的潜力。作为基础的是，迭代提示工程仍是引导代理行为的关键。

如今，被动LLM和互动、半自主代理之间的界线已经大幅模糊。代理展示出令人印象深刻的主动性，利用它们的LLM来共同协作提示，而不仅仅是响应。这种演化在迅速进行，随着提示工程激发出LLM更高级的推理、学习和技能。

### <font style="color:#117CEE;">提示循环概览</font>
迭代式的提示循环是促进用户与LLM代理之间自然对话的关键：

1. 用户提示：用户提供一个初始提示以启动对话，并将代理引向特定的任务或讨论主题。
2. 提示工程：提示的创建被精心设计，以向LLM提供最佳指令和上下文。语气、观点和对话风格等因素有助于引导LLM的响应。
3. LLM生成：LLM处理在其当前上下文窗口内编码的提示，以生成相关的文本响应。这个响应显示出反映提示工程的细微差别。
4. LLM自回归链接：LLM生成的文本递归地添加到上下文窗口。这使LLM能够基于自身的响应构建，自回归地链接输出。
5. 用户反馈循环：用户根据LLM的输出提供后续提示。这种反馈通过循环的进一步迭代引导对话。
6. 上下文扩展：随着每个循环，上下文窗口扩大，使LLM代理能够积累知识并更好地理解用户的对话目标。
7. 反复循环：经过多次循环，LLM代理在不断演变的对话中逐渐找到解决方案，揭示更深层次的洞察，并保持话题焦点。

### <font style="color:#117CEE;">什么构成了一个好的AI提示？</font>
AI提示是一段精心制作的文本或其他输入，提供给人工智能系统以引发期望的响应。AI提示作为指令，传达用户的意图给底层的机器学习模型。

提示的结构和内容对于成功指导AI系统至关重要。提示必须设计得与被利用的特定AI模型的能力相匹配。不同的AI模型被训练以专门处理特定类型的输入和输出。

在提示生成性AI系统，如大型语言模型和图像生成模型时，用户必须提供描述性文本，指明期望的输出。提示中的措辞和细节程度显著影响AI响应的质量和相关性。

从本质上说，AI提示以AI可以处理和采取行动的自然语言编码用户的请求。提示工程是将想法转化为优化指令的技能，这些指令生成准确、相关且有用的AI输出。有效的提示将AI系统视为协作伙伴，用户通过互动式提示仔细引导机器的行为。

### <font style="color:#117CEE;">AI提示的结构</font>
AI提示由几个基本构建块组成，它们共同为AI系统提供指令和上下文。理解有效提示的核心组成部分有助于用户制定优化的提示。

+ **任务：**任务定义了AI的预期输出或目标。这可能是回答问题、生成图像或制作创意内容。明确陈述任务有助于使AI系统集中注意力。
+ **指令：**指令向AI提供了如何执行任务的具体指导。这包括输出的期望属性、格式、内容要求和任何约束。指令作为指引AI的规则。
+ **上下文：**上下文提供了背景信息以定位任务。例如，图片和其他种子数据给AI模型一个预期响应的感觉。上下文作为灵活的指导，而非固定规则。
+ **参数：**参数是改变AI处理提示的配置。这包括诸如温度和top-p之类的设置，它们影响输出的创造性和随机性。
+ 输入数据：对于像图像编辑这样的任务，提示必须包括AI要转换的输入数据。语言模型也需要文本输入。

仔细结合这些核心组件使用户能够高效地提示AI系统。任务和指令提供方向，而上下文和数据给AI提供了所需的参考。参数微调最终输出。在提示结构方面的专业知识是提示工程的关键。

### <font style="color:#117CEE;">提示组件内的元素</font>
上述AI提示的关键组件可以进一步细分为更细致的元素。每个组件包含许多元素，这些元素有助于为AI系统提供一套完整详细的指令和上下文。

例如，任务组件包含以下元素：

+ 角色 - AI应采用的人格
+ 命令 - 指导AI的动作动词
+ 主题 - 关注的主题内容
+ 查询 - 需要回答的具体问题



指令组件的元素包括：

+ 输出 - 生成内容的预期属性
+ 结构 - 组织格式、部分、流程
+ 可以 - 可接受的质量和内容
+ 不可以 - 不可接受的质量和内容
+ 要点/想法 - 需要包含的具体概念
+ 示例 - 展示期望输出的样本



上下文组件涉及的元素如下：

+ 目标受众 - 内容的预期消费者
+ 视角 - 采用的观点
+ 目的 - 目标和动机
+ 补充信息 - 额外的背景细节



参数组件包含诸如以下设置：

+ 温度 - 创造性/不可预测性水平
+ 长度 - 生成内容的大小
+ Top-p - 不太可能输出的可能性
+ 惩罚 - 阻止不想要的输出
+ 模型 - 使用的AI系统



通过将提示细化为更精细的元素，用户可以精确地为AI系统定制指令，从而对输出实现更大的控制。元素级别的提示工程打开了更高级的提示能力。

### <font style="color:#117CEE;">提示配方</font>
提示配方是用于以结构化格式构建AI提示的预定义模板。它们提供了一个框架，将任务、指令、上下文和参数的核心组件结合成可重复使用的模式。

提示配方的主要好处是标准化。通过填写配方模板，用户可以快速生成新的提示，并在不同用例中保持一致性。这确保了AI系统结果的可靠性和统一性。

在每个配方中，某些字段预先填充了默认设置，而其他字段则保留空间以便定制。这样，用户可以根据自己的特定需求定制提示，同时保持整体配方结构。可定制的字段可能包括具体内容要求、目标受众、期望语调、输出长度、创造性水平等。

分享和协作编辑配方有助于通过迭代和测试进行优化。可以对配方进行编目和性能跟踪，以识别最佳模板。将配方分组到项目中，可围绕业务领域和用例进行组织。

随着时间的推移，用户可以建立涵盖多种场景和应用的广泛提示配方库。新的配方可以基于现有配方的元素构建，随着知识的累积而发展。保持结构化的配方使用户能够适应性地组合各种技术，推动AI提示的可能性边界。

![](https://cdn.nlark.com/yuque/0/2023/png/406504/1701348612465-285f3bd1-4d3d-4daa-9e43-36471f6845be.png)

## <font style="color:#2F4BDA;">大型语言模型代理的结构</font>
那么，构建这些代理到底需要什么？将原始语言模型转化为能力强大、自主的代理，需要将核心LLM与知识、记忆、接口和工具的额外组件仔细集成。

虽然LLM构成了基础，但三个关键元素对于创建能够理解指令、展示有用技能并与人类协作的代理至关重要：底层的LLM架构本身、有效的提示工程，以及代理的接口。

让我们探索这些将LLM从被动文本生成器升级为活跃、半自主代理的核心组件。了解代理创建中涉及的成分，揭示了在现实世界中部署这些AI系统的机会和考虑因素。我们将详细解析是什么将LLM转化为LLM代理。

### <font style="color:#117CEE;">LLM核心</font>
LLM代理的基础是底层的大型语言模型本身。这个基于庞大数据集训练的神经网络提供了基本的文本生成和理解能力。LLM的大小和架构决定了代理的基线能力和局限性。

### <font style="color:#117CEE;">提示配方</font>
同样重要的是有效的提示配方，以激活和引导LLM的技能。精心制作的提示赋予代理其人格、知识、行为和目标。提示配方提供预定义的模板，结合关键指令、上下文和参数，以一致地引出所需的代理响应。

提示中嵌入的人格对于会话代理来说至关重要，以采用独特的说话风格。对于面向任务的代理，提示分解目标、提供相关知识，并构建指令。

### <font style="color:#117CEE;">接口和互动</font>
接口决定了用户如何向代理提供提示。命令行、图形化或对话式接口允许不同程度的交互性。完全自主的代理可能通过API从其他系统或代理以程序化方式接收提示。

接口影响代理互动是否感觉像是来回合作，还是自主助手。流畅的接口使焦点保持在提示本身。

### <font style="color:#117CEE;">记忆</font>
记忆提供了时间上的上下文，并记录了与特定用户或任务相关的细节。在代理中通常使用两种形式的记忆：

+ 短期记忆 - LLM固有的上下文窗口保持对最近对话历史或最近采取的行动的意识。
+ 长期记忆 - 与LLM配对的外部数据库，用于扩展对过去更远时期的事实、对话和其他相关细节的回忆能力。长期记忆为代理装备了持久、累积的记忆库。

记忆使代理在时间和用户特定体验上有所根据。这种上下文个性化对话，并在多步骤任务中提高一致性。

### <font style="color:#117CEE;">知识</font>
虽然记忆专注于用户和任务的时间细节，知识代表了适用于所有用户的通用专业知识。知识扩展了LLM模型参数内本身包含的内容。

+ 专业知识 - 以特定主题或领域为针对性，补充LLM基础知识，包括领域特定的词汇、概念和推理方法。
+ 常识知识 - 增加LLM可能缺乏的关于社会、文化、物理等方面的一般世界知识。
+ 程序性知识 - 提供完成任务的方法，如工作流程、分析技术和创造性过程。

注入知识扩展了代理理解和讨论的范围。即使在记忆被重置或跨任务适应时，知识也保持相关性。这种结合使代理既有专业知识又有个性化记忆。

将记忆和知识的实施保持独立，最大化了根据多样化需求配置代理的灵活性。代理可以集成不同的知识来源，并与随时间积累的用户特定记忆库进行整合。

### <font style="color:#117CEE;">保持记忆与知识逻辑上的分离</font>
为LLM代理实施单独的外部记忆和知识库提供了多种好处，包括：

+ 可以分析代理的推理技能随着其记忆积累而随时间演变的情况，同时其知识保持不变。比较不同时间的输出可以隔离扩展记忆的影响。
+ 允许选择性地“清除”代理的记忆，而不会丢失一般知识。这对于承接新项目很有用，之前的上下文记忆可能引入偏见。保留知识而抹除记忆使代理严格专注于新的任务上下文。
+ 通过避免错误提示或数据注入，将代理的经过验证的知识库从可能的恶意记忆修改中保护起来。单独的存储保持了可信知识的纯净性。

将外部记忆与注入的知识解耦增加了LLM代理在处理多样化任务和建立长期经验时的敏捷性、可解释性和安全性。架构分离最大化了两个组件的效用。

### <font style="color:#117CEE;">工具集成</font>
代理不必仅通过语言生成行动 - 工具集成允许通过API和外部服务完成任务。例如，代理可以使用代码执行工具来运行提示中引用的软件程序，或者使用诸如OpenAi的代码解释器这样的“插件”。

总结来说，LLM代理将强大的核心能力与补充组件结合起来，展现出它们令人印象深刻的能力。底层LLM提供了基本语言技能，而提示配方将这些能力引向目标和人格。接口使得互动成为可能，额外的记忆和知识提高了上下文理解。

这些成分共同使得协作、半自主的代理能够理解自然语言、对提示进行推理、积累记忆并做出明智的行动。LLM代理已经超越了被动语言建模，成为在众多对话和任务导向领域协助人类的有能力的伙伴。

然而，它们的表现和对齐最终取决于它们接收的提示的质量。深思熟虑的提示工程仍然是从LLM中解锁更高智能和实用性的关键驱动力，因为它们正在转变为越来越能干的代理。

![](https://cdn.nlark.com/yuque/0/2023/png/406504/1701348778025-7579a573-adb5-49cb-b9c7-07ba9ea6186a.png)

## <font style="color:#2F4BDA;">LLM代理的两种主要类型</font>
大型语言模型使一种具有令人印象深刻能力的新一代AI代理成为可能。基于LLM的代理可以根据其主要功能被划分为两种关键类型：对话代理和任务导向型代理。

尽管两者都利用了语言模型的力量，但这两种代理类型在其目标、行为和提示方法上有重要的区别。

对话代理专注于提供引人入胜、个性化的讨论，而任务导向型代理致力于完成明确定义的目标。

在下面的部分中，我们将探索每种类型LLM代理独特的特征和提示考虑。了解这些差异使用户能够选择和引导适合其需求的适当代理。

### <font style="color:#117CEE;">对话代理：模拟人类对话</font>
最近在自然语言处理方面的进步使得像ChatGPT和GPT-4这样的AI系统具备了显著的对话能力。这些对话代理能够进行令人印象深刻的类似人类的对话，理解上下文并以逼真的陈述进行回应。

例如合成交互式人格代理（SIPA）这样的对话代理，通过特征化它们的语调、说话风格、观点和领域知识的提示来扮演人格。这允许用户与拟人化的代理进行细腻的讨论。

对话代理的一个主要吸引力是它们在讨论中模仿人类倾向的能力。当通过提示工程制定时，代理考虑了语调、说话风格、领域知识、观点和个性特质等因素。这允许进行细腻、上下文相关的互动。

在应用程序中，如客户服务聊天机器人，对话代理可以利用人格提示来塑造自然而富有同情心的回应。它们在语言理解和生成方面的能力使得对话流畅且适应性强。

对话代理还开启了交互式获取信息的大门，这类似于人与人之间的对话。它们可以通过提示采纳领域专业知识，作为知情的顾问或专家，例如在医疗或法律领域。

对话代理提供商继续增强记忆、知识整合和响应质量能力。随着时间的推移，这些AI系统可能具备足够的能力通过扩展的图灵测试，并作为全功能的虚拟助理。

由语言模型驱动的对话代理标志着人机交互的一次重大演变。它们通过提示工程进行生产性、个性化对话的能力，在许多领域和应用中开启了新的可能性。

### <font style="color:#117CEE;">任务导向型代理：目标驱动的生产力</font>
与对话代理（如生成型AI网络（GAINs）中的代理）相比，任务导向型AI代理专注于实现定义明确的目标和完成工作流程。这些目标驱动的系统擅长将高层次任务分解为更易管理的子任务。

任务导向型代理利用其强大的语言建模能力来分析提示、提取关键参数、制定计划、调用API、通过集成工具执行动作，并报告结果。这使得可以自动处理多方面的目标。

提示工程使任务导向型代理具备战略性任务重构、思维链条串联、反思过去的工作以及方法的迭代改进的技能。现代问题解决技巧也可以编码到提示中，以增强分析和规划。

通过充分访问知识和工具，任务导向型代理可以半自主地运作，由提示定义的目标驱动。它们的工作可以由人类协作者异步审查。

任务导向型代理的群体也可以通过集中的提示接口进行协调。这允许组装具有互补能力的AI代理团队来完成广泛目标。这些代理处理不同的子任务，同时协同地朝着总体目标努力。

未来，企业级任务自动化和增强将越来越多地利用以目标为中心的代理。它们专门的提示赋予代理不仅理解自然语言提示的能力，而且根据这些提示采取行动，推动进展和生产力。

## <font style="color:#2F4BDA;">LLM代理如何表现自主性？</font>
要使LLM代理展现有意义的自主性，它不能仅仅孤立地响应单个提示——它必须在持续的过程中不断地被引导。这引出了一个问题：是什么提供了这种持续的提示，使得自我管理行为成为可能？

当前LLM的一个主要局限是它们无法独立执行递归自我循环来自我提示。一个LLM本身无法质疑自己的输出并在外部干预下重新自我提示。

真正的自主性需要一个外部系统来审查代理的响应，提供必要的指导和纠正，并提供基于上下文构建的后续提示。这个自动化提示系统充当着监督者的角色，引导代理持续的学习和改进。

在大多数情况下，这个监督系统是另一个AI代理，通常也是一个LLM。两个代理配合工作 - 一个生成响应，另一个根据需要审查并重新提示第一个代理。多代理互动创造了培养自主技能的训练循环。

监督代理审查生成代理的工作，提供后续提示和指令，并提供互动反馈。这种通过API介导的配对提示关系，为生成代理从狭窄能力向通用智能的进步提供了支架。

本质上，自主性来自于提示生态系统中代理之间的相互作用。通过专门的监督代理持续提供的提示培养自主技能，这些提示提供方向、纠正和日益增加的挑战。持续的提示解锁了在推理、效果和自我导向决心方面的成长。

## <font style="color:#2F4BDA;">代理基础方法的好处</font>
以语言模型为驱动力，将AI系统作为互动、半自主代理使用，提供了一系列优势：

+ 安全性 - 代理可以被容器化，并通过安全的API连接，以限制风险。它们的互动被监控和审查。
+ 模块化 - 可以根据需要组装和协调具有不同能力的代理。添加或替换代理很直接。
+ 灵活性 - 代理的角色和行为通过提示来指导，允许动态配置。
+ 自动化 - 与更僵硬的AI系统相比，代理需要较少的持续人类监督。
+ 专业化 - 代理可以基于专注的提示策略在特定领域建立深入专业知识。
+ 质量 - 监控代理对话使得提示的持续改进更加准确和相关。
+ 隐私 - 敏感用户数据可以保持隔离，而代理操作衍生数据。

代理基础范式提供了人类控制和AI自主性之间的理想平衡点。代理与人类提示协作，通过迭代改进。将AI助理构建为目标驱动的代理释放了许多好处。

## <font style="color:#2F4BDA;">总结</font>
大型语言模型正在迅速从被动文本生成器演变为多功能的、半自主和自主代理。精心的提示工程激活了LLM核心的对话和任务驱动能力。知识库、工具集成和记忆等补充组件使代理能够展示扩展的推理和专业知识。

对话代理可以与用户进行个性化对话和领域特定的建议。任务导向型代理调动其技能来执行工作流程和目标。如果架构得当，LLM代理可以提供灵活的智能，与人类在广泛的应用中协作。

然而，它们的最终潜力仍然与它们接收的提示的质量紧密相连。发展提示工程的艺术和科学是安全有效指导这些系统的关键。随着提示的改进，LLM代理的能力也将提升，开启AI协助的新前沿。









