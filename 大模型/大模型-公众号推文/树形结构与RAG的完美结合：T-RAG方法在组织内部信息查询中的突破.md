> <font style="color:rgb(0, 0, 0);">原文：T-RAG: LESSONS FROM THE LLM TRENCHES</font>
>

<font style="color:rgb(0, 0, 0);">这篇论文介绍了在企业文档中进行问答的应用场景，并探讨了如何利用大型语言模型（LLM）和检索增强生成（RAG）框架构建一个可靠的应用程序。作者分享了他们使用自定义树结构来表示组织实体层次结构的经验，并将其与微调过的开源LLM相结合，以提高系统的性能。实验结果表明，这种组合方法比简单的RAG或微调实现表现更好。最后，作者总结了一些他们在构建实际应用中的经验教训。</font>

### **<font style="color:rgb(0, 0, 0);">论文方法</font>**
### **<font style="color:rgb(0, 0, 0);">方法描述</font>**
<font style="color:rgb(0, 0, 0);">该论文提出了三种不同的方法来处理组织内部的信息查询：基于检索的生成（RAG）、知识图谱（KG）和使用特定领域的训练数据进行微调（finetuning）。其中，RAG方法是通过检索与用户查询相关的文档片段，并将这些片段作为上下文输入到预训练的语言模型中，然后根据上下文生成回答。KG方法则是利用组织内部的知识图谱来增强上下文信息，以便更好地回答用户问题。而finetuning方法则是在预训练的语言模型上进行微调，以适应特定领域的需求。</font>

### **<font style="color:rgb(0, 0, 0);">方法改进</font>**
<font style="color:rgb(0, 0, 0);">在RAG方法的基础上，该论文还提出了一种新的方法——Tree-RAG（T-RAG），它结合了树形结构和RAG方法的优点。具体来说，T-RAG首先使用RAG方法从文档中检索相关段落，并将其作为上下文输入到语言模型中；同时，它还会利用组织内部的实体树来增强上下文信息，特别是当用户查询涉及组织内的实体时。这样可以更准确地回答用户的问题。</font>

### **<font style="color:rgb(0, 0, 0);">解决的问题</font>**
<font style="color:rgb(0, 0, 0);">该论文的主要目标是开发一种能够高效、准确地回答组织内部信息查询的语言模型。传统的检索式问答系统虽然效率高，但其答案质量较低，无法满足用户的期望。相比之下，预训练的语言模型具有更强的泛化能力和更好的表现效果，因此成为了解决方案之一。然而，由于预训练的语言模型通常需要大量的训练数据才能达到最佳性能，因此如何在有限的数据集上对其进行优化是一个关键问题。该论文提出的三种方法都旨在解决这个问题，从而提高语言模型在组织内部信息查询任务中的表现。</font>

![](https://cdn.nlark.com/yuque/0/2024/png/406504/1708581142593-b67fcdc3-7a70-432b-bace-c600c4aba0f9.png)

### **<font style="color:rgb(0, 0, 0);">论文实验</font>**
<font style="color:rgb(0, 0, 0);">本文主要介绍了使用预训练语言模型（Pretrained Language Models，PLMs）构建问答系统的方法，并通过一系列的对比实验来验证该方法的有效性。具体来说，本文采用了以下几种对比实验：</font>

1. <font style="color:rgb(0, 0, 0);">与传统的基于规则的问答系统（Rule-Based Question Answering System，RBQAS）和基于检索的问答系统（Retrieval-Based Question Answering System，RBQAS）的比较实验。在该实验中，作者使用了三组问题集对三种不同的问答系统进行了测试，并统计了它们的正确率。结果表明，使用预训练语言模型构建的问答系统在准确率上表现更好。</font>
2. <font style="color:rgb(0, 0, 0);">对于同一个预训练语言模型，分别使用不同的微调策略（Fine-Tuning Strategies）进行实验。在该实验中，作者使用了一个由多个文档组成的知识库，以及一个预先定义好的问题集合，对三种不同的微调策略进行了测试，并统计了它们的准确率。结果表明，在不同的微调策略下，预训练语言模型的表现存在差异。</font>
3. <font style="color:rgb(0, 0, 0);">对于同一个预训练语言模型，分别使用不同的实体树结构（Entity Tree Structures）进行实验。在该实验中，作者使用了一个由多个文档组成的知识库，以及一个预先定义好的问题集合，对两种不同的实体树结构进行了测试，并统计了它们的准确率。结果表明，使用实体树结构可以显著提高预训练语言模型的回答准确性。</font>

<font style="color:rgb(0, 0, 0);">综上所述，本文通过一系列的对比实验，证明了使用预训练语言模型构建问答系统的有效性，并提供了一些优化建议。</font>

![](https://cdn.nlark.com/yuque/0/2024/png/406504/1708581142542-00e19da0-2bc5-478e-b522-9410026fdc04.png)

![](https://cdn.nlark.com/yuque/0/2024/png/406504/1708581142595-c1602570-b878-4d6e-8e1e-165fecb57ba4.png)

