人工智能经过几十年的发展，已经在各行各业展现出了令人惊叹的能力。得益于深度学习技术的进步和算力的飞跃，尤其是最近几年预训练语言模型的崛起，AI已经具备了相当强大的语言理解和语言生成能力。GPT-3、PaLM等大模型让我们看到了通往通用人工智能的曙光。



然而，当前的语言模型在面对复杂现实任务时，还是难免有些捉襟见肘。再强大的模型，也脱离不了输入文本、输出文本的局限。现实世界的任务千差万别，单一的语言交互远远不够。这时候，我们就需要赋予语言模型使用外部工具的能力，让它像人类一样，善用工具来解决问题。这就引出了今天的主题：工具学习(Tool Learning)。



顾名思义，工具学习就是让语言模型学会使用工具，遵循人类的指令，操纵工具来完成任务。这里的工具可以是软件程序，比如搜索引擎、知识库、文档阅读器、图像识别模型等等，也可以是硬件设备，比如家用电器、机器人等。语言模型通过对环境中的工具进行调用和交互，利用工具反馈的信息，最终给出满足要求的高质量结果。



举个简单的例子，如果我们让模型回答"爱因斯坦出生于哪一年?"，原来的做法是在语料库或知识库里搜寻相关信息，现在我们可以让模型使用搜索引擎，浏览网页，提取关键信息，给出准确的答案。又比如我们让模型创作一首古风歌词，模型可以先调用古诗词数据库，学习借鉴前人的技法，再利用知识增强的文本生成模型，谱写出一首格律工整、韵味十足的好作品。



工具学习带来的提升是显而易见的：

1. 知识来源更加广泛，不限于预训练数据，工具可以接入海量的动态信息。 
2. 模型能力更加全面，不限于语言任务，借助工具可以完成多种形态的工作。
3. 任务适用面更加宽泛，不限于特定领域，可以灵活应对各种场景需求。



从技术角度看，目前工具学习主要有两种范式：工具增强学习和面向工具的学习。



工具增强学习把工具视为语言模型的有力助手，模型将工具的执行结果等信息融入到推理过程中，产出更加精准、知识丰富的结果。代表工作如WebGPT，它利用搜索引擎获取网页内容，作为问答模型的补充输入，大幅提升了模型在开放域问答任务上的表现。这一范式的优点是比较简单有效，模型只需要学会融合不同来源的信息即可。



而面向工具的学习则更进一步，它要求模型主动管理工具的使用，根据任务形成工具使用的策略和计划。模型要学会用自然语言表达每一步动作，推理每个工具的效用，优化工具选择和排列组合，以期最高效地完成目标。这对模型的推理决策能力要求很高，需要深度理解工具的机理，同时平衡工具使用的成本和收益。



要实现灵活高效的工具学习，对语言模型的要求可以概括为三个方面：意图理解、工具理解、规划推理。



首先是意图理解。我们知道人类表达指令的方式是千变万化的，即使表达同一个意图，遣词造句也可能大相径庭。模型必须学会从形形色色的指令中准确提取语义，哪怕指令有歧义、不完整，也要映射到正确的语义空间。同时，模型要有强大的泛化能力，不能只局限于训练数据中见过的指令形式。一些前沿工作如Tk-Instruct、FLAN等，通过海量指令数据的多任务微调，让模型掌握了执行任务指令的通用能力，迁移到新指令时也毫无压力。



其次是工具理解。模型要熟悉每个工具的功能、输入输出规范、适用条件等等，这样才能根据任务需求选择最匹配的工具。工具理解可以通过少样本学习或提示学习来实现。少样本学习就是给模型一些使用工具的示例，模型通过模仿这些人类行为，很快掌握工具的玩法。提示学习则是直接用自然语言描述工具的meta信息，模型阅读理解后就能领会工具的特性。总之，让模型尽快熟悉工具，为后续使用打好基础。



最后是规划推理。工具的使用往往不是一蹴而就的，需要多个步骤的协同。一些任务可能需要不同工具的配合，一些任务可能需要同一工具的反复调用。模型必须根据终极目标，灵活地规划每一步的工具选择和参数设置。而且，规划要有动态调整的能力，根据每一步的实际效果，及时修正后续的策略。这就要求模型在执行的同时还要持续地观察和思考。一方面模型要尽可能利用先验知识做好执行的内部演练，尽量不要在真实环境中反复试错。另一方面也要利用实时反馈不断改进策略，在探索和利用之间找到平衡。



工具学习的训练策略主要有两类：从人类演示中学习，以及从环境反馈中学习。前者通过监督学习让模型模仿人类使用工具的轨迹，后者通过强化学习让模型自主摸索最佳的工具使用策略。大家可能比较熟悉的是第一类方法，用人工标注的工具使用数据去指导模型行为。但我认为，随着工具种类的爆炸式增长，人工标注的代价会越来越高。第二类让模型自主学习的范式或许更有前景，关键是如何设计恰当的奖励函数去引导模型探索。我们在WebCPM、WebShop等项目中做了一些尝试，利用模型决策前后的loss变化去优化搜索引擎和电商平台的使用效果，让模型不断学习对任务目标最有利的工具使用方式。



除了利用现有工具，我们更期待语言模型能创造出新的工具。目前大多数工具是为人类用户设计的，考虑到易用性和鲁棒性。但对于AI模型来说，工具完全可以设计得更灵活、高效、易计算，专门匹配模型的特性。最新的CREATOR工作就让GPT-3充当工具创造者的角色。它将复杂任务拆解成一系列可复用的原子操作，并将这些原子操作实现为Python函数。在推理和决策的每个关键节点，模型可以调用这些自创的工具函数，极大加速了任务的执行。在数学推理、表格问答等领域，取得了超越人类的效果。可以预见，让语言模型参与工具的设计将是一个很有前景的方向。模型创造的工具必将更贴合模型使用的场景，不仅便于模型使用，也有利于模型学习。



工具学习作为连接语言模型和实际应用的桥梁，大有可为。通过自然语言指令使用和创造工具，赋予了语言模型感知、操控外部世界的能力，极大拓宽了其应用的范围和空间。从信息搜索、问答、数据分析到写作、编程、绘画，工具加持下的语言模型无所不能。



当然，工具学习现在还处于起步阶段，要达到成熟完善还有不少挑战：

1. 工具的标准化问题。现在每个工具的接口规范都不尽相同，模型很难统一学习，效率受限。未来需要制定工具的通用规范。
2. 工具的理解深度问题。目前的工具学习还是基于浅层的语义理解，对工具的内在机理缺乏洞察。如何让模型真正理解每一个工具的原理和效用，是一个有待探索的问题。
3. 多模态工具的整合问题。现实任务往往需要处理文字、语音、图像、视频等多种形态的信息。单一模态的工具已经不够用，必须实现多模态工具的无缝衔接，发挥1+1>2的协同效应。
4. 人机协作问题。工具不是万能的，在很多专业领域，人类专家的参与必不可少。如何设计人机协作的机制和接口，让人的专业知识和模型的推理能力高度融合，是实现更强大智能系统的关键。



下一阶段，我们计划围绕几个方向展开研究：一是进一步扩充工具的规模和覆盖面，要将各行各业的实用工具纳入模型学习的范畴。二是深化语言模型对工具的理解，比如通过因果建模、逻辑推理等方法加强模型对工具内在机理的把握。三是在更广泛的场景中实践工具学习范式，用真实世界的需求来检验模型的工具使用能力，并以实际效果为导向来优化模型训练。四是引入更多人机协作的环节，发挥人在回路中的重要作用，用工具学习赋能每一个人。



工具学习代表了语言模型走向真正智能的重要方向。随着模型规模的持续增长，和算力成本的不断下降，我相信这一范式必将得到更广泛的应用。同时它也为认知科学、脑科学研究提供了新的视角。人脑能够灵活运用工具，标志着人类智能的一大进步。机器模仿人脑习得工具使用的机制，想必也能带来人工智能的质的飞跃。让我们共同期待工具学习和认知智能在未来碰撞出更加灿烂的火花!





