> 昨天（0319）在ITPUB上进行了一场关于RAG在实际项目中，如何提升大模型落地效果的技术分享。下面是分享的大概内容。
>



![](https://cdn.nlark.com/yuque/0/2024/png/406504/1710891490344-7332a6a1-4c0f-4bb5-b489-3821de2cf2a6.png)

### 引言
![](https://cdn.nlark.com/yuque/0/2024/png/406504/1710891576419-b0052c06-49d9-4c4a-87da-ca0a88c4e059.png)

在人工智能领域，大型语言模型（LLM）如ChatGPT已经成为我们日常交流和信息处理的重要工具。然而，随着时间的推移，我们对这些模型的期望也在不断提高。为了满足这些期望，研究人员和开发者们一直在探索如何进一步提升LLM的性能。今天，我们将深入探讨一种名为检索增强生成（RAG）的技术，它通过结合检索到的外部信息，来增强LLM生成的响应。



### RAG的基本原理
![](https://cdn.nlark.com/yuque/0/2024/png/406504/1710891591654-28987f8c-6373-4467-9ca2-4260a9c72d6d.png)

RAG的核心思想是将用户输入的信息与从其他来源检索到的附加信息相结合。这个过程包括四个主要步骤：索引、检索、生成和提示。索引是创建一个可以快速检索的数据库；检索是根据用户的输入找到相关信息；生成是根据检索到的信息创建响应；提示则是引导模型生成更加准确和相关的输出。

### 技术挑战
![](https://cdn.nlark.com/yuque/0/2024/png/406504/1710891611239-c93def6a-2b5b-4b9c-803f-cd472dd73fdc.png)

尽管RAG的概念很有前景，但在实践中它面临着几个技术挑战。首先是上下文限制，模型能力限制，以及数据缺陷，这些都可能导致生成的答案质量不佳。此外，用户问题意图不清晰，多模态数据不统一，以及复杂场景下的RAG应用也是当前研究的热点。

### RAG与微调的比较
![](https://cdn.nlark.com/yuque/0/2024/png/406504/1710891628337-df654b71-54ec-4182-8c85-e8d8c0536b4b.png)

RAG和微调是两种不同的方法，它们各有优势和局限性。RAG侧重于信息检索和整合外部知识，适合动态数据环境，但可能需要更多的计算资源。微调则侧重于根据特定语调或术语调整模型行为，可以提供更低的延迟响应，但可能需要频繁重新训练以适应新的知识。

### 方法探索
![](https://cdn.nlark.com/yuque/0/2024/png/406504/1710891644494-7f07e863-b46b-4019-af9d-3d0864a28607.png)

为了克服RAG面临的挑战，研究者们探索了多种方法。这包括用户意图理解和优化，关键词提取，任务定义，扩写纠错，分词去噪，以及历史query分析等。此外，还有small2big、sliding window等技术，以及如何通过迭代检索和自适应检索来提升性能。

### 未来展望
RAG技术的未来充满了可能性。在技术上，我们期待看到更多关于检索评估、生成评估和评估工具的发展。评估基准，如RGB和RECALL，将帮助我们更好地理解和提升RAG的基础能力。同时，我们也希望看到RAG技术在更多实际应用场景中的落地和优化。

### 结语
检索增强生成（RAG）技术为我们提供了一个新的视角，让我们可以更有效地利用外部信息来提升大型语言模型的性能。随着技术的不断进步，我们有理由相信，RAG将在未来的人工智能发展中扮演重要角色。让我们拭目以待，看看这项技术将如何改变我们的世界。





