> 法研杯：[http://cail.cipsc.org.cn/CAIL-dataset.html#cail_2019](http://cail.cipsc.org.cn/CAIL-dataset.html#cail_2019)
>

## 目的
+ 实验验证大模型在特定任务上是否强于传统AI模型
+ 制定大模型垂直领域落地应用的具体实现方案

## 整体结论
> 通过调研传统方法在法律任务上效果，预估大模型在法律领域任务的可行性和效果。以下内容以法律案例文本匹配任务作为切入点分析。
>

ChatGPT之前大模型指代的是Bert、GPT1/2、T5等模型，对模型的使用方式是具体任务上的fine-tuning微调。相较于当前的ChatGLM、LLaMa等大模型，微调方式变为指令微调（P-tuning）

+ 相比Fine-tuning核心在输入和特征构建的微调方式，P-tuning的微调关键在于Instruction和Prompt的书写
+ 当前的LLMs（ChatGLM、LLaMa等）相较于Bert、GPT2、T5等模型规模增加了多倍，微调的代价也增加了

通过对法研杯案件匹配任务的调研，有如下的观察和结论：

1. Bert相较于CNN、LSTM等模型，引入了预训练和更大的模型规模，具备了更强的特征提取能力，在案件匹配任务上实际效果更好，那么理论上同样基于微调后的LLMs（ChatGLM、LLaMa）等在该任务上效果要优于Bert模型。
    1. 考虑调研方案普遍采用了模型集成，LLMs模型集成的成本和代价更大，对LLMs的模型不考虑模型集成。
    2. P-tuning的微调相较于Fine-tuning，指令（Instruction）和提示（Prompt）的书写直接影响微调效果
2. 基于专家经验、人工构建的特征能够一定程度提升模型的效果，调研方案中无论是pattern抽取特定信息还是模型隐层的状态拼接，都对模型更准确理解文档的含义提供了帮助。在LLMs解决该问题时，可能需要将专家经验以提升（Prompt）的形式输入LLMs中。
3. 传统解决方案的可迁移性较差，每个模型通常只解决单一任务问题，对单一任务数据更加拟合。LLMs通过预训练对大多数任务具有适配性，单一垂直领域问题效果在没有微调或者微调不足的情况下相比之前的方案提升可能有限。

通用场景下的LLMs模型在特定的垂直领域问题上，效果不一定优于传统的解决方案（基于集成学习的Bert等），借助微调、人工特征工程等Bert、CNN等也可以具备较好的效果，但时间和人力成本会比较高。

从传统解决方案看，随着整体解决方案规模的增加（模型数量、模型规模），模型的效果是提升的。那么，我们希望LLMs在少量时间和人工成本下，在特定任务上远优于传统的解决方案，就需要考虑LLMs定位和要解决的问题有哪些，这决定了微调过程中指令和提示的书写内容，从而直接影响LLMs效果。

## 法研杯2019任务概要
2019CAIL竞赛包含三个任务：阅读理解、要素提取和相似案例匹配

+ 阅读理解任务：【生成任务】篇章片段抽取型阅读理解比赛（Span-Extraction Machine Reading Comprehension）。
+ 要素提取任务：【多标签分类任务】给定司法文书中的相关段落，系统需针对文书中每个句子进行判断，识别其中的关键案情要素，并根据领域专家设计的案情要素体系进行分类。
+ **相似案例匹配：【匹配任务】**是一个法律文书相似度计算问题，所有文书来自裁判文书网的真实借贷纠纷案件。问题形式：给定三个文书（A, B, C），预测A与B, C中的哪一个更为相似，数据中明确给定A和B的相似度大于A和C的相似度。评价指标：准确率。

以相似案例匹配任务作为分析的切入点，分析已有方案在该任务上的解决思路，从而对比大模型在该任务上可行性和可能的效果预估。

## 相似案例匹配问题分析
> <font style="color:rgb(65, 65, 65);">比赛分三个阶段。第一阶段训练数据有500组三元文书，用(A, B, C)表示一条数据中的三篇文书。每条数据中A与B的相似度大于A与C的相似度。第二阶段有5102组训练数据，第三阶段为封闭式评测阶段。</font>
>
> + <font style="color:rgb(65, 65, 65);">官方提供了第二阶段5102条数据集</font>
>

### <font style="color:rgb(65, 65, 65);">问题分析</font>
> <font style="color:rgb(31, 35, 40);">文件的每一行对应一组数据，且每行的格式都为一个json数据。对于每份数据，我们用$(A,B,C)$来代表该组数据，其中$(A,B,C)$均对应某一篇文书。数据$A$与$B$的相似度是大于$A$与$B$的相似度的，即$sim(A,B)>sim(A,C)$。</font>
>
> <font style="color:rgb(31, 35, 40);">评估过程：评估数据格式和训练数据格式一致，</font>但不保证$sim(A,B)>sim(A,C)$。如果有$sim(A,B)>sim(A,C)$则选手需要输出B，否则输出C。
>

在该场景下，存在的一些任务难点包括：

1. 文本长度过长，单独的法律文本平均长度分别为A（678）、B（675）、C（676），对于Bert等之前的大模型而言超过512的限制，输入内容存在一定的不完整。对当前GLM和LLaMa模型而言是可接受的，当前大模型接受长度如下：
    1. ChatGLM使用相对位置编码，训练预测token不建议超过2048
    2. LLaMa的训练token长度为2048
    3. Chinese-LLaMa的token长度为512

> GPT系列中token的计算和中文字符串长度计算存在一定差异，<font style="color:rgb(15, 20, 25);">英文单词比token大概是1.35 . 中文的话, GPT3 比例大概是2.1 (单中文字~2.1 token) </font>
>
> + 测试网址：[https://platform.openai.com/tokenizer](https://platform.openai.com/tokenizer)
>

2. 法律文本存在大量重复结构信息，在所有数据中，结构相似度非常高，在专业术语方面，存在陈词逻辑的相似性。需要结合先验知识进行特征的抽取。直接学习可能会存在重复度非常高的问题。
    1. 开篇为原告基本信息：姓名、性别、年月、民族、职业
    2. 然后承接委托诉讼代理人基本信息、被告基本信息
    3. 然后是原告的诉讼要求和内容陈述
    4. 最后是法院陈词总结部分。
3. 案件相似定义，指的是案情的相似，即原告诉求内容的相似性，是一种语义层面的相似而非简单的文本相似，存在一定的专业知识理解。例如生活借款纠纷、生意合作借款纠纷等

这对上述的难点，在比赛Top3的解决方案如下：

### [Top1方案](https://github.com/GuidoPaul/CAIL2019/tree/master) (准确率)
![](https://cdn.nlark.com/yuque/0/2023/png/406504/1684118034891-01d2430a-240b-48a3-a631-e3e7709c6e4d.png)

1. 整体解决方案采用多模型融合思路，以Bert为base模型，通过多种方法进行特征提取后，生成最终模型的预测结果
2. 模型base的框架采用排序Rank的思路，计算文档与正样本的预测值是否大于文档与负样本的预测值

![](https://cdn.nlark.com/yuque/0/2023/png/406504/1684118145666-87c13863-b9d9-465d-bcbf-1b96b9cbe636.png)

3. 在上述Rank的思路下，对特征的提取思路包括：提取最后三层或两层中间状态作为模型额外特征；使用TF-IDF等思路提取额外特征；以及Bert的状态信息和其他模型串联预测

该方案将任务看做是一种排序，要求与正样本距离小于与负样本距离；预测过程中进行了模型的集成，从不同粒度对原始文档进行了特征提取，最终结果是所有集成模型集合的和。该方法在竞赛中表现良好，考虑实际应用场景下，存在如下几点问题：

1. Bert的512输入长度限制下，该方案是后向截取方法：从后往前截取，超过长度的进行舍弃；是因为通过分析数据后前面的原告、被告、代理人等信息是可以忽略的。但针对不可忽略的长文本情况下，该方法可能效果会出现下降。
2. 模型集成在不考虑速度、时效性等离线场景是可以的，如果存在速度的要求，多模型的集成通常会带来响应速度的下降。
3. 可迁移性或通用性上有限制；上述的特征工程、模型集成以及loss的专门优化，都是针对上述单一场景设计的，在比赛其他两个赛道或者相同类型任务但数据不同的任务上，效果可能也会下降。

### [Top2方案](https://github.com/padeoe/cail2019)
![](https://github.com/padeoe/cail2019/raw/master/doc/models.jpg)

<font style="color:rgb(31, 35, 40);">模型是一个孪生网络的结构，使用了两个共享权重的 BERT 模型，分别将 AB 和 AC 输入 BERT，将对应的 [CLS] 取出，并做一个相减运算，最后拼接一个线性层输出后进行分类，使用交叉熵计算二分类损失。</font>

> <font style="color:rgb(31, 35, 40);">模型可以这么理解，通过模型监督任务的设计， BERT 输出的 </font><font style="color:rgb(31, 35, 40);">[CLS]</font><font style="color:rgb(31, 35, 40);"> 可以学习出每次输入的两个句子在各种不同维度上的相似度情况，因此 Cab、Cac分别表示了 AB 的相似度，AC 的相似度，最终将两者相减，就可以对比出在各种不同维度上 AB 相似度更高还是 AC 相似度更高，最终线性层则是对这些维度进行加权，得出一个综合的相似度判定。</font>
>

<font style="color:rgb(31, 35, 40);">在该方案中，同时采用了数据增广的方案</font>：反对称增广、自反性增广、启发式增广等获取更多更有效的数据，是模型的训练避免过拟合。

<font style="color:rgb(31, 35, 40);">针对之前提到的文本长度、文本结构难点问题，分别进行了一些尝试和优化：</font>

1. <font style="color:rgb(31, 35, 40);">文本过长问题：分别尝试相对位置编码、不同截断方式、模型特征提取等方法，最终采用的还是后向截断方式，这也证明该截断方法在当前数据上是有效的，文档前部分原告、被告、委托人等背景信息对相似性判断不起作用</font>
2. <font style="color:rgb(31, 35, 40);">法律文本是一种特殊的文本，尤其是本问题中遇到的借贷纠纷文本，其中的数字如金额，利率，日期均具有重要语义。同时，法律文本是有结构的，他一般分为原被告-诉求-事实-本院认定这4个段落，直接训练神经网络难以识别到这些数字和结构特征。一种可能的想法就是通过特征工程提取出这些数字特征和神经网络相结合以提升效果。 通过简单的正则表达式，我们提取了案件中的金额，利率，案发时间，各段落长度等特征。</font>

<font style="color:rgb(31, 35, 40);">该方案将匹配问题转化为Rank问题，计算AB与AC相似度分数的高低。在具体实验方案上，以Bert作为base模型。相比Top1的方案，该方案在速度上有提升、工作量相对较小，最终离线效果有一定差距。</font>

### <font style="color:rgb(31, 35, 40);">Top3方案</font>
![](https://cdn.nlark.com/yuque/0/2023/png/406504/1684121275907-d5779759-5e86-4086-93dd-0e98ed022abe.png)

该方案中，利用基本的CNN模型和ESIM模型，计算分别计算模型的相似度，通过交叉验证的方式，获取每次的预测结果，然后利用FC网络实现相似度的计算。整体是集成的思想，模型选择上没有选择通用的大模型，在特征提取上进行了一定的设计：

+ 多层CNN网络提取特征，通过不同size的kernel获取不同的特征；双向LSTM生成交互矩阵，利用多层双向LSTM进行提取，有效的解决了文本长度的限制问题
+ 训练阶段利用交叉验证的想法，对模型不同折数预测结果进行拼接求平均，最终实现模型相似度的计算，有效避免了对特定结构的过拟合学习。

整体方案上，该方法比较简单但有效，通过集成学习思想在轻量的CNN、LSTM等网络结构上实现了不错的效果。

## 匹配任务总结
针对该任务的top3方案，均采用了多个模型进行预测，利用了集成学习的思想，实现了模型特征的有效提取。在模型选择上，大模型（Bert）效果优于传统轻量模型（CNN、LSTM）等。

+ 模型集成在一定程度能够提升任务的效果，本任务中，第一阶段只有500条数据，使用过重的模型集成方案存在一定的过拟合数据风险，泛化性和可迁移性受限。
+ 模型选择上从效果来看，大模型优于传统轻量模型。本任务数据具有特殊性（数据之间存在结构相同，存在专业术语），对于特征的有效提取是提升任务效果的重点，Bert等大模型在特征提取上还是好于CNN、LSTM等。如果叠加上专家经验等先验知识，可能效果还会有一定的提升。

通过上述三个方案的分析，我们可以看出，在长文本、数量少（一阶段500条）、领域性强等难点下，解决文本匹配的有效思路和方法如下：

1. 设计有效的特征提取方法，不论是利用正则等pattern还是模型，特征的有效性是最终效果的关键。大模型相交传统模型（CNN）在特征提取上效果略优。
2. 在不考虑速度和响应时间约束下，模型的集成和堆叠，在一定范围内对任务效果是正向的。不同模型或相同模型的不同输出形式，表征了数据不同维度的特征。
3. 数据增广能够带来一定的收益，且在数据稀少情况下避免模型的过拟合。



