大型语言模型（LLMs）以其令人印象深刻的生成类人文本、回答问题甚至编写代码的能力，在全球范围内引起了轰动。然而，了解这些人工智能奇迹并非没有局限性至关重要。一个常被忽视的关键方面是LLMs如何处理记忆以及“上下文窗口”的概念。

LLMs不是基于规则的系统，而是更类似于人脑的功能，依赖于大量相互关联的数据点和上下文来生成响应。这就要求从发布命令转变为通过提示引导LLM，并将其响应理解为关联输出。

普遍存在一个误解，即大型语言模型（LLMs）是无所不能的巫师，拥有无限的记忆力。

### 全知的误解
想象一下，如果你能记住你学过的一切，每一条琐事，每一个被遗忘的生日，每一次尴尬的对话。听起来像超能力，对吧？LLMs常被认为拥有这种超人类的能力，将所有人类知识都放在他们的比喻口袋里。但关键点在于——它们的运作更像是一个健忘的天才，而不是一个无所不知的神。

#### 上下文窗口：LLM的认知透镜
将上下文窗口视为LLM的RAM（随机存取存储器），或者对于不太懂技术的人来说，是一个非常短期的记忆。这是事情变得有趣的地方。尽管可以访问到大量信息的海洋（为了简单起见，我们称之为它们的永久记忆），LLMs在任何给定时刻只能将这个海洋中的一小杯水放在它们的临时记忆中。

#### 上下文窗口的运作
本质上，上下文窗口充当LLM的“思维空间”。在这里，模型扫描、识别并利用提示中的关键词来创建一个相关信息的地图。然后，这个地图被统计上与模型庞大的潜在知识库关联起来，使得特定实体和关系的激活成为可能。通过这个过程，LLM构建出不仅相关而且与潜在查询复杂相连的响应。

#### 上下文窗口的关键特征：
+ 关键词识别：LLM首先识别提示中的关键关键词，作为进一步探索的锚点。
+ 映射和关联：通过基于这些关键词开发地图，LLM统计上将新发现与其已有的知识库关联起来。
+ 实体激活：这个过程允许激活特定实体及其关系，这对于构建连贯和相关的响应至关重要。

### 让LLM“思考”的重要性
#### 给予LLM处理空间
为了LLMs生成细致和高质量的输出，至关重要的是给予它们通过上下文窗口“思考”的机会。这种思考过程不仅仅是匹配关键词到数据库条目；它要求模型利用其庞大的知识库，并理解语言的复杂性和微妙性。

#### 受限思考的后果：
+ 缺乏细微差别：如果没有足够的思考空间，LLM的响应可能缺乏深度，无法捕捉更复杂查询的本质。
+ 次优结果：生成的文本质量可能会受到影响，导致答案虽然正确，但可能不是最佳或最相关的。

#### 为什么这很重要
那么，为什么这很重要？为了让LLMs给出最细致和具体的响应，它们需要从广阔的海洋（上下文窗口）中提取相关信息。然而，它们面临一个限制——它们不能同时提取构建细致响应所需的所有主要和次要信息。这就像试图解决一个复杂的数学问题，但每次只能看到一个方程的一部分。

### 理解核心问题
#### 沟通脱节
许多用户挫败的核心是一个信息交换过程中的根本脱节。用户可能没有提供足够的上下文、关键词或示例，这些都是LLM生成相关和精确输出的关键。这种缺乏详细输入可能导致输出虽然技术上正确，但可能不符合用户的需求或期望，从而滋生不满的循环。

#### 制定解决方案
1. 掌握提示的艺术
    - 清晰简洁的解释：从简洁明了的请求开始。清晰的提示确保LLM对你的需求有坚实的理解。
    - 丰富的例子：在提示中包含例子可以更有效地引导LLM，展示你寻求的响应或解决方案类型。
    - 战略性关键词放置：深思熟虑地包含关键词可以引导LLM的思考过程，确保更有针对性和有效地探索其知识库。
    - 鼓励全面思考：通过提出开放式问题，允许LLM在其上下文窗口内探索各种实体和关系，刺激更深层次的处理。
2. 拥抱上下文丰富的输入
    - 提供全面的上下文：不要害怕提供详细的背景或框架来围绕你的查询。你提供的上下文越多，LLM就能更好地定制其响应以满足你的要求。
3. 人性化与LLMs的互动
    - 拟人化以获得更好的对齐：将LLMs视为具有伪感知能力，可以帮助制定对模型更直观的提示，从而产生更符合人类推理的响应。
4. 利用全面理解的力量
    - 多学科整合：利用LLM整合来自不同领域知识的能力，以获得考虑多重视角的综合答案。
5. 激发类似直觉的响应
    - 间接提示：使用间接接近主题的提示，鼓励LLM“读懂字里行间”并提供类似人类直觉的洞察力。
6. 通过提示工程进行改进
    - 迭代精炼：不要犹豫根据你收到的响应来精炼和调整你的提示。这个过程有助于找到最有效地传达你需求的方式。
    - 控制上下文调节：尝试调整你提供的上下文的数量和类型，为每种特定类型的查询找到最佳点。

### 变通方法：思维链和类似方法
#### 利用思维链获得更深入的洞察力
##### 思维链的本质
思维链方法类似于引导LLM逐步进行认知旅程，以到达细致的理解和响应。它涉及以模仿人类解决问题过程的方式构建提示，引导模型在通往结论的过程中“思考”。这种方法在初始提示可能没有提供所有必要上下文或具体信息的情况下特别有效。

#### 思维链方法的关键好处：
+ 提高准确性：通过将查询分解为一系列逻辑步骤，LLMs可以提供更准确的答案，特别是对于复杂问题。
+ 增强上下文理解：CoT鼓励模型考虑额外的上下文，导致响应更加相关和有洞察力。
+ 促进复杂问题解决：这种方法对于解决多方面的问题非常有价值，允许模型依次解决每个组成部分。

#### 在你的查询中实施思维链
1. 策略性地构建你的提示：
    - 从清晰、简洁地介绍主题或问题开始。
    - 接着是一系列逻辑步骤或问题，引导LLM朝着期望的结论前进。
2. 鼓励顺序思考：
    - 将每个步骤构建为一个基于前一个响应的迷你提示，鼓励LLM发展其推理线索。
    - 确保每个步骤都清晰，并有助于解决整体查询。
3. 利用例子以增加清晰度：
    - 提供例子来说明每一步你寻求的推理或答案类型。
    - 例子作为路标，帮助引导LLM朝正确的方向前进。

### 参考书籍的类比
想象一下，你有大量的参考书来写一篇文章，但你一次只能打开一本书。思维链方法类似于这个过程，允许LLMs“咨询”不同的“书籍”（信息片段），依次构建一个全面和连贯的响应。这种方法不仅规避了有限上下文窗口所带来的限制，还通过将不同的信息片段编织成一个整体，丰富了输出的质量。

### 平衡期望和理解
作为用户和开发者，我们在与LLMs互动时保持现实的期望至关重要。虽然这些AI系统非常强大，但它们并非无懈可击。通过理解上下文窗口和记忆限制所带来的挑战，我们可以更好地欣赏创造真正智能和上下文感知AI的挑战。

随着研究的进展和新技术的出现，我们可以期待LLMs能更有效地导航它们庞大的知识库，并提供越来越细致和准确的响应。在此之前，让我们在记住它们局限性的同时，庆祝这些AI奇迹的非凡成就。

### 底线
尽管LLMs的能力令人敬畏，但它们并非许多人认为的全知数字实体。它们的“智能”，虽然广阔，但受到临时记忆限制的约束。理解这些局限性，不是作为缺陷，而是作为技术进步持续旅程中的挑战，至关重要。

