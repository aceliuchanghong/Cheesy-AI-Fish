随着自然语言处理（NLP）和生成性人工智能（Generative AI）领域的最新进展，RAG（检索增强生成，Retrieval Augmented Generation）的引入有望推动现有技术如ChatGPT的进步，它通过结合基于检索的模型和序列到序列的架构来提升大型语言模型（LLM）生成响应的质量。

然而，由于RAG存在一些不足之处，需要进行升级以实现其潜在的增强功能，这就是RAG Fusion发挥作用的地方。让我们来理解RAG和RAG Fusion，它们都围绕着使用生成性AI通过向量搜索来革新搜索和信息检索，以提供基于真实数据的直接答案。

## RAG：理解检索增强生成
检索增强生成是一种结合了超大型预训练语言模型和外部检索或搜索机制的方法。RAG的核心思想是通过允许生成性AI模型在生成过程中从大量文档中提取信息，来增强其能力。

要理解RAG如何增强LLM的提示-响应生成的可信度，这里是它的工作原理：

1.  检索步骤 — 当用户输入提示或向生成性AI模型提问时，RAG模型会从大量文档中检索出一组相关文档或段落。这通常是通过基于文档和查询的密集向量表示的检索机制实现的。 
2.  生成步骤 — 一旦检索到相关段落，它们就会被提供给生成性AI模型以及原始提示或查询。模型利用其预训练的知识以及从段落中检索到的信息生成响应。 

![](https://cdn.nlark.com/yuque/0/2024/png/406504/1708328716686-195df02f-85e1-43bb-8579-487a722e8454.png)

 上述图像阐明了RAG模型的机制，重要的是要注意，增强提示的外部数据可以来自多个数据源，如文档库、数据库或API。然而，关键步骤是将文档转换成一种兼容格式以进行相关性搜索。

文档集合或知识库以及用户提交的查询通过嵌入语言模型转换为数值表示，以使格式兼容。嵌入是一种将文本在向量空间中赋予数值表示的过程。RAG模型架构在知识库的向量内比较用户查询的嵌入，并检索出具有相似上下文的文档。下图代表了最基本的检索增强生成模型架构。

![](https://cdn.nlark.com/yuque/0/2024/png/406504/1708328746620-7cc833e0-229e-4c2c-8617-741a99e35dbd.png)

## RAG的优势
与孤立工作的大型语言模型相比，RAG在生成最佳提示响应方面提供了显著的优势。以下是检索增强生成的一些好处：

+ 提供最新和最准确信息的高质量响应。
+ 减少计算和存储需求。
+ 减少幻觉（即生成不真实或不准确的信息）。

## RAG的局限性
尽管有诸多优势，但RAG也存在一些挑战，需要解决以确保提供符合伦理和事实的答案：

+ RAG依赖外部知识，可能会因为错误信息而产生不准确的结果。
+ 从外部资源获取数据可能会引发关于敏感数据的隐私和安全问题；然而，通过使用文档级访问，可以限制对特定文档的访问。
+ 当前搜索技术，如基于检索的词汇和向量搜索技术，限制了RAG模型。
+ 毫无疑问，人类在将所需信息输入搜索引擎时效率不高，拼写错误、模糊查询和有限的词汇量导致错过了搜索结果之外的大量信息。
+ 线性范式缺乏深入理解人类查询本质的效率。线性方法无法捕捉复杂的用户查询，导致搜索结果效率低下。

## RAG Fusion
RAG Fusion（Raudaschl, 2023）提供了解决RAG模型局限性的最佳解决方案。通过生成多个用户查询并使用策略如RRF（Reciprocal Rank Fusion）对结果进行排名，RAG Fusion可以轻松克服人类搜索的低效和搜索简化带来的挑战。改进的技术弥合了用户查询与其意图之间的差距。

RAG Fusion技术使用编程语言、向量搜索数据库（如Elasticsearch或Pinecone）、以及大型LLM（如ChatGPT）进行查询生成和结果重排。RAG Fusion的核心概念是在不依赖更先进的LLM的情况下，理解复杂人类查询的细微差别。RAG Fusion通过生成多个查询并重排结果，利用RRF和自定义向量分数加权来实现全面和准确的搜索结果。

## 为什么选择RAG Fusion？
RAG Fusion背后的中心概念是理解复杂的人类查询，而无需更先进的LLM。RAG Fusion通过生成多个查询并重排结果来轻松应对RAG的固有约束。此外，它利用RRF和自定义向量分数加权，以实现全面和准确的搜索结果。

### RAG Fusion的方法论
RAG Fusion使用与RAG相同的技术：Python语言、向量搜索数据库（如Elasticsearch或Pinecone）以及大型LLM（如ChatGPT）。RAG Fusion的工作方法与RAG相同；然而，还有一些额外的步骤，如查询生成和结果重排，以改革响应质量。

它的工作原理如下：

+ 通过LLM将用户的查询翻译成相似但不同的查询，执行查询复制。
+ 对原始查询及其生成的类似查询进行向量搜索，实现多个查询生成。
+ 使用RRF结合和精炼所有查询结果。
+ 选择新查询的所有顶部结果，为LLM提供足够的材料，以考虑所有查询和重排的结果列表来创建输出响应。

### 理解RAG Fusion背后的复杂性 — RRF
RRF，即排名融合，是一种围绕结合多个搜索结果以产生单一、统一排名的技术。单个查询无法涵盖用户查询的所有方面，可能过于狭窄，无法提供全面结果；这就是为什么必须考虑所有不同元素并提供精心策划的答案的多个查询生成。

RRF通过结合不同搜索查询的排名，增加了所有相关文档出现在最终结果中的机会。此外，它不依赖于搜索引擎分配的绝对分数，而是依赖于相对排名，因此结合具有不同分数尺度或分布的结果变得实际。

![](https://cdn.nlark.com/yuque/0/2024/png/406504/1708328866054-2a6904ac-a41d-4bef-97cf-119d0462a597.png)

 Raudaschl在2023年提供的上述图像展示了互惠排名融合（Reciprocal Rank Fusion, RRF）的位置重排系统算法。根据图像，`reciprocal_rank_fusion`函数接收一个搜索结果的字典，其中每个键（key）代表一个查询，对应的值（value）是一个按与查询相似度排名的文档ID列表。RRF算法根据文档在不同列表中的排名计算每个文档的新分数，并将它们排序以创建最终的重排结果。

这种方法通过考虑文档在多个查询结果中的排名情况，而不是仅仅依赖于单一查询的结果，从而提高了搜索结果的整体质量和相关性。通过这种方式，RRF能够更全面地理解用户的需求，并提供更准确的信息。这种方法特别适用于处理那些可能需要多个相关查询来完全理解的复杂用户查询。

![](https://cdn.nlark.com/yuque/0/2024/png/406504/1708328879637-4d4daa65-9910-4b4c-b09c-16cf4ab4c8b1.png)

 RRF根据一个简单的评分公式对文档进行排序。在上述公式中，集合D代表要排序的给定文档，集合R是每个文档的排名，每个排名都是1到|D|的排列，k设置为60。

计算融合分数后，函数根据分数将文档按降序排序，并返回最终的重排列表。

为了确保多个查询不会偏离用户的意图，模型被指导在提示工程中给予原始查询比随后的多个查询更多的权重。重排的文档和查询被提供给LLM，它类似于RAG，通过请求响应或摘要来产生生成性输出。

## RAG Fusion的优势
以下是RAG Fusion相比RAG模型提供的更多好处：

+ 通过增强搜索深度，提升了源材料的质量。
+ 它提供了一个全面的输出，与用户的输入查询产生共鸣，回应他们多方面的信息需求。
+ 它通过从多样化的文档中提取信息，创建了一个组织良好且有洞察力的答案。
+ 它执行隐式的拼写和语法检查，并优化搜索查询以提供准确的搜索结果。
+ 该系统充当语言催化剂，将复杂查询分解为向量搜索可管理的小片段。
+ 它增加了发现用户未意图但有帮助的信息的可能性。

### 可能的局限性
每件强大的事物或算法都有一套局限性，RAG Fusion也不例外。它只有两个缺点：

+ RAG Fusion模型通过生成多个查询来达到查询深度的能力，可能会提供一个过于详细的答案。
+ 多查询输入和多样化的文档集合可能会给语言模型的上下文窗口带来压力，导致输出不够连贯。
+ 多个查询的变化，可能带来错误的累计和传递。

## 总结
将RAG Fusion模型与LLM（大型语言模型）集成是一种创新的方法，用于改进提示响应并提供可信的引用。RAG Fusion轻松克服了RAG模型的局限性并提升了其性能。Adrian H. Raudaschl提出的RAG Fusion理念仍处于实验阶段，旨在使搜索更加智能和上下文感知，帮助获取手动或使用传统LLM无法找到的更丰富、更深层次的信息。此外，RAG Fusion也伴随着一些伦理问题，因为为了改善结果而操纵用户的原始查询可能会踏入道德灰色地带。这就是为什么保持AI模型的透明度，并控制人们在AI中投入多少以及付出的代价至关重要。

