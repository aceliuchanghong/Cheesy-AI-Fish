![](https://cdn.nlark.com/yuque/0/2023/png/406504/1689212047508-dc1797a4-e474-44f5-b04a-9bead388b047.png)

人工智能 (AI) 在改变我们的生活、工作以及与技术互动的方式方面取得了令人难以置信的进步。最近，取得重大进展的领域是大型语言模型 (LLM) 的开发，例如[GPT-3](https://arxiv.org/abs/2005.14165)、[ChatGPT](https://openai.com/blog/chatgpt)和[GPT-4](https://cdn.openai.com/papers/gpt-4.pdf)。这些模型能够以令人印象深刻的准确性执行语言翻译、文本摘要和问答等任务。

虽然很难忽视LLMs不断增加的模型规模，但同样重要的是要认识到它们的成功很大程度上归功于用于训练它们的大量高质量数据。

在本文中，我们将从以数据为中心的人工智能角度概述LLMs的最新进展，借鉴我们最近的调查论文 [1,2] 以及GitHub上相应技术资源的见解。特别是，我们将通过以数据为中心的人工智能（数据科学界中一个不断发展的概念）的视角来仔细研究 GPT 模型。我们将通过讨论三个以数据为中心的 AI 目标来解开 GPT 模型背后以数据为中心的 AI 概念：训练数据开发、推理数据开发和数据维护。

## 大型语言模型 (LLM) 和 GPT 模型
LLM 是一种自然语言处理模型，经过训练可以在上下文中推断单词。例如，LLM 最基本的功能是在给定上下文的情况下预测缺失的标记。为此，LLMs经过训练，可以从海量数据中预测每个候选令牌的概率。

![](https://cdn.nlark.com/yuque/0/2023/png/406504/1689212047426-efce3b92-0474-4e44-89a4-968307287c24.png)

使用 LLM 在上下文中预测丢失标记的概率的说明性示例。图片由作者提供。

GPT模型是指OpenAI创建的一系列LLM，例如[GPT-1](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)、[GPT-2](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)、[GPT-3](https://arxiv.org/abs/2005.14165)、[InstructGPT](https://arxiv.org/abs/2203.02155)和[ChatGPT/GPT-4。](https://cdn.openai.com/papers/gpt-4.pdf)就像其他LLMs一样，GPT 模型的架构很大程度上基于[Transformer](https://arxiv.org/abs/1706.03762)，它使用文本和位置嵌入作为输入，并使用注意力层来建模标记的关系。

![](https://cdn.nlark.com/yuque/0/2023/png/406504/1689212047591-3250253f-e994-4064-8ee8-23932dd582d6.png)

后来的 GPT 模型使用与 GPT-1 类似的架构，除了使用更多的模型参数、更多的层数、更大的上下文长度、隐藏层大小等。

![](https://cdn.nlark.com/yuque/0/2023/png/406504/1689212048216-917f468b-4e27-4f2c-91e5-f27ad4c37ce7.png)

## 什么是以数据为中心的人工智能？
[以数据为中心的人工智能](https://github.com/daochenzha/data-centric-AI)是一种新兴的思考如何构建人工智能系统的新方式。它是由人工智能先驱吴恩达（Andrew Ng）倡导的。

> 以数据为中心的人工智能是一门系统地设计用于构建人工智能系统的数据的学科。— 吴恩达
>

过去，我们主要专注于在数据基本不变的情况下创建更好的模型（以模型为中心的人工智能）。然而，这种方法可能会在现实世界中导致问题，因为它没有考虑数据中可能出现的不同问题，例如不准确的标签、重复和偏差。因此，“过度拟合”数据集不一定会带来更好的模型行为。

相比之下，以数据为中心的人工智能专注于提高用于构建人工智能系统的数据的质量和数量。这意味着注意力集中在数据本身，模型相对更加固定。采用以数据为中心的方法开发人工智能系统在现实场景中具有更大的潜力，因为用于训练的数据最终决定了模型的最大能力。

需要注意的是，“以数据为中心”与“数据驱动”有着本质的区别，后者只强调用数据来指导人工智能的开发，通常仍然以开发模型而不是工程数据为中心。

![](https://cdn.nlark.com/yuque/0/2023/png/406504/1689227730229-08bf34c3-19fa-40fe-be54-4d7a057a4731.png)

以数据[为中心的人工智能框架](https://github.com/daochenzha/data-centric-AI)包含三个目标：

+ 训练数据开发就是收集和产生丰富的、高质量的数据来支持机器学习模型的训练。
+ 推理数据开发是为了创建新颖的评估集，这些评估集可以提供对模型更精细的见解或通过工程数据输入触发模型的特定功能。
+ 数据维护是为了保证动态环境下数据的质量和可靠性。数据维护至关重要，因为现实世界中的数据不是一次性创建的，而是需要持续维护。

![](https://cdn.nlark.com/yuque/0/2023/png/406504/1689212048422-36eb7be1-605e-41d5-a187-776e440b0650.png)

## 为什么以数据为中心的人工智能使 GPT 模型取得成功
几个月前，Yann LeCun 在推特上表示 ChatGPT 并不是什么新鲜事。事实上，ChatGPT 和 GPT-4 中使用的所有技术（Transformers、来自人类反馈的强化学习等）根本就不是什么新鲜事。然而，他们确实取得了以前模型无法做到的令人难以置信的结果。那么，他们成功的动力是什么？

培训数据开发。通过更好的数据收集、数据标记和数据准备策略，用于训练 GPT 模型的数据的数量和质量显着增加。

+ GPT-1： [BooksCorpus 数据集](https://huggingface.co/datasets/bookcorpus)用于训练。该数据集包含 4629.00 MB 的原始文本，涵盖冒险、奇幻和浪漫等一系列类型的书籍。  
-以数据为中心的人工智能策略：无。  
-结果：在该数据集上使用 GPT-1 可以通过微调提高下游任务的性能。
+ GPT-2： 训练时使用[WebText 。](https://paperswithcode.com/dataset/webtext)这是 OpenAI 中的内部数据集，通过从 Reddit 抓取出站链接创建。  
-以数据为中心的人工智能策略： (1) 仅使用 Reddit 的出站链接来管理/过滤数据，该链接至少收到 3 个业力。(2)使用[Dragnet](https://dl.acm.org/doi/abs/10.1145/2487788.2487828)和[Newspaper](https://github.com/codelucas/newspaper)工具提取干净的内容。(3) 采用去重和其他一些基于启发式的清理（论文中未提及的细节）  
-结果：过滤后获得 40 GB 的文本。GPT-2 无需微调即可实现强大的零样本结果。
+ GPT-3： GPT-3的训练主要基于[Common Crawl](https://commoncrawl.org/the-data/)。  
-以数据为中心的人工智能策略： （1）训练分类器，根据每个文档与高质量文档代理 WebText 的相似度过滤掉低质量文档。（2）利用Spark的MinHashLSH对文档进行模糊去重。(3) 使用 WebText、书籍语料库和维基百科扩充数据。  
- 结果： 45TB明文过滤后得到570GB文本（本次质量过滤只选择了1.27%的数据）。GPT-3 在零样本设置中显着优于 GPT-2。
+ InstructGPT：让人类评估答案来调整 GPT-3，使其能够更好地符合人类的期望。他们为标注者设计了测试，只有通过测试的人才有资格进行标注。他们甚至设计了一项调查，以确保注释者享受注释过程。  
-以数据为中心的人工智能策略： （1）使用人类提供的提示答案来通过监督训练来调整模型。(2) 收集比较数据来训练奖励模型，然后使用该奖励模型通过人类反馈的强化学习（RLHF）来调整 GPT-3。  
- 结果： InstructGPT 显示出更好的真实性和更少的偏见，即更好的一致性。
+ ChatGPT/GPT-4： OpenAI 未透露详细信息。但众所周知，ChatGPT/GPT-4 很大程度上遵循了之前 GPT 模型的设计，并且他们仍然使用 RLHF 来调整模型（可能具有更多、更高质量的数据/标签）。人们普遍认为，GPT-4 使用了更大的数据集，因为模型权重有所增加。

推理数据开发。由于最近的 GPT 模型已经足够强大，我们可以通过在模型固定的情况下调整提示（或调整推理数据）来实现各种目标。例如，我们可以通过提供要总结的文本以及“总结它”或“TL;DR”等指令来引导推理过程，从而进行文本摘要。

![](https://cdn.nlark.com/yuque/0/2023/png/406504/1689212048756-60044ffb-55e3-43d9-a784-e4513fb563d3.png)

设计适当的推理提示是一项具有挑战性的任务。它在很大程度上依赖于启发法。一个很好的[调查](https://arxiv.org/abs/2107.13586)总结了不同的提示方法。有时，即使语义相似的提示也可能有非常不同的输出。在这种情况下，可能需要[基于软提示的校准来减少方差。](https://arxiv.org/abs/2303.13035v1)

![](https://cdn.nlark.com/yuque/0/2023/png/406504/1689212049194-e5210d26-caf1-41af-8645-40b73a659a76.png)

LLMs推理数据开发的研究仍处于早期阶段。更多[已在其他任务中使用的推理数据开发技术](https://arxiv.org/abs/2303.10158)可以在不久的将来应用于LLMs。

数据维护。ChatGPT/GPT-4作为商业产品，不仅训练一次，而且不断更新和维护。显然，我们无法知道 OpenAI 之外的数据维护是如何执行的。因此，我们讨论一些通用的以数据为中心的 AI 策略，这些策略很可能用于 GPT 模型：  
- 连续数据收集：当我们使用 ChatGPT/GPT-4 时，我们的提示/反馈可能反过来被 OpenAI 使用进一步推进他们的模型。质量指标和保证策略可能已被设计和实施以在此过程中收集高质量数据。  
- 数据理解工具：可以开发各种工具来可视化和理解用户数据，有助于更好地理解用户的需求并指导未来改进的方向。  
- 高效的数据处理：随着ChatGPT/GPT-4用户数量的快速增长，需要高效的数据管理系统来实现快速数据采集。

![](https://cdn.nlark.com/yuque/0/2023/png/406504/1689212049700-0285f9f4-ee68-4a4e-80d6-6a3f6b21b1af.png)

## 数据科学界可以从这波LLMs浪潮中学到什么？
LLMs的成功彻底改变了人工智能。展望未来，LLMs可以进一步彻底改变数据科学生命周期。我们做出两个预测：

+ 以数据为中心的人工智能变得更加重要。经过多年的研究，模型设计已经非常成熟，尤其是Transformer之后。工程数据成为未来改进人工智能系统的关键（或者可能是唯一）方式。而且，当模型变得足够强大时，我们就不需要在日常工作中训练模型了。相反，我们只需要设计适当的推理数据（即时工程）即可从模型中探查知识。因此，以数据为中心的人工智能的研究和开发将推动未来的进步。
+ LLMs将实现更好的以数据为中心的人工智能解决方案。在LLMs的帮助下，许多繁琐的数据科学工作可以更有效地进行。例如，ChaGPT/GPT-4 已经可以编写可行的代码来处理和清理数据。此外，LLMs甚至可以用来创建培训数据。例如，[最近的工作](https://arxiv.org/abs/2303.04360)表明，使用LLMs生成合成数据可以提高临床文本挖掘中的模型性能。

![](https://cdn.nlark.com/yuque/0/2023/png/406504/1689212049955-1908d517-9ecb-4ed5-9bc0-f6b379fff152.png)

