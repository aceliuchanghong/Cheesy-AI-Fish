> 原文：_HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language Models_
>



![](https://cdn.nlark.com/yuque/0/2024/png/406504/1717630419066-a3a674d9-8674-4b96-82b8-22d5d981aec2.png)

## 引言


在人工智能领域，尤其是自然语言处理（NLP）中，大型语言模型（LLMs）的长期记忆能力一直是研究的热点和难点。人类大脑能够在不断变化的环境中存储和更新大量知识，而现有的LLMs在预训练后整合新经验时仍面临挑战。为了解决这一问题，本文介绍了HippoRAG，这是一种新颖的检索框架，灵感来源于人类长期记忆的海马索引理论，旨在实现更深层次、更高效的知识整合。



## 研究背景与动机


LLMs在处理多跳问题时，如科学文献回顾、法律案例摘要和医学诊断等，需要跨文档整合知识。然而，现有的检索增强生成（RAG）方法在处理这类任务时，由于每次编码新篇章时都是孤立的，因此难以实现跨篇章的知识整合。HippoRAG的提出正是为了克服这一限制，通过模仿人类大脑中新皮层和海马体的不同角色，提高LLMs在多跳问答等任务中的表现。



## HippoRAG方法详解


### 海马记忆索引理论


HippoRAG的设计灵感来源于海马记忆索引理论，该理论认为人类的长期记忆由三个组成部分协同工作：模式分离和模式完成。模式分离确保不同感知经验的表示是独特的，而模式完成则从部分刺激中检索完整的记忆。

![](https://cdn.nlark.com/yuque/0/2024/png/406504/1717630435972-78372271-8885-4ee4-87a5-c2c67faf6544.png)

### 离线索引


HippoRAG的离线索引阶段类似于记忆编码过程，使用一个指令调整的大型语言模型（LLM）作为人工新皮层，通过开放信息提取（OpenIE）从检索语料库中的篇章中提取知识图谱（KG）三元组。这个过程提取出篇章中的显著信号作为离散名词短语，而不是密集的向量表示，从而实现更细粒度的模式分离。



### 在线检索


在线检索阶段，HippoRAG模仿人脑的记忆检索过程。LLM基于新皮层从查询中提取一组显著的命名实体，这些命名实体与KG中的节点基于检索编码器确定的相似性相连。选定的查询节点成为部分线索，HippoRAG的合成海马体执行模式完成，通过个性化PageRank（PPR）算法在KG上运行，使用查询概念作为种子，整合跨篇章的信息进行检索。



### 方法执行步骤


1. **使用LLM进行OpenIE**：从每个篇章中提取名词短语节点和关系边。
2. **构建KG**：将提取的三元组整合成知识图谱，作为人工海马索引。
3. **使用检索编码器**：为KG中的相似但不相同名词短语添加额外的边，帮助下游模式完成。
4. **查询命名实体提取**：从查询中提取命名实体，并由检索编码器编码。
5. **PPR算法**：在KG上运行PPR算法，通过查询节点分布概率，实现上下文相关检索。



## 实验分析


### 实验设置


实验主要在两个具有挑战性的多跳问答基准测试上评估HippoRAG的检索能力：MuSiQue和2WikiMultiHopQA。此外，还包括了HotpotQA数据集，尽管它在多跳推理方面的测试较弱。



### 实验结果
![](https://cdn.nlark.com/yuque/0/2024/png/406504/1717630456192-aef3a174-f89a-48e7-a2e6-8b94dd495a9a.png)

HippoRAG在MuSiQue和2WikiMultiHopQA数据集上的表现显著优于现有RAG方法，提高了约20%。与迭代检索方法IRCoT相比，HippoRAG的单步检索在成本上节省了10-30倍，在速度上快了6-13倍，并且在集成到IRCoT中时还能带来进一步的显著提升。

![](https://cdn.nlark.com/yuque/0/2024/png/406504/1717630465419-0fb7c904-ca9d-4c6b-8d65-ac767e38d1f5.png)

## 创新点与现有方法的差异


HippoRAG的主要创新在于其能够执行单步多跳检索，这在多跳问答中是一个重要的优势。与现有RAG方法相比，HippoRAG通过模仿人类大脑的记忆整合机制，实现了更高效的知识整合。此外，HippoRAG的在线检索过程在成本和速度上都有显著提升，这对于服务最终用户来说是至关重要的。



## 不足与未来工作


尽管HippoRAG在实验中表现出色，但仍存在一些局限性。首先，HippoRAG的所有组件目前都是现成的，没有进行特定的微调。其次，HippoRAG的可扩展性还需要进一步验证。未来的工作可以集中在对HippoRAG组件进行特定微调，改进图搜索算法，并验证其在更大规模数据集上的性能。



## 结论


HippoRAG作为一种新型的LLM长期记忆框架，通过模仿人类大脑的记忆机制，展示了在多跳问答任务中的潜力。其单步多跳检索能力和在线检索效率的提升，使其成为LLM长期记忆的一个有前景的解决方案。尽管存在一些局限性，但HippoRAG为未来LLMs的长期记忆研究提供了新的思路和方法。

