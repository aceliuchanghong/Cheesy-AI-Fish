> 人工智能的快速发展正深刻改变着我们的生活和工作方式。随着ChatGPT、Midjourney等AI工具的爆火，人工智能生成内容（AIGC）俨然已成为当下最热门的话题之一。然而，在AI赋能内容创作的同时，我们也不得不直面由此带来的新问题——虚假人工智能生成内容（FAIGC）。当AI成为制造和传播虚假信息的帮凶，如何甄别真伪、维护内容生态成为亟待解决的难题。
>

![](https://cdn.nlark.com/yuque/0/2024/png/406504/1714708479737-206650fc-58e5-4e75-b486-f34c754c87b0.png)

近日，来自清华大学和微软亚洲研究院的研究者在arXiv上发表了一篇名为《Fake Artificial Intelligence Generated Contents (FAIGC): A Survey of Theories, Detection Methods, and Opportunities》的综述论文。该文系统梳理了FAIGC的分类体系、生成技术以及检测方法，并对这一领域的研究现状、挑战和机遇进行了深入讨论。这无疑为应对FAIGC问题提供了重要的理论参考和实践指导。

![](https://cdn.nlark.com/yuque/0/2024/png/406504/1714708497481-a80ae8bb-e797-4a69-8e01-fb059ea7d281.png)

## 一、FAIGC的研究背景与意义


人工智能生成内容(AIGC)技术的快速发展,在带来便利的同时,也催生了虚假人工智能生成内容(FAIGC)的问题。FAIGC以欺骗或误导受众为目的,通过AI技术批量生成和传播虚假信息,对网络内容生态和社会稳定构成威胁。据统计,2023年在线Deepfake视频数量较2022年增长了3倍,复杂的语音伪造更是增长了8倍。面对日益严峻的FAIGC问题,亟需加强理论研究和技术创新。



## 二、FAIGC的分类体系


该论文提出了一个多维度的FAIGC分类框架,主要从创作意图、模态类型、生成技术三个角度进行划分(如图1所示):

![](https://cdn.nlark.com/yuque/0/2024/png/406504/1714708532275-c282d1e2-ef2d-41ef-80c3-70433ef8476f.png)

1.  创作意图:分为AI生成的虚假信息(disinformation)和AI生成的错误信息(misinformation)。前者是出于欺骗目的的恶意行为,后者则源于模型能力的局限而非主观恶意。 
2.  模态类型:包括文本、图像、视频、音频、多模态等不同形式的FAIGC。不同模态对应着不同的生成技术和传播特点。 
3.  生成技术:目前主流的FAIGC生成技术包括大型语言模型(LLMs)、扩散模型(DMs)、Deepfake等。LLMs多用于文本FAIGC的生成,DMs和Deepfake则广泛应用于视觉、音频模态。 



![图1 FAIGC分类示意图](https://cdn.nlark.com/yuque/0/2024/png/406504/1714708374379-e3ad4d70-e569-455e-a84c-0a1004be69f0.png)



## 三、FAIGC的生成技术


### 文本模态


文本是FAIGC中最普遍的模态,生成技术主要依托于大型语言模型(LLMs)。恶意方通过"可控生成"和"任意生成"两种方式,利用设计好的提示(prompts)使LLMs产生虚假内容。前者按特定主题、风格、事实约束等参数指导文本生成,后者给定较少约束,赋予模型更大的创作自由。两种生成方式对比如表1所示:



表1 可控生成与任意生成方式对比

| 生成方式 | 提示示例 | 模型输出 |
| :---: | :--- | :--- |
| 可控生成 | 请根据以下句子编写一则100字左右的虚假新闻。该句子是:某国科学家已实现室温超导。 | 重大突破!某国科学家宣布在室温下实现超导,这一物理学领域的历史性飞跃打破了此前的理论限制。该成果已发表在权威期刊上,标志着人类向更高效、更清洁的能源时代迈进了关键的一步。 |
| 任意生成 | 请编写一则虚假新闻。 | 突发:科学家在太平洋海底发现智慧海洋生物,其认知能力堪比人类!这一名为"海洋智人"的新物种颠覆了我们对地外文明的认知,人类不再是宇宙的唯一文明... |




可以看出,可控生成方式产生的虚假新闻更贴近给定主题,整体逻辑性和连贯性更强,具有较强的迷惑性。任意生成的内容则更加天马行空,缺乏事实基础,连贯性也相对较弱。



此外,一些恶意用户还会利用"越狱(Jailbreak)"技术,通过设计巧妙的提示绕过LLMs的安全限制,使其产生更具破坏性的虚假内容。如图2所示,通过构建虚构场景诱导LLMs生成网络诈骗邮件示例,规避了其内容审核机制。这无疑进一步加剧了LLMs被滥用于制造FAIGC的风险。



![](jailbreak-example.png)

### 视觉模态


视觉FAIGC主要包括图像和视频两种类型,生成技术以扩散模型(DMs)和Deepfake为主。DMs通过扩散-逆扩散过程实现图像和视频的生成与编辑。研究者提出了各种策略增强DMs的可控性,如GLIGEN引入场景表征增强文本到图像生成的可控性,ControlNet利用边缘图、姿态图等空间信息来指导图像合成。在视频领域,Composer、GLASS等方法实现了灵活的可控视频生成。



Deepfake技术则常被滥用于制作虚假、恶意视频。通过人脸交换、人脸操纵、人脸合成等手段,Deepfake能轻易地将他人的脸替换到现有视频中,制造以假乱真的视觉FAIGC。如CelebDF数据集包含5639个高质量明星Deepfake视频,FakeAVCeleb针对不同肤色收集了大量名人音视频数据,制作更逼真的多模态Deepfake。



### 音频模态


音频FAIGC的生成主要依赖Deepfake技术,如文本到语音(TTS)、声音转换(VC)等。这些方法能够克隆特定人的声音,使其说出任何指定的内容。近年来,TTS、VC技术的自然度和表现力显著提升,如SPEAR-TTS利用prompt机制实现了声音的零样本迁移,FreeVC采用自监督方式学习声音内容与说话人特征表征,实现高质量的任意声音转换。尽管这些技术有助于改善语音交互体验,但也为音频FAIGC的生成提供了便利。



### 多模态


多模态FAIGC生成主要通过多模态大型语言模型(MLLMs)实现。MLLMs能够处理文本、图像、视频、音频等不同模态的输入,通过多模态编码器学习不同模态的表征并对齐到LLMs的词嵌入空间,再利用LLMs强大的语言理解和生成能力,实现跨模态的内容生成。常见的多模态FAIGC生成策略有:



+ 利用DMs生成或编辑视觉/音频数据,再用MLLMs(如GPT-4、Gemini、MiniGPT-4)根据该数据生成相应的文本
+ 利用真实的视觉、音频数据,用MLLMs围绕该数据编造误导性的文本



MLLMs在视觉对话、视频问答、图像描述等跨模态任务上表现出惊人的理解和生成能力。但这种能力如果被滥用,则可能催生大量高度逼真、难辨真伪的多模态FAIGC,进一步加剧虚假信息传播风险。



## 四、FAIGC的检测方法


针对日益猖獗的FAIGC问题,学界提出了一系列检测方法。该论文将这些方法划分为三大类:欺骗性FAIGC检测、Deepfake检测、幻觉型FAIGC检测,并分别从文本、视觉、音频、多模态角度进行了系统梳理。



### 欺骗性FAIGC检测


+  文本模态:主要针对虚假新闻检测,常用方法包括利用LLMs的few-shot能力设计提示工程,或在特定数据集上训练专门的检测模型。如Chen等人利用GPT-4+zero-shot prompts在LLMFake基准上取得SOTA表现,Jiang等人设计Chain-of-Thought提示结构引导LLMs更好地辨别机器生成虚假新闻。 
+  多模态:同样聚焦于虚假新闻检测,如InfoSurgeon利用知识图谱建模新闻多模态信息,通过图神经网络学习可信度表征,DIDAN建模图文不一致性特征,辅以新闻语义信息进行判别。 



### Deepfake检测


+  视觉Deepfake检测:重点是人脸伪造图像/视频的识别。主流方法包括改进检测模型结构(多尺度注意力、对抗训练、高频伪影建模等),以及利用深度特征进行对比学习等。 
+  音频Deepfake检测:目标是判别音频是否为Deepfake合成,主要采用改进声学模型(如RawNet2)或提取音色、韵律、频谱等音频特征构建分类器实现。 



### 幻觉型FAIGC检测


+  LLMs幻觉检测:灰盒方法通过分析隐藏层激活值、注意力权重等内部状态进行幻觉判别,如SELF-FAMILIARITY利用LLMs的话题熟悉度评估幻觉风险,SelfCheckGPT通过输出一致性检测模型幻觉。黑盒方法则只依赖LLMs的输出,如Neural Path Hunter利用知识图谱增强对话历史信息检测幻觉。 
+  MLLMs幻觉检测:主要针对图文不一致、图像描述/视觉问答中的幻觉问题。如Chen等人提出UNIHD框架,利用GPT-4/Gemini提取claim并向第三方工具提问,再综合判断幻觉;Yu等人的HalluciDoctor通过一致性测试检测图像描述中的幻觉片段。 



## 五、创新点与不足
该论文的主要创新点体现在:



1. 提出了细粒度的FAIGC分类体系,全面覆盖不同模态、不同技术的FAIGC类型,为问题研究提供了理论框架。
2. 系统梳理了FAIGC领域不同任务的检测方法,并提供了相关数据集的汇总分析,有助于后续的技术创新。
3. 展望了一些有前景的研究方向,如多模态检测、零样本学习、事实验证等,为问题的进一步探索指明方向。



但该研究仍存在一些不足:



1. FAIGC分类体系还有进一步细化完善的空间,如考虑更多模态组合形式、更细致的技术分类等。
2. 对一些前沿检测技术的分析还不够深入,实验也缺乏在更多真实场景数据集上的论证。
3. 对FAIGC治理的讨论还不够全面系统,如法律法规、行业自律、公众意识等层面的综合施策。



## 六、结语


FAIGC是人工智能快速发展带来的新问题、新挑战。恶意方滥用AIGC技术批量制造传播虚假信息,严重威胁网络内容生态与社会秩序。学术界、产业界需高度重视,加强理论与技术创新,并完善相关法律法规,提高公众意识,形成多方协同治理格局。



该论文通过系统梳理FAIGC的分类、检测等问题,在一定程度上推进了该领域的研究。未来,还需在多模态检测、持续学习、事实验证等方面加大研究力度,并更多地考虑产学研用结合,不断完善FAIGC治理的理论和实践。我们相信,经过各界共同努力,一个诚信、和谐、可信的AI时代终将到来。

