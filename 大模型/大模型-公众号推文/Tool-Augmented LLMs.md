---

语言模型对于创意内容生成、虚拟助理、客户支持、搜索等广泛的应用是有用的。然而，根据定义，它们仅限于产生自然语言，这不允许它们与现实世界交互。

这可以通过允许模型访问外部工具来改善——通过预测特殊的tokens或命令。工具可以采取各种形式：它可以是a）模型本身或另一个神经网络；b）检索组件，如搜索引擎；c）符号计算或代码模块；或者d）用于控制物理机器人或虚拟代理的模块。

更广泛地说，一个工具可以是任意的应用编程接口。下面是三个对语言模型化有用的工具示例：question answering、machine translation和calculator。Mialon等人在他们的调查中提供了这个新兴主题的一个很好的概述。

![](https://cdn.nlark.com/yuque/0/2024/jpeg/406504/1704871929185-ffcb37c4-b121-4ffb-91cf-bfc63d5d693c.jpeg)

![](https://cdn.nlark.com/yuque/0/2024/jpeg/406504/1704871928871-f29ec465-1924-4784-8153-c3e4b52411e8.jpeg)

![](https://cdn.nlark.com/yuque/0/2024/jpeg/406504/1704871929047-1f8bd12e-66c5-443a-b3fc-3a39c8aa65b0.jpeg)

Toolaker使用的不同工具示例从上到下：question answering、machine translation、calculator。

工具提供了一种实用的方法来解决当前LLMs的一些限制：

+ ❌LLMs不擅长数学。✅调用calculator可能会提高模型的算术能力。
+ ❌LLMs的预训练数据很快就会过时。✅调用search engine允许大模型生成最新信息。
+ ❌LLMs可能会产生信息幻觉。✅允许一个大模型cite其来源可能会提高其可信度。
+ ❌LLMs是黑盒。✅API的跟踪调用用于获得预测的大模型提供了一定程度的可解释性。

许多工具只是一个应用编程接口调用——但是我们如何教一个大模型使用它们呢？小样本提示是调节当前模型的标准方法。然而，小样本提示可能无法提供足够的监督来使大模型有效地使用工具，特别是当工具有复杂的参数或需要多个工具时。

我们可以为模型提供工具留档，而不是向模型展示一些工具使用演示。虽然演示展示了工具应该如何用于特定任务，但留档描述了不同工具的一般功能。发现工具留档在新领域的演示中优于小样本提示。

![](https://cdn.nlark.com/yuque/0/2024/jpeg/406504/1704871929386-58e2a5f6-a4eb-44ba-b638-b577c92b5392.jpeg)

提示LLMs工具使用的两种类型的信息。带有演示的小样本提示（左），即由问题组成的<输入，输出>对及其对应的输出工具使用计划。文档（右）提供了工具功能的描述（Hsieh et al.，2023）。

对通过API调用增强的数据进行微调似乎是首选。对于一个示例，尽可能多的API调用，可以过滤数据以仅保留“正确的”API调用。在实践中，可以以小样本方式提示大模型，并丢弃不导致正确最终预测的API调用。Parisi等人例如，为自然问题示例生成示例API调用。API调用被执行并用于生成模型响应。模型产生不正确输出的示例被过滤，模型在通过API调用增强的更新数据集上进行微调。

Schick等人使用应用于未标记文本数据集（Common Crawl的子集）的类似策略。它们不仅保留导致正确响应的API调用，还保留减少LLM损失的调用。由于使用来自多个API的调用来注释大型未标记文本很昂贵，因此它们使用启发式方法来通知何时应该选择每个API。

![](https://cdn.nlark.com/yuque/0/2024/jpeg/406504/1704871929254-711f0eb7-07f0-46a0-ba7b-566957986e03.jpeg)

Schick等人（2023）使用API调用扩充未标记的文本数据集，方法是：

+ 1）通过小样本提示对文本中随机位置的抽样API调用；
+ 2）执行API调用；
+ 3）过滤掉所有不会减少LLM在下一tokens损失的API调用；并将所有剩余的API调用添加到文本中。

模型也可以使用具有硬编码奖励函数或人类反馈（RLHF）的强化学习进行训练，尽管这可能会导致训练期间的不稳定问题。

鉴于当前模型的通用性，工具增强LLMs很快引起了研究人员的注意，最近的多篇论文声称工具使用为人工全智能铺平了道路（AGI）。工具增强LLMs的一个核心挑战是API和模型的可访问性。最近提出了以下工具增强LLMs平台：

+ [TaskMatrix.AI](http://taskmatrix.ai/)（[2023年3月](https://arxiv.org/abs/2303.16434)），一个生态系统的愿景，使LLMs能够与数百万个应用编程接口无缝接口。他们的框架包括一个基础大模型、一个应用编程接口平台和一个应用编程接口搜索引擎。作者设想模型主要学习如何使用RLHF使用应用编程接口，这可能很难扩展到数百万个应用编程接口。它们包括一个使用ChatGPT与PowerPoint应用编程接口的实例学习。
+ API-Bank（[2023年4月](https://arxiv.org/abs/2304.08244)），评估小样本提示设置中LLMs工具使用的基准。为了使小样本设置中的工具使用可行，模型需要生成一个API搜索引擎查询，该查询返回最相关的API的留档。
+ [OpenAGI](https://github.com/agiresearch/OpenAGI)（[2023年4月](https://arxiv.org/abs/2304.04370)），由合成多步骤多模态数据集组成的基准测试，需要对不同领域特定模型进行逆向推理链调用。模型可以在零样本、小样本、微调或基于RL的设置中进行评估。
+ [Gentopia](https://github.com/Gentopia-AI/Gentopia)（[2023年8月](https://arxiv.org/abs/2308.04030)），一个创建和共享工具增强代理的平台。

![](https://cdn.nlark.com/yuque/0/2024/jpeg/406504/1704871930008-3f4f4ff5-cf3b-40c7-91dc-4099a08675c6.jpeg)

TaskMatrix.AI概述。（1）基础模型生成解决方案大纲，API选择器根据该大纲选择最相关的API。（2）大模型生成API调用，该调用针对API执行。

回顾这一领域在短短几年内取得的进展，令人鼓舞。有一些趋势和发展尤其使我们走到了今天。

工具使用当时和现在。拥有带有辅助模块的模型接口的想法并不新鲜。例如，神经Programmer-Interpreter（[Reed&de Freitas，2016](https://arxiv.org/abs/1511.06279)）需要复杂的神经网络结构来学习执行不同的特定领域程序；为了给BERT配备计算器（[Andor et al.，2019](https://arxiv.org/abs/1909.00109)），定义了一组有限的算术运算的基于向量的运算。改变的是，当前的LLMs比以前的模型更加通用，这允许使用任意API。

****

**嵌入→模块→工具**

5年前，我们有学会为给定任务选择最佳嵌入组合的方法（例如，[Kiela et al.，2018](https://aclanthology.org/D18-1176/)）。去年，方法为给定任务选择了新的参数高效模块（例如，[毛等人。，2022](https://aclanthology.org/2022.acl-long.433/)）。现在我们处于模型学习选择和使用整个模型和任意黑盒工具的阶段。

****

**闲聊→面向目标的对话**

长期以来，端到端目标或面向任务的对话在NLP中一直是一项具有挑战性的任务（[Bordes et al.，2016](https://arxiv.org/abs/1605.07683)）。虽然之前的模型已经根据其信念状态查询数据库信息（[Hosseini-Asl et al.，2020](https://proceedings.neurips.cc/paper/2020/hash/e946209592563be0f01c844ab2170f0c-Abstract.html)），但工具增强的LLMs将能够更无缝地从闲聊过渡到面向目标的对话。

展望未来，工具增强LLMs有几个挑战和方向：

1. 使API可供模型使用。有数百万个可用的API可供模型交互。API平台（见上文）以及ChatGPT插件和其他旨在集中对API的访问，这可能会有锁定用户的风险。为了确保这一领域的研究进展，关键是确保一组标准的API可以公开和自由使用。
2. 应用编程接口搜索和可扩展性。找到最相关的应用编程接口的问题类似于为虚拟助理（如阿列克谢）找到最合适的技能。关键是要有一个搜索组件，从不断增长的应用编程接口池中可靠地返回最相关的应用编程接口，并使LLMs能够通过新工具轻松扩展。
3. 学习使用工具。如何最好地教一个大模型使用工具仍然是一个悬而未决的问题。[Schick等人。（2023）](https://arxiv.org/abs/2302.04761)的方法仅限于一次使用一个工具，并且需要特定于工具的启发式方法来有效地扩展数据集。研究能够提供（多步骤）监督和扩展到100s和1000s API的方法非常重要。
4. 预训练工具增强LLMs。鉴于API及其用例的多样性，将更多预算用于训练工具增强LLMs是有意义的。虽然预训练模型可以针对工具使用进行微调，但预训练工具增强大模型允许模型在训练早期卸载某些行为，并专注于学习工具未捕获的内容。
5. 改进推理和问题分解推理和工具使用紧密交织在一起（[Mialon et al.，2023](https://arxiv.org/abs/2302.07842)）为了为一个问题调用正确的API，需要将其分解为可能更简单的子任务如何最好地分解开放式问题是一个开放的挑战。
6. 补偿API错误并防止错误级联。对其他模型或工具（如搜索引擎）的API调用可能会产生错误的结果，从而导致下游故障。LLMs应该学会评估API的可靠性并从API故障中恢复。
7. 更好地理解工具的使用。模型如何学习使用和与工具接口的许多方面知之甚少。例如，尚不清楚模型在多大程度上使用预测推理步骤来支持最终预测（[Yu et al.，2022](https://arxiv.org/abs/2212.08286)）。因此，开发分析方法和诊断工具以及新的工具增强LLMs非常重要。

工具的使用使我们能够解决当前模型的一些局限性，并有可能使它们同时更有能力和可解释。我很高兴看到这一领域未来的进展会是什么样

