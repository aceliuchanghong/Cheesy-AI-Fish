# ConvPrompt： 卷积提示与语言模型相结合实现持续学习
> 原文：《Convolutional Prompting meets Language Models for Continual Learning》
>

## 1. 引言
在这个不断变化的世界中，计算机视觉模型必须适应新兴的概念。然而，这些模型经常遭受灾难性遗忘的问题，即在适应新概念时忘记之前学习的概念。解决这个问题的一个简单方法是为每个新任务使用单独的模型。但这需要在推理过程中知道任务标识，这在实践中可能不太可行。

另一种方法是保留模型训练过的所有数据，将新数据添加到其中，然后从头开始重新训练模型。显然，这会增加存储和计算成本。

一种试图保持平衡的方法是保留以前任务的一些样本，并在学习新任务时用它们来复习以前的概念。然而，由于隐私、安全或立法方面的考虑，存储旧任务的样本可能并不总是可行的。因此，开发无需存储旧数据的无复习持续学习方法变得更加理想。

最近，基于提示调优的方法利用预训练的Transformer模型，在不使用任何复习数据的情况下展现出了良好的性能。提示调优最初在自然语言处理中引入，它将小的可学习向量附加到预训练的冻结模型上，以适当地重用已学习的表示。尽管这些方法在持续学习中很有前景，但它们仍存在以下缺点：

1. 在单独的层中学习特定任务和共享任务的信息，忽视了特定任务和共享任务组件之间可能的交互。
2. 无论任务与之前任务的相似性如何，始终为每个任务学习固定数量的提示。冗余的提示可能导致过拟合，特别是在任务高度相似的情况下(通常见于细粒度数据集)。

本文提出了ConvPrompt，它利用通过对任务共享参数进行卷积生成的特定任务提示。作者还利用任务之间的相似性来控制提示的生成。具体来说，任务共享知识由每一层的可学习嵌入矩阵建模。另一方面，提示是特定于任务的，通过对任务共享嵌入进行可学习卷积核的卷积来生成。共享嵌入可以自由地适应不同的任务。

而生成提示的卷积核在为一个任务学习后就被搁置，为下一个任务使用新的一组卷积核。这种设计使共享嵌入能够捕获共同概念，同时允许卷积操作从共同概念中捕获特定任务的概念。

此外，作者利用语言模型获取任务之间的相似性，以确定可训练卷积核的数量。这种扩展策略允许模型在参数效率方面表现出色，仅在需要时引入必要数量的新参数。这种方法的优势主要有三个方面：

1. 它促进了使用任务共享嵌入在任务之间进行知识迁移。
2. 卷积提示生成促进了对新任务的高效适应，同时参数开销较低。
3. 利用大型语言模型探索相似任务，进一步减少了参数数量并提高了性能。

在几个无复习持续学习基准测试中进行的大量实验表明，ConvPrompt方法与最先进的方法相比，在性能上取得了显著的提升。平均而言，在3个基准数据集和不同的实验设置下，ConvPrompt比最先进的基于提示的持续学习方法(如CODA-Prompt)的性能提高了约3%，同时需要的参数数量显著减少。本文的主要贡献可以总结如下：

1. 提出了一种局部提示创建机制，通过对任务不变的全局参数应用卷积，实现了局部和全局概念在任务之间的高效迁移，有助于新任务更好地适应。
2. 首次在持续学习中引入基于语言的任务相似性预测，这有助于显著减少模型参数，同时不牺牲性能，也不增加显著的预处理开销。
3. 在各种标准数据集和实验设置上进行的广泛消融实验和实验表明，本文方法在性能上有显著的提升。

## 2. 相关工作
### 2.1 持续学习
持续学习方法可以分为三大类：

1. 基于正则化的方法：通过应用正则化器来解决灾难性遗忘问题，这些正则化器优先保留与先前学习的任务相关的重要参数。通过引入惩罚项或限制参数更新的方向，这些方法鼓励重要参数保持接近先前的解决方案。虽然基于正则化的方法在涉及较少任务的情况下表现出良好的结果，但在面对涉及大量任务的具有挑战性的场景时，它们的性能可能不太令人满意。
2. 基于动态架构的方法：通过为每个任务分配不同的参数来学习新任务。虽然这些方法表现出学习扩展任务序列的能力，但它们可能会遇到大量的内存和计算开销。此外，这一类别下的大多数方法在推理过程中需要知道图像所属的任务信息，这可能是不现实的。
3. 基于复习的方法：在缓冲区中存储先前任务的一些代表性训练样本，然后在当前任务训练的同时使用这些样本。虽然有效，但这些方法受到缓冲区大小和任务序列长度的限制。它们也不特别适用于有数据隐私要求的场景。

相比之下，ConvPrompt通过在预训练模型上智能地利用提示来解决无复习持续学习问题。

### 2.2 提示学习
基于提示的持续学习通过引入少量称为提示的模型指令，而不是直接修改编码器参数，提供了对灾难性遗忘的强大保护。初始方法如L2P和DualPrompt采用提示池，从中选择提示。这些方法在不依赖任务识别的情况下，使用基于局部聚类的优化来匹配输入数据和提示。

最近，S-Prompts在域增量学习场景中使用提示进行持续学习，该场景涉及在协变量分布变化下学习相同的类集。CODA-Prompt在L2P和DualPrompt的基础上，将软注意力应用于提示，实现端到端的持续学习。

ProgressivePrompts为每个传入任务逐步学习新的提示标记，但假设在推理过程中存在任务ID。一项同期工作LGCL使用外部手工制作的提示，并对比地学习将Transformer的输出表示带到提示。然而，没有内在的提示学习，这种方法只能作为现有持续学习方法的插件，在性能上只能实现增量改进。

本文提出的ConvPrompt方法在任务间知识共享的熟练程度、即时提示生成的能力以及有效处理所需附加参数方面都优于其他方法。

## 3. 预备知识
### 3.1 持续学习
持续学习(CL)训练模型在一段时间内顺序到达的任务上，而不忘记之前的任务。每个任务 $ t \in \{1, \ldots, T\} $ 包含训练样本 $ \{(x_i^t, y_i^t)\} $，其中 $ x_i^t $ 是第 $ t $ 个任务的第 $ i $ 个样本，而 $ y_i^t \in C^t $ 是相应的标签。不同任务的类别标签集是互斥的，即 $ C^0 \cap C^1 \ldots \cap C^T = \phi $。本文解决了持续学习中具有挑战性的无复习和类增量学习(CIL)设置，其中训练好的模型 $ f $ 需要预测未见测试样本 $ x $ 的标签 $ y = f(x) $，而不考虑其任务，也不能访问先前任务的训练数据。

### 3.2 Transformer架构
本文的方法建立在预训练的Vision Transformer (ViT)之上。Transformer首先将输入图像 $ x $ 分割成一组固定大小的块 $ z_1 \in \mathbb{R}^{N \times d} $，然后将它们嵌入到具有位置编码的 $ d $ 维空间中。ViT的单个编码器层由多头自注意力(MHSA)、层归一化和前馈网络(FFN)块组成，并带有残差连接。

给定第 $ l $ 层的输入 $ z_l $，生成进入下一层的输出 $ z_{l+1} $，其中 $ l \in \{1,2,\cdots L\} $，而 $ L $ 是编码器层的总数。在第 $ l $ 层，MHSA块使用 $ H $ 个独立的自注意力头对输入 $ z_l $ 计算自注意力。第 $ l $ 层第 $ h $ 个头的自注意力值由以下公式给出：

$ A(Q_{l,h}, K_{l,h}, V_{l,h}) = \text{softmax}\left(\frac{Q_{l,h}K_{l,h}^T}{\sqrt{d_k}}\right)V_{l,h} $

其中 $ Q_{l,h} = z_lW_{l,h}^Q $， $ K_{l,h} = z_lW_{l,h}^K $ 和 $ V_{l,h} = z_lW_{l,h}^V $ 分别是查询、键和值，具有可学习的权重 $ W_{l,h}^Q $， $ W_{l,h}^K $ 和 $ W_{l,h}^V \in \mathbb{R}^{d \times d_h} $。$ d_h = d/H $ 是键、查询和值向量的维度。

来自不同注意力头的激活被连接起来，并与输入 $ z_l $ 残差相加，然后进行层归一化。得到的激活通过由两个线性层和一个激活函数(通常是GELU)组成的FFN块。经过另一个残差连接和层归一化后，生成第 $ l $ 层的输出 $ z_{l+1} $。

### 3.3 提示和前缀调优
前缀或提示调优旨在学习连续向量，同时保持预训练的Transformer冻结。它在每一层的自注意力头的原始键和值之前添加 $ l_p $ 个可学习的向量。具体来说，$ l_p $ 长度的前缀向量 $ P_{l,h}^{(K)} $; $ P_{l,h}^{(V)} \in \mathbb{R}^{l_p \times d_h} $ 与原始的键 $ K_{l,h} $ 和值 $ V_{l,h} $ 分别连接。然后，第 $ l $ 层第 $ h $ 个头的自注意力值计算为 $ A(Q_{l,h}, [P_{l,h}^{(K)}, K_{l,h}], [P_{l,h}^{(V)}, V_{l,h}]) $，遵循公式(1)。

与现有的直接学习附加向量的基于提示的方法不同，本文的工作专注于通过维持系统的旧知识和即时放置的新信息之间的平衡来创建提示。

## 4. 方法
![](https://cdn.nlark.com/yuque/0/2024/png/406504/1728546687657-4ff688c0-c0b8-40d3-afd8-bdee1e29e818.png)

本文提出了一种基于提示的持续学习方法(ConvPrompt)，通过结合先前学习的知识为每个新任务生成提示向量。来自先前任务的知识由所有任务共享的可学习嵌入矩阵建模。特定任务的提示是通过对共享嵌入矩阵进行卷积操作创建的。虽然现有的工作已经证明通过对预训练的Transformer进行提示调优可以取得良好的性能，但它们依赖于单一组提示向量，需要将图像的所有必要信息压缩到一个单一集合中。

与其使用一组 $ l_p $ 提示向量，本文遵循CODA-Prompt，使用 $ M $ 组这样的向量，称为提示组件。然而，与CODA-Prompt不同，本文方法中的提示组件不是直接学习的。相反，它们是通过在每一层的每个头中使用 $ M $ 个卷积核(称为提示生成器)从先前任务知识中生成的。

提示组件的加权组合提供了最终的 $ l_p $ 提示向量，其中权重来自与输入图像对应的ViT每一层的[CLS]嵌入。这种加权不仅允许端到端地优化模型，还提供了先前任务知识和输入图像的独特融合。

### 4.1 提示生成
本文方法中的提示向量是通过小型卷积操作动态生成的。卷积是在两个可学习的组件之间进行的：

1. 共享嵌入
2. 提示生成器

对应于Transformer的每一层 $ l \in \{1,2,\cdots L\} $ 中的每个头 $ h \in \{1,2,\cdots H\} $，分别有用于键和值的共享嵌入矩阵 $ SE_l^K $ 和 $ SE_l^V $。这些矩阵在任务之间共享。提示生成器是应用于共享嵌入的单通道卷积核。对于每个头和每一层，我们学习一组 $ M $ 个提示生成器，用于键和值。对于第 $ h $ 个头和第 $ l $ 层，提示生成器表示为 $ G_{l,h,m}^K $ 和 $ G_{l,h,m}^V $，其中 $ m \in \{1,2,\cdots M\} $。

共享嵌入的维度为 $ (l_p + k - 1) \times (d_h + k - 1) $，其中 $ k $ 是提示生成器的卷积核大小。卷积操作的结果是维度为 $ l_p \times d_h $ 的提示组件 $ PC_{l,h,m}^K $ 和 $ PC_{l,h,m}^V $。卷积提示生成器不仅使我们能够在性能和每个任务的低参数要求之间保持良好的平衡，还利用了结构化提示创建的固有偏置。

### 4.2 提示加权
不同于将所有信息压缩到一组提示向量中，本文方法利用 $ M $ 个提示组件在每一层的每个头获得最终的提示向量。对于每个提示组件 $ PC_{l,h,m}^K $ (和 $ PC_{l,h,m}^V $)，我们生成权重(在-1和1之间)，可以解释为特定提示组件在混合中的相对重要性。我们为此目的使用 $ M $ 个可学习的键，称为提示键 $ \pi \in \mathbb{R}^{d_\pi} $。提示键作用于表示为每一层[CLS]标记的非线性函数的图像特征。

[CLS]标记通过一个投影网络($ PN_\phi $)传递，该网络由 $ \phi $ 参数化，包含一个两层全连接神经网络，中间有ReLU激活。输出 $ PN_\phi([CLS]) $ 将输入图像映射到与提示键相同的空间，在每一层 $ l $ 中，通过 $ PN_\phi([CLS]) $ 与 $ M $ 个提示键之间的余弦相似度得到重要性值 $ \{s_{l,1}, s_{l,2}, \cdots, s_{l,M}\} $。

提示生成器与共享嵌入之间的卷积操作得到的提示组件由 $ M $ 个相似度分数加权，得到最终的提示 $ P_{l+1,h}^{(K)} $ 和 $ P_{l+1,h}^{(V)} $，如下所示：

$ P_{l+1,h}^{(K)} = \sum_{m=1}^M s_{l,m} PC_{l,h,m}^K; \quad P_{l+1,h}^{(V)} = \sum_{m=1}^M s_{l,m} PC_{l,h,m}^V $

虽然现有工作线性组合提示组件以获得最终提示，但相似度分数是使用所有层中相同的最终[CLS]标记生成的。然而，这需要仅为获取相似度分数而对Transformer进行完整的前向传播，然后在每一层获得最终提示以进行最终预测，总共需要两次传递。

相比之下，本文方法利用每一层的[CLS]嵌入，使我们能够在一次传递中生成后续层的最终提示，从而显著减少计算量。从图像生成的相似度值帮助不同的提示组件关注特定特征以获得最终提示。基于此，作者使用非线性学习的投影网络，能更好地捕捉复杂任务，这一点已在经验上得到验证。

### 4.3 语言引导的提示
为了在学习新任务和保存从旧任务累积的知识之间保持平衡，本文方法同时使用任务共享和任务特定的参数。在本文的工作中，$ PN_\phi $ 和 $ SE $ 作为共享参数，促进任务间信息共享，而随着新任务的到来，先前学习的提示生成器和提示键被冻结，从而使它们成为任务专门化的参数。每个传入任务都会重新学习一组新的参数。

设直到第 $ (t-1) $ 个任务每层学习的提示生成器总数为 $ M_{t-1} $，而仅为任务 $ i $ 学习的提示生成器数量为 $ J_i $。自然地，$ M_{t-1} = \sum_{i=1}^{t-1} J_i $，当学习新的 $ J_t $ 个提示生成器时，所有 $ M_{t-1} $ 个提示生成器都被保持冻结。尽管提示生成器的作用是缓解灾难性遗忘，但随着任务数量的增加，控制参数增加也很重要。

理想情况下，如果一个任务与之前见过的任务相似，那么之前学习的提示生成器可以被重用。因此，与之前的工作不同，本文方法根据任务与之前任务的相似性动态学习提示组件的数量，而不是每个任务学习固定数量的提示组件。

本文的关键洞见是，可以使用语言作为工具来获取不同类别的视觉属性描述，并使用这些来找到任务相似性。视觉属性是额外的语义知识，表达与每个类别相关的视觉概念。例如，蜜蜂的一些视觉属性是"黑黄条纹"、"两对翅膀"、"三个身体部分"等。作者不是手动编写这些属性，而是查询GPT-3来获取每个任务中每组类别的属性。这在计算上很便宜，不需要额外的训练，并且可以扩展到大量类别。

受到一些工作的启发，对每个类别使用查询"在照片中区分[类别名称]的有用特征是什么？"来生成类别属性。作者生成这些属性的BERT嵌入，并将它们存储在所有已见任务的池中。为了找到任务间的相似性，计算当前任务 $ t $ 的每个属性与之前所有任务(0到 $ t-1 $)的所有存储属性嵌入之间的余弦相似度。

对于任务 $ t $ 中的每个类别，考虑其与任何先前类别的最大相似度得分。最后，任务 $ t $ 的相似度 $ sim_t $ 计算为任务 $ t $ 中所有类别的最大相似度的平均值。

设 $ J_{max} $ 表示每个任务的最大提示生成器数量。那么 $ J_t $ 由 $ (1 - sim_t)J_{max} $ 给出，即更高的相似性使得需要的提示数量更少。利用语言知识，如果一个任务中的类别与之前遇到的类别有高度重叠，作者减少了可学习的参数。

### 4.4 正则化和最终目标
为了防止全局任务共享的 $ PN_\phi $ 和 $ SE $ 中捕获的先前任务概念被覆盖，需要确保在学习当前任务时，这些参数与先前任务的偏差较小。为了实现这一点，在学习任务 $ t $ 时，作者对投影网络的参数集 $ \phi_t $ 和共享嵌入 $ SE_t $ 进行正则化，使其与前一个任务的 $ l_1 $ 范数较小：

$ L_r(\phi_t, \phi_{t-1}) = ||\phi_{t-1} - \phi_t||_1 $

$ L_r(SE_t, SE_{t-1}) = ||SE_{t-1} - SE_t||_1 $

$ SE_t $ 表示任务 $ t $ 的所有头和层以及键和值的共享嵌入参数。需要注意的是，虽然用于共享嵌入的后缀 $ t $ 可能表明 $ SE $ 是特定于任务的，但事实并非如此。共享意味着相同的一组嵌入用于学习不同任务之间的共享语义。作者对每个任务逐步更新相同的 $ SE $，使用来自紧接前一个任务的 $ SE $ 副本进行公式(3)中的正则化，该副本在训练后被丢弃。$ \phi_t $ 表示第 $ t $ 个任务的投影网络参数。最终目标是：

$ L_{cls}(f(x), y) + 1(t > 1)\lambda[L_r(\phi_t,\phi_{t-1}) + L_r(SE_t,SE_{t-1})] $

其中 $ L_{cls} $ 表示分类损失，$ t $ 是任务id，$ \lambda \in [0, 1] $ 是用于权衡损失组件的超参数。指示函数 $ 1(t > 1) $ 表示正则化在第一个任务之后应用。

## 5. 实验
### 5.1 数据集
作者在CIL设置下评估了ConvPrompt在以下基准数据集上的表现：

1. ImageNet-R： 由ImageNet的200个子类别组成，但包含来自不同领域的图像，如卡通、涂鸦和折纸。它还包括一些标准模型无法分类的ImageNet中的困难示例。它包含24，000张训练图像和6，000张测试图像。按照之前的工作，将200个类别分成10个任务，每个任务包含20个类别。
2. CIFAR-100： 一个广泛用于持续学习的数据集，包含100个类别，每个类别有500张训练图像和100张测试图像。按照之前的工作，使用CIFAR-100的10个任务设置，每个任务包含10个类别。
3. CUB-200： 一个细粒度数据集，包含200个不同鸟类物种的类别，有5994张训练图像和5794张测试图像。按照之前的工作，使用CUB-200的10个任务设置，每个任务包含20个类别。

### 5.2 训练和实现细节
作者使用在ImageNet-21k上预训练的ViT-B/16模型作为骨干网络，在其上应用ConvPrompt。投影网络是一个两层神经网络，这两层分别有 $ d/2 $ 和 $ d/4 $ 个神经元，其中输入([CLS]标记)是 $ d $ 维的。在两层之间应用ReLU激活函数。本文方法将提示应用于预训练ViT的7个层，因为消融实验表明更多的层应用提示并不能提高性能，尽管参数开销增加。

对于CIFAR-100、ImageNet-R和CUB-200中的每个任务，分别训练10、10和60个epoch。超参数 $ J_{max} $ 设置为5，作为每个任务所需的最大提示组件数量的上限。用于权衡公式(4)中正则化项的超参数 $ \lambda $ 设置为0.01。

作者在进行五次随机试验后呈现结果，每次运行都随机选择任务顺序。报告平均值±标准差。

### 5.3 使用的指标
文章报告了在 $ T $ 个任务上计算的平均准确率 $ A_T $ 和遗忘 $ F_T $。具体来说，在完成 $ T $ 个任务的训练后，$ A_T $ 和 $ F_T $ 的计算如下：

$ A_T = \frac{1}{T}\sum_{t=1}^T S_{t,T} $

$ F_T = \frac{1}{T-1}\sum_{t=1}^{T-1} \max_{t' \in \{1,...,T-1\}} (S_{t,t'} - S_{t,T}) $

其中 $ S_{t,T} $ 是模型在任务 $ T $ 上训练后在任务 $ t $ 上的测试分类准确率。换句话说，平均准确率衡量在最后一个任务训练后所有任务的平均准确率，而遗忘衡量一个任务在最后一个任务训练后的准确率相对于其达到的最大准确率的平均下降。

### 5.4 比较方法
作者将本文方法与几种无复习方法进行了评估比较。这些方法包括：

+ Learning without Forgetting (LwF)
+ Learning to Prompt (L2P)
+ DualPrompt
+ CODA-Prompt

作者还评估了LGCL，它使用基于语言的提示，并作为L2P和DualPrompt的插件。此外，作者还将本文方法与一种基于复习的方法Experience Replay (ER)进行了比较，缓冲区大小为5000。

作者还报告了Joint-FT和Seq-FT的性能，因为它们在许多情况下作为性能的边界。在Joint-FT中，ViT模型在所有任务的训练数据组合上联合训练，作为性能的上限。Seq-FT表示仅使用新任务的训练数据顺序微调ViT模型，因此Seq-FT受到严重的灾难性遗忘影响。

### 5.5 结果和分析
![](https://cdn.nlark.com/yuque/0/2024/png/406504/1728546716709-decbe97e-8cb1-466f-9f4f-3242482f946c.png)

![](https://cdn.nlark.com/yuque/0/2024/png/406504/1728546725753-3d688154-da6f-4ae9-b97a-0a54eadaa5c1.png)

如表1和表2所示，ConvPrompt在性能上显著优于无复习和基于复习的方法。平均而言，ConvPrompt比现有最先进的CODA-Prompt的性能提高了约3%，同时只使用了CODA-Prompt所用可训练参数的约40%。

本文方法在Split-CUB的10任务设置中显示出略多的遗忘。然而，即使遗忘更多，本文方法仍能以至少3%的优势超过现有方法，从而证实了本文设计能够通过防止过拟合来有效适应新任务，这导致任务达到更高的最大准确率。这表明本文的卷积提示创建机制能够比CODA-Prompt和DualPrompt更好地利用共享的任务间概念。

#### 与SLCA的比较
作者还与最近的一种不使用提示进行持续学习的SOTA方法Slow Learner with Classifier Alignment (SLCA)进行了比较。该方法不是使用提示，而是对整个网络进行微调，对表示层使用较小的学习率，对分类层使用较大的学习率。这种方法相比现有的持续提示调优方法展示了优越的性能。由于它涉及全网络调优，计算成本很高，使其在资源受限的情况下不切实际。相比之下，本文方法在计算受限的情况下是可行的。在这个实验中，作者展示了本文方法也可以利用差异学习率和分类器对齐，就像SLCA一样，并提供进一步的性能改进。具体来说，在这种情况下，作者在微调过程中学习提示以及Transformer权重。表8中的结果表明，本文方法与SLCA结合，在三个数据集中的两个上优于SLCA，达到了新的最先进水平，而在CIFAR-100数据集上，它几乎与SLCA持平。

### 5.6 消融研究和其他分析
作者在ImageNet-R数据集的10任务设置上进行了所有消融研究，除非另有说明。在整个研究中，作者考虑了ImageNet-21k预训练的ViT-B/16模型，并逐步整合本文的模块以展示它们的重要性。表4显示了结果。

![](https://cdn.nlark.com/yuque/0/2024/png/406504/1728546774306-274e12cd-fca4-4110-af76-134927ae4797.png)

#### 跨任务利用共享嵌入
在ViT-B/16基线之上添加共享嵌入，已经给出了比使用提示池的L2P更好的性能(参考行"+SE")。这表明，当适当正则化时，跨任务共享的知识本身就可以比纯粹的单独提示更好。

#### 提示生成器的作用
接下来，作者在任务共享嵌入之上添加了特定任务的提示生成器。作者实验了两种形式的提示生成器：a)卷积核和b)神经网络。这两种类型都显示出显著的改进(参考行"+SE+NN"和"+SE+Conv")。然而，使用神经网络在计算上自然比卷积提示生成器更重，如最右列所示。总的来说，添加特定任务的提示生成器导致比仅任务共享的方法提高了约6%的性能，比也使用任务共享和任务特定知识的DualPrompt提高了约3%的性能。这再次证实了作者的假设，即通过共享嵌入生成提示有助于有效地共享任务间概念，以更好地适应新任务。

#### 提示加权的重要性
然后，作者添加了提示加权机制，这进一步带来了约3%的改进(参考以"+SE+Conv+PN"开头的两行)。这表明本文的提示加权更好地利用了重要的提示。为了研究投影网络中的非线性是否有帮助，作者比较了线性投影网络(单层全连接神经网络)和非线性网络(两层全连接神经网络，中间有ReLU)的性能，并观察到非线性自然地在复杂的视觉数据上表现更好，尽管参数数量略有增加。

#### 语言帮助减少参数
最后，作者添加了语言驱动的任务相似性来动态确定提示生成器的数量(参考表4的最后一行)，这构成了完整的ConvPrompt。这导致了显著的参数减少，同时保持了相同的性能。在包含非常相似任务的数据集(如CUB-200)中，性能也得到了提升(约1%)，可能是由于参数减少导致的过拟合减少。

#### 提示长度的影响
作者分析了提示向量长度($ l_p $)对不同基于提示的持续学习方法(包括本文方法)性能的影响。为此，作者进行了不同提示长度的实验，将长度从4到40以4的倍数增加。如图2a所示，ConvPrompt在所有$ l_p $值下表现最佳，性能呈上升趋势，直到提示长度为20，之后趋于饱和。因此，作者使用$ l_p = 20 $，除非另有说明。

#### 增加提示层数的影响
为了分析对每一层进行提示是否有帮助，作者对ConvPrompt和密切相关的方法在预训练骨干网络的不同层应用了提示(参考图2b)。具体来说，从对前5层应用提示开始，作者逐步对直到最后一层(即第12层)应用提示。如图所示，ConvPrompt的性能在7层时达到峰值，然后趋于稳定，而DualPrompt和CODA-Prompt的性能在5层后下降，然后趋于稳定。

#### 提示生成器数量的影响
作者分析了增加最大提示生成器数量$ J_{max} $的影响(参考图2c)。作者观察到性能在$ J_{max} = 5 $时达到峰值，之后性能下降。

#### 提示生成器卷积核大小的影响
为了理解提示生成器卷积核大小的影响，作者将卷积核大小k从5到25以2的步长进行了变化。如图2d所示，大小为17的卷积核给出了最佳结果，而对于更高的值，性能略有下降并趋于稳定。作者选择核大小17作为默认值，因为它在可训练参数数量和性能之间达到了更好的平衡。

#### 投影前后的前缀
作者分析了将提示向量$ P_{l,h}^{(K)} $和$ P_{l,h}^{(V)} $与原始键$ K_{l,h} $和值$ V_{l,h} $连接，与将它们与投影得到键和值的输入$ z_l $连接的效果。如果在连接后进行投影(C→P)，性能与另一种方式(P→C)相比变化不大(表6)。自然地，由于更大的矩阵-向量乘法，C→P的计算量更大(约0.2B MACs)。由于计算开销低且性能相当，P→C更有优势，并在本文实验中使用。

#### 测量任务相似性的最佳方法
由于任务之间的相似性在性能和额外训练的参数方面都起着关键作用，作者尝试了不同的方法来测量任务相似性。具体来说，作者实验了(i)基于类别标签的任务相似性和(ii)基于图像的任务相似性。在第一种方法中，作者直接使用类别标签而不是GPT-3生成的属性，在第二种方法中，作者使用预训练的ViT-B/16提取视觉特征，并用它们来测量与先前任务的相似性。表5显示了这些方法在10任务ImageNet-R上的性能和参数要求。可以看出，基于属性的类别相似性导致引入的参数最少，同时性能最佳。

#### 推理时间比较
作者将推理时间与竞争的基于提示调优的方法进行了比较，包括L2P、DualPrompt和CODA-Prompt。作者计算了模型在ImageNet-R数据集的所有10个任务上训练后，在推理过程中的MAC(乘累加运算)数量。如表7所示，ConvPrompt所需的计算量最少，这得益于其单次传递的提示过程。

## 6. 结论
本文提出了ConvPrompt，这是一种新颖的卷积提示生成机制，结合了基于任务相似性的扩展策略，用于无复习持续学习。与现有方法不同，本文方法通过对任务共享嵌入应用卷积在每一层创建提示，从而实现更好的任务间知识迁移。此外，本文基于大型语言模型驱动的任务相似性的扩展策略确保了在不显著增加可学习参数数量的情况下实现这种性能提升。大量实验表明，ConvPrompt显著优于SOTA基线，同时需要更少的额外参数。

