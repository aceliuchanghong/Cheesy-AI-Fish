> 原文：《<font style="color:rgb(41, 38, 27);background-color:rgb(245, 244, 239);">Unlocking Continual Learning Abilities in Language Models</font>》
>

## 1. 引言
语言模型(LMs)展现了令人印象深刻的性能和泛化能力。然而，LMs仍然面临灾难性遗忘的持续挑战，这削弱了它们在持续学习(CL)中的长期可持续性。现有的方法通常通过将旧任务数据或特定于任务的归纳偏置纳入LMs来解决这个问题。但是，旧数据和准确的任务信息通常无法获得或收集成本很高，这阻碍了当前CL方法在LMs中的应用。

为了解决这个限制，本文提出了"MIGU"(基于幅度的梯度更新，用于持续学习)，这是一种无需重放和无需任务标签的方法，它只更新LMs线性层中输出幅度较大的模型参数。MIGU基于我们的观察：当LM模型处理不同任务数据时，LMs线性层中输出的L1归一化幅度分布是不同的。通过在梯度更新过程中施加这个简单的约束，我们可以利用LMs的内在行为，从而释放它们天生的CL能力。

## 2. 相关工作
### 2.1 语言模型的持续学习
持续学习是机器学习和深度学习历史中一个长期存在的挑战。最近针对LMs的CL研究大致可分为三类：

1. 基于重放的方法：将新任务数据与少量过去任务样本混合。
2. 基于架构的方法：扩展新模块(如adapters)以纳入新任务。
3. 基于参数的方法：以任务感知的方式更新参数。可进一步分为：
    - 基于正则化的方法：添加正则化项以惩罚对先前学习任务的重要权重的更改。
    - 基于优化的方法：将每个任务的参数梯度更新到正交子空间以避免冲突。

这些方法依赖于旧任务数据或准确的任务标签，这对于LMs的持续训练来说是难以或昂贵获得的。相比之下，MIGU只利用LMs的内在特征进行CL。

### 2.2 持续学习中的部分参数更新
在现有的LMs CL方法中，我们的方法和基于正则化的方法都部分更新参数，但我们的方法在动机和设计上与基于正则化的方法有根本的不同：

+ 我们利用前向阶段任务间幅度分布的差异，而它们依赖反向梯度来识别和保护旧任务的重要权重。
+ 我们的方法能够在样本级别自由mask，而它们采用固定的梯度mask方法。
+ 我们的方法不需要任务标签，因此可以在更广泛的无任务标签场景中工作。
+ 层输出分布在前向阶段训练中自然获得，而它们通常需要额外的子集来在训练任务之前推导梯度mask。

### 2.3 寻找重要权重
![](https://cdn.nlark.com/yuque/0/2024/png/406504/1728470239161-2aeda67b-b346-4a62-9d30-acddd59623e5.png)

我们的方法可以归类为寻找重要权重的更广泛研究集群，这个主题在持续学习、模型剪枝和压缩、高效训练和推理以及激活稀疏性研究等领域已被广泛探索。然而，这些工作大多使用权重或梯度幅度来定义固定大小的重要权重。少数关于激活稀疏性的工作使用激活函数后的稀疏模式来实现高效推理或性能改进。没有上述工作探索权重和层输入的一般点积。与我们最接近的是一项非结构化剪枝工作，使用权重和输入的点积，证明了比纯粹基于权重的剪枝更优越的方法。然而，这项先前工作未能考虑不同任务间重要权重的变化模式。相比之下，我们的方法利用权重和输入的L1归一化点积作为CL设置中重要性的内在指标。

## 3. 方法
> 压缩版：**<font style="color:rgb(51, 51, 51);">在模型的前向传播阶段捕获并标准化线性层的输出，然后在反向传播阶段，只更新那些具有最大L1标准化幅度的参数</font>**
>

![](https://cdn.nlark.com/yuque/0/2024/png/406504/1728470261958-e4c90402-22ab-4e66-8772-4d5874c9fa25.png)

### 3.1 持续学习设置
持续学习旨在解决持续序列中出现的挑战。形式上，任务 $ {T_1, ..., T_T} $ 按顺序到达。每个任务 $ T_t = \{(x_t^i, y_t^i)\}_{i=1}^{n_t} $ 包含一个大小为 $ n_t $ 的单独目标数据集。对于任何时间步 t，期望模型不仅能够适应第 t 个任务，还能保留它在所有先前训练过的任务上的能力。本研究探讨了两种不同的CL设置：

1. 只使用MIGU方法时，在训练和测试阶段都无法获得任务标签。
2. 与三种现有CL技术结合时，模型可以在训练阶段接触到旧任务数据或任务信息。

### 3.2 MIGU - 基于幅度的梯度更新，用于持续学习
我们的方法采用两步过程来利用各种任务间幅度分布的内在差异进行持续学习：

1. 缓存输出幅度
2. 通过基于幅度的mask更新梯度

为了说明我们的方法，我们首先考虑LMs中的基本组件，一个具有权重W的单个线性层，并只将一个输入token x输入LMs。

> <font style="color:rgb(51, 51, 51);">挑战：</font>
>
> + <font style="color:rgb(51, 51, 51);">MIGU依赖于模型线性层输出的幅度分布差异，这需要模型能够在不同任务之间展示出足够的幅度变化，这在某些情况下可能不容易实现。</font>
> + <font style="color:rgb(51, 51, 51);">其次，尽管MIGU减少了对旧任务数据的依赖，但在没有任何任务标签的情况下，如何有效地区分和处理不同任务的学习过程仍然是一个开放的问题。</font>
> + <font style="color:rgb(51, 51, 51);">此外，MIGU的效果可能受到模型架构和任务性质的限制，其在不同类型的语言模型和任务上的普适性和效率仍需进一步验证</font>
>

#### 前向传播：缓存输出幅度
给定权重矩阵 $ W \in \mathbb{R}^{d_{in} \times d_{out}} $，我们将W的列解释为一组 $ d_{out} $ 向量，每个向量维度为 $ d_{in} $：

$ W = [w_1, ..., w_i, ..., w_{d_{out}}] $， 其中 $ w_i \in \mathbb{R}^{d_{in}} $

给定层的输入向量 $ x \in \mathbb{R}^{d_{in}} $，该层的操作可以视为x与每个权重向量 $ w_i $ 的点积：

$ h_i = x \cdot w_i $

然后我们使用L1范数计算归一化乘积幅度 $ n_i $：

$ n_i = \|h_i\|_1 $

其中 $ \|\cdot\|_1 $ 表示L1范数。因此，我们得到W的L1归一化幅度乘积分布向量n。

#### 反向传播：通过基于幅度的mask更新梯度
在反向阶段计算梯度后，我们得到权重W的梯度矩阵 $ \nabla W $，它表示给定输入x的优化方向。然后我们定义一个mask矩阵M来部分mask $ \nabla W $，使用前向阶段缓存的L1归一化乘积幅度。形式上，我们按降序对乘积幅度进行排序，并按如下方式mask相应的梯度：

$ t = \lfloor T \times d_{out} \rfloor $

$ M = \text{BinaryTopT}(n, t) $

$ \text{BinaryTopT}(n_i, t) = \begin{cases} 1 & \text{如果} n_i \text{在} n \text{的前} 1-t \text{个元素中} \\ 0 & \text{否则} \end{cases} $

其中T是mask梯度的阈值比率，t是实际要mask的数量t， $ \lfloor \cdot \rfloor $ 是向下取整。

然后模型更新规则为：

$ W_{new} \leftarrow W - \eta \cdot M \odot \nabla W $

其中 $ \eta $ 是学习率。这个公式确保只有那些L1归一化幅度超过阈值T的权重被更新。

### 3.3 MIGU在实践中
在实践中，为了简单实现，我们对批次中所有token的乘积幅度取平均来生成mask。

#### MIGU在Transformer Block中
对于Transformer block，我们将3.2节中的方法应用于多头注意力(MHA)组件中的Query、Key、Value和Output线性层，以及FFN组件中的两个(对于T5和RoBERTa)或三个(对于Llama)线性层。

#### MIGU在LoRA实现中
我们还为LMs的参数高效微调(PEFT)实现了MIGU，特别是我们采用了低秩适应(LoRA)。标准LoRA的数学表示如下：

$ x_A = x \cdot A $  
$ x_B = x_A \cdot B $  
$ x_O = x \cdot W + \frac{\alpha}{r} \cdot x_B $

其中x表示层的输入表示， $ A \in \mathbb{R}^{d_{in} \times r} $ 和 $ B \in \mathbb{R}^{r \times d_{out}} $ 是低秩矩阵， $ \alpha $ 是缩放常数，W是标准线性的原始权重矩阵， $ x_O $ 是应用LoRA变换后的输出。

为了实现MIGU，我们对矩阵A应用3.2节中的相同方法。但对于矩阵B，我们使用等式8中 $ x_O $ 的输出而不是等式9中 $ x_B $ 的输出来计算幅度分布向量。

## 4. 实验
我们使用三种语言模型：编码器-解码器T5模型、编码器RoBERTa和解码器Llama2。我们首先在两个CL数据集上对T5-large进行持续微调，遵循(Qin and Joty， 2021; Wang et al.， 2023b)的设置。我们在普通微调和使用LoRA的PEFT上实现MIGU。我们还将我们的方法与三种主要类型的CL方法结合，以检验我们的方法与现有CL方法的无缝集成。接下来，我们使用编码器RoBERTa对领域自适应数据进行持续预训练，遵循(Ke et al.， 2023)的设置。我们进一步将实验扩展到解码器Llama2-7B，并测试基础模型能力和新任务能力之间的权衡。所有实验结果都报告为3次运行的平均值。

### 4.1 T5-large上的持续微调
#### 两个基准
我们在T5-large上使用标准CL基准和长序列基准评估我们的持续微调方法。我们遵循(Qin and Joty， 2021; Wang et al.， 2023b)的设置，将LM数据集(Zhang et al.， 2015)中的四个文本分类任务打乱成三种不同的顺序，形成标准CL基准的Order 1、2、3。同样，我们将15个任务(五个分类任务、九个GLUE和SuperGLUE任务以及IMDB数据集)打乱，形成长序列基准的Order 4、5、6。

#### 基线
我们将基线分为两类：没有旧数据或任务信息的基线，以及训练期间有旧数据或任务信息的基线。

没有旧数据或任务信息的基线包括：

+ FT：在一系列任务上训练所有模型参数
+ LoRA：在一系列任务上训练固定大小的LoRA参数

有旧数据或任务信息的基线包括：

+ 基于重放的方法：LoRAReplay(使用2%过去任务混合训练新任务的LoRA)、LFPT5
+ 基于架构的方法：IncLoRA、MoELora、SAPT-LoRA、MoCL
+ 基于参数的方法：OIncLoRA

我们还有一个多任务学习基线MTL作为基准的"上限"参考。

#### 指标
ACC(准确率)：在最后一个任务上训练后所有任务的平均性能，即 $ A_T = \frac{1}{T}\sum_{t=1}^T a_{T,t} $。

#### T5上的结果
表2显示，我们提出的方法(+MIGU)改善了所有五种CL方法的性能。值得注意的是，当应用我们的方法时，普通FT和LoRA基线看到了实质性的改进。使用我们的方法获得的一些结果与利用任务标签或旧任务数据的SOTA CL方法相当。特别是，LoRA+MIGU方法在长序列基准上比普通LoRA方法显著提高了15.2%，大大缓解了LoRA在具有长序列的CL设置中的缺点。

我们选择将我们的方法与三种基于LoRA的技术结合，以与利用旧数据或额外标签的三种CL方法集成。基于参数的IncLoRA+MIGU相对于原始IncLoRA表现出最显著的改进，这表明我们基于幅度的方法可以有效缓解CF 现象。

在IncLoRA中顺序学习的LoRA参数之间的冲突。基于参数的OIncLoRA+MIGU相对较小的改进表明，我们的方法和将LoRA投影到正交子空间具有类似的功能，但我们的方法不需要在持续训练过程中使用任务标签。SAPT-LoRA在长序列基准上实现了最先进的性能，但它需要任务标签和过去的数据，这在LMs设置中通常是不可行或成本高昂的。

我们还在附录D.2表10中报告了效率研究，以显示我们的方法仅导致普通方法上的微小开销，这假定比其他CL方法更有效。我们在附录D.1表8中提供了完整的实验。我们还绘制了小提琴图来显示我们的方法相对于基线的统计显著性，详见附录D.1。

为了更直观地展示我们的结果与基线的比较，我们绘制了小提琴图，显示了在完全微调条件下有无我们方法的性能。这些图表清晰地展示了MIGU方法在各种设置下的性能提升。

#### 阈值选择的消融研究
由于当前的指令微调数据集(如标准CL基准)通常缺乏单独的开发集，我们进行了消融研究，手动为标准CL基准中的每个任务从训练数据中创建1，000个样本的开发集。我们使用这个新的分割数据集来评估FT、FT+MIGU、LoRA和LoRA+MIGU方法的mask阈值选择。我们的发现如图4所示，表明0.7的阈值对FT+MIGU和LoRA+MIGU都是最优的。

#### 梯度Mask组件的消融
我们进一步研究了应该在transformer块的哪些组件中使用MIGU。通常，一个transformer块由六个线性层组成：MHA模块中的查询、键和值(QKV)线性层和输出线性层(O)，以及FFN中的两个线性层。我们的分析(如表5所示)表明，在所有这些线性层中使用MIGU可以实现最佳的整体性能，这表明基于幅度的方法对transformer架构中不同部分的线性层都是有效的。

### 4.2 RoBERTa上的持续预训练
#### 基准
与之前的持续微调设置相比，Ke等人(2023)引入了DAS，这是一个用于LMs持续预训练(CPT)的新基准。DAS由六个无标签领域语料库组成，包含三个评论领域和三个学术论文领域。然后使用六个相应的分类数据集进行评估。与持续微调不同，CPT分两个阶段进行：

1. 在每个领域上连续顺序预训练
2. 分别在每个领域上持续微调对应的终端任务

#### 指标
对于持续预训练，我们遵循(Ke et al.， 2023)使用MF1(宏F1)和ACC(准确率)来评估在最后一个领域上预训练后的性能。

#### 基线
我们选择了一系列顶级基线，包括：

+ 普通方法：顺序在领域上预训练RoBERTa的全参数(FT)和使用PEFT Adapter
+ 基于重放的方法：DER++
+ 基于架构的方法：DEMIX
+ 基于参数的方法：HAT-Adapter和DAS

#### RoBERTa上的结果
我们在另一个设置中评估MIGU，在这个设置中，我们连续预训练RoBERTa模型到六个领域。我们的实验结果(如表3所示)也显示了我们的方法优于或与使用任务标签或旧数据的复杂CL方法相当的有希望的结果。例如，FT+MIGU在MF1上实现了0.37%的改进，在ACC上实现了0.42%的改进。

我们还探讨了不同顺序的领域的性能。我们在表4中报告了首先和最后两个学习领域的平均ACC。结果表明，虽然DAS模型在较早学习的领域表现出较少的遗忘，但在最后的领域学习较少，这可能是由于在长序列的CL过程中使用了强正则化来约束其参数更新。相比之下，MIGU展示了一种更可持续的方法，在较早和最近学习的领域都表现出稳健的性能。

### 4.3 扩展到Llama2：更少遗忘和同样学习
我们进一步评估了我们的方法在更具挑战性的LLM持续指令调优设置中的表现。我们在Magicoder-Evol-Instruct-110K上对基础Llama2-7B进行了32个epoch的微调。这个数据集(Wei et al.， 2024)包含72.97M个编程问题和答案的token。然而，由于计算限制，我们只抽样了20%的数据并在LoRA上进行了实验。

我们遵循(Biderman et al.， 2024)的方法，评估LoRA+MIGU在基础能力(遗忘领域)和代码能力(学习领域)上的表现。为了评估代码学习性能，我们使用了Humaneval基准(Chen et al.， 2021)，它包含164个问题，要求生成带有文档字符串和函数签名的Python程序。如果生成通过所有提供的单元测试，则认为是正确的。为了量化它们忘记了多少先前知识，我们遵循(Biderman et al.， 2024)使用三个基准的平均分数：HellaSwag(Zellers et al.， 2019)、WinoGrade(Sakaguchi et al.， 2019)和ARC-challenge(Clark et al.， 2018)。

实验结果如图3所示。与基线FT相比，我们的方法学习了类似水平的新代码知识，但表现出明显更少的先前知识遗忘。这表明我们的方法在学习可塑性和记忆稳定性之间的Pareto前沿上实现了更好的权衡点(Huang， 2003; Wang et al.， 2024a)。例如，在32个训练epoch后，我们方法在三个基准上的平均准确率为59.4，而基线模型只达到58.4。

## 5. 讨论
### 5.1 梯度Mask阈值的消融
我们对梯度mask阈值进行了更详细的消融研究。我们使用原始标准CL基准，并绘制了我们方法(+MIGU)在梯度mask阈值从0.0到0.9的所有五条曲线，如图13所示。FT+MIGU、LoRA+MIGU和IncLoRA+MIGU设置的最佳阈值为0.7，而LoRAReplay+MIGU为0.4。OIncLoRA+MIGU仅为0.1，这可能是由于OIncLoRA方法本身的参数更新正则化。IncLoRA+MIGU的最佳值为0.6，接近FT+MIGU、LoRA+MIGU和IncLoRA+MIGU设置。

令人惊讶的是，即使只更新5%(T=0.95)或1%(T=0.99)的参数，LoRA+MIGU仍然大幅优于LoRA。这个有趣的发现可能表明，只有一小部分具有大幅度的比例权重对成功的CL设置至关重要，这可能值得未来进一步研究。

### 5.2 可视化
为了研究我们的方法如何提高模型性能，我们可视化了FT模型和使用我们的MIGU技术增强的FT模型之间的乘积幅度变化，如图5所示。我们使用热图来描绘不同任务间乘积幅度分布的相似性。我们的发现清楚地表明，实现MIGU的FT模型的任务相似性明显降低。这表明使用我们方法训练的模型对不同任务表现出更独特的权重激活，从而减少了它们之间的冲突。这种激活模式的区别表明我们的方法能够在模型中培养更多特定于任务的表示，从而在各种学习场景中贡献其改进的性能。

我们还绘制了T5-large模型第23个FFN层第一个线性层上COPA样本、BoolQA样本和Yelp样本的L1归一化幅度分布，如图17所示。这进一步说明了不同任务之间幅度分布的差异。

## 6. 结论
我们提出了MIGU，这是一种无需重放和无需任务标签的方法，只更新LM线性层中具有大输出幅度的模型参数。通过在梯度更新过程中施加这个简单的约束，我们可以利用LMs的内在行为，从而解锁它们天生的CL能力。我们的实验应用于所有三种LM架构(T5、RoBERTa和Llama2)，在两种CL场景(持续微调和持续预训练)和四个CL基准上，始终提供更好的性能。我们的方法还可以无缝集成到现有的CL解决方案中，以进一步提高它们的性能。

## 7. 局限性
我们承认这项工作有两个局限性：

1. 由于计算限制，虽然我们使用LoRA微调了Llama2-7B，但我们无法将实验扩展到LM持续预训练或完全微调。然而，我们在持续预训练RoBERTa上的实验性能表明这种一般方法具有很大的可扩展性潜力。
2. 我们只探索了通过更新输出幅度的梯度来解锁LMs固有CL潜力的方法。正如在相关工作部分讨论的那样，还存在更多关于利用固有特征(如激活稀疏性)的讨论。虽然我们在附录的表11中包含了初步结果，但这个局限性可以在未来的工作中进一步解决。

总的来说，MIGU为语言模型的持续学习开辟了一个新的视角，展示了利用模型内在特性来改善性能的潜力。未来的研究可以进一步探索这种方法在更大规模模型和更多样化任务上的应用，以及与其他CL技术的结合。

