> 原文：《<font style="color:rgb(41, 38, 27);background-color:rgb(245, 244, 239);">Understanding Catastrophic Forgetting and Remembering in Continual Learning with Optimal Relevance Mapping</font>》
>

## 1. 引言
连续学习是指模型以序列方式学习不同的数据和任务,类似于人类通常遇到的学习方式。然而,与人类或动物学习不同,人工神经网络(ANNs)更倾向于以并发方式学习,并且已被证明会发生灾难性遗忘。神经网络中的灾难性遗忘(CF)通常用来定义ANNs在有新信息出现时无法保留旧信息的情况。

### 1.1 连续学习(CL)的定义
连续学习范式指的是ANNs严格按顺序在不同数据和任务上训练。重要的训练条件包括:

1. 顺序训练:对于单个神经网络f,参数θ在时间T内使用顺序可用的数据D1...N进行训练:

```plain
T1[fθ(D1)] < T2[fθ*(D2)] < ... < TN[fθ**(DN)]
```

2. 无负面样本、示例或反馈:不能向网络提供未来(或过去)的数据样本作为当前数据/任务的参考。

```plain
(D1 ∩ DT) ∪ ... ∪ (DT-1 ∩ DT) ∪ (DT ∩ DT+1) ∪ (DT ∩ DT+2)... ∪ (DT ∩ DT+N) = ∅
```

### 1.2 灾难性遗忘和记忆
灾难性遗忘(CF)是连续学习的直接影响,主要被认为是网络中分布式表示重叠的直接结果。大多数先前的工作通过完全消除表示重叠或更频繁地重放以前任务的数据来处理CF。数据重放方法可以处理CF,但反过来会导致网络区分新旧输入的能力降低。这被称为灾难性记忆(CR),已被证明是重放方法的一个重要限制。

本文的目标是开发一种连续学习方法,同时缓解灾难性遗忘和灾难性记忆的双重问题,而不违反或放宽严格连续学习框架的条件。

## 2. 相关工作
连续学习的当前机制主要分为以下几类:

+ 正则化方法:如EWC和LWF,对权重更新施加约束以缓解灾难性遗忘。
+ 动态架构:随着新任务的加入动态调整网络结构。 
+ 互补学习系统:利用多个子系统来平衡稳定性和可塑性。
+ 重放架构:存储过去观察样本的记忆来缓解遗忘问题。

目前还没有已知的方法能在连续学习框架中同时处理灾难性遗忘和记忆问题。

## 3. 严格连续学习与灾难性记忆
### 3.1 灾难性遗忘的概率视角
从概率角度来看,给定初始学习的参数集θi和任务i的数据Di,当网络从新数据Di+1学习新的参数集θi+1时,原参数会被覆盖。可以用贝叶斯规则计算任务的条件概率:

对于第一个任务:

$ \log P(\theta_1|D_1) = \log P(D_1|\theta_1) + \log P(\theta_1) - \log P(D_1) $

对于第二个任务:

$ \log P(\theta_{1:2}|D_{1:2}) = \log P(D_2|\theta_2) + \log P(D_1|\theta_1) + \log P(\theta_1) - \log P(D_1) - \log P(D_2) $

如果不对两个任务的θ1和θ2同时优化似然项,先验信息就会被覆盖,导致灾难性遗忘。

### 3.2 灾难性记忆
灾难性记忆(CR)是指模型在序列学习过程中突然失去区分新旧数据/任务的能力。可以从概率角度理解CR:

对于第n个任务:

$ \log P(\theta_{1:n}|D_{1:n}) = \log P(D_n|\theta_n) + \sum_{i=1}^{n-1} \log P(D_i|\theta_i) + \log P(\theta_1) - C $

当先验项远大于当前优化的似然项时,即:

$ \log P(D_n|\theta_n) \ll \sum_{i=1}^{n-1} \log P(D_i|\theta_i) $

模型就会对新输入产生虚假的熟悉感,无法区分新旧输入。

## 4. 用于连续学习的关联映射
本文提出了关联映射方法,旨在学习最优的表示重叠,使得不相关任务使用不同的网络参数,同时允许相似任务有表示重叠。

### 4.1 关联映射的算法实现
以一个简单的两层多层感知机为例:

$ f(x) \triangleq \sigma(W_2\sigma(W_1x)) $

其中 $ x \in \mathbb{R}^{d_1} $, $ W_1 \in \mathbb{R}^{d_2 \times d_1} $, $ W_2 \in \mathbb{R}^{d_3 \times d_2} $, σ表示非线性激活函数。

定义权重集合 $ W \triangleq \{W_1, W_2\} $。即使对于简单的MLP设置,过度参数化也会发生。对于足够简单的任务,W中只需要一个子集的参数。

如果我们能学习每个权重节点的重要性或关联性,我们可以对非必要参数应用零掩码而无需修剪它们,仍然可以成功学习真实函数。定义一组映射 $ M^P = \{M^P_1, M^P_2\} $,其中 $ M^P_1 \in \{0,1\}^{d_2 \times d_1} $, $ M^P_2 \in \{0,1\}^{d_3 \times d_2} $,显式表示网络的神经元到神经元连接。

初始化的关联映射可以用logit-normal分布混合来近似,在推理时进行四舍五入:

$ M^P_k \approx \prod_k L_R N(\mu_k, \sigma^2_k) $

其中LR是sigmoidal伪四舍五入函数:

$ L_R(x_k; \beta) = \frac{1}{1 + \exp(-(β(x_k - 0.5)))} $

这样做是为了使映射可微分,各个混合成分与网络参数一起联合优化。

### 4.2 关联映射的概率解释
关联映射保留了分布和可分离性的想法,但不限制在顺序任务之间学习的后验表示的显式分离。相反,分离由关联映射提供。

对于第一个任务:

$ P(\theta_1, M^P_1|D_1) \propto P(D_1|\theta_{M^P_1})P(\theta_{M^P_1}) $

对于第二个任务:

$ P(\theta_{1:2}, M^P_2|D_{1:2}) \propto P(D_2|\theta_{M^P_2})P(\theta_1, M^P_1|D_1) $

这里第二项由于独立的关联映射而不对第二个任务的优化做出任何贡献,有效地分解了顺序任务参数。

对于n个任务:

$ P(\Theta, M^P|D_{1:n}) \propto \prod_{i=1}^n P(D_i|\theta_{M^P_i})P(\theta''_i) $

这表明关联映射算法能够学习良好分离和分布的内部表示,从而处理灾难性遗忘问题。由于模型参数与关联映射MP共同优化,网络不会对特定任务过度泛化,从而处理灾难性记忆问题。

## 5. 实验
### 5.1 监督连续学习(测试灾难性遗忘)
实验设置:

+ 使用标准基准架构,包括CNNs、Siamese Networks和Residual Networks
+ 对每个任务的分类输出定义为:

$ f(x; W, M^P_1, ..., M^P_T) \triangleq \argmax_{i \in \{1...T\}}(\{f(x; W, M^P_i)\}) $

+ 损失函数加入MP掩码的L1范数惩罚项和MP1, ..., MPT)重叠和,以奖励稀疏性和权重空间的最优分离

模型:  
评估了5个基准测试:Permuted-MNIST、Split-MNIST、Sequential Omniglot、10任务Split-Cifar100和20任务Split-Cifar100 (RES-CIFAR)

结果:  
关联映射网络(RMNs)在所有连续学习基准测试中都达到了新的最先进水平,相比之前的SOTA分别提高了2.8% (P-MNIST)、0.5% (S-MNIST)、3.9% (S-Omnliglot)、8.7% (S-Cifar100)和13.9% (RES-CIFAR)。

RMNs在简单(MLP)和复杂(ResNet)架构上,以及长期(S-Omniglot, RES-CIFAR)和短期连续学习中都表现出色,展示了其多功能性。

### 5.2 无监督连续学习(测试灾难性记忆)
提出两个测试来衡量灾难性记忆:

1. (无监督)新任务/数据检测
2. 无监督任务推理

#### 5.2.1 新任务/数据检测
设置:

+ 模型在训练(和推理)时没有任务信息
+ 将结果与完全监督版本进行比较
+ 假设没有任务标签信息,包括不同任务的数量

RMN方法:

+ 初始化f只有一个MP,即初始化时只能学习一个前向推理路径
+ 设置当前任务指示器est_j = 0
+ 对每个小批量x,运行任务切换检测(TSD)方法TSD(x),返回布尔值
+ 如果TSD(x)返回True,则est_j增加,并向f添加另一组MP
+ 使用修改的Welch's t检验来确定任务切换

结果:  
RMNs在无监督连续学习设置中达到了最先进的性能,而不使用数据重放缓冲区、专家模型混合或任何生成重放。

#### 5.2.2 无监督任务推理
设置:

+ 算法必须在推理时识别数据输入属于它已学习的所有任务中的哪一个
+ 训练后,对测试数据进行随机化并提供给模型进行推理,不提供任务身份
+ 模型识别数据所属的任务,然后计算整个任务集上正确识别任务的测试准确率

RMN方法:

+ 推理时不给出任务j,返回maxk f(x, k; W)
+ 实验结果表明,对于任何真实任务标签j,所需结果是f(x, j; W) ≈ maxk f(x, k; W),这允许无监督CL推理,因为不同任务的路径不会重叠,除非任务相同

结果:

RMN是唯一已知的在严格CL设置约束下能够成功完成无监督任务推理的连续学习方法。

## 6. 结论
本研究探讨了连续学习中灾难性遗忘和记忆的双重问题。为了解决这些问题,我们引入了用于连续学习的关联映射,它在每个任务的学习过程中同时学习神经网络参数的关联图。具体而言,关联映射学习顺序学习任务之间网络参数的最优重叠,减少不相似任务的表示重叠,同时允许相关任务的网络参数重叠。我们证明了我们的模型能有效地处理灾难性遗忘和记忆,并在不放宽严格连续学习框架条件的情况下,在广泛的流行基准测试中达到最先进的性能。

