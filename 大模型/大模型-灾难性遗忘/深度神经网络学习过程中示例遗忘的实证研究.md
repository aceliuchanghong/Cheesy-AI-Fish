> 原文：《<font style="color:rgb(41, 38, 27);background-color:rgb(245, 244, 239);">AN EMPIRICAL STUDY OF EXAMPLE FORGETTING DURING DEEP NEURAL NETWORK LEARNING</font>》

## 1. 引言
本文受到灾难性遗忘现象的启发，研究了神经网络在单个分类任务训练过程中的学习动态。研究目标是了解在数据没有明显分布变化的情况下是否会发生相关现象。文章定义了"遗忘事件"的概念:当一个训练样本在学习过程中从分类正确转变为分类错误时，就发生了遗忘事件。

通过对几个基准数据集的研究，作者发现:

1. 某些样本经常被遗忘，而另一些样本从未被遗忘。
2. 一个数据集的(不)可遗忘样本在不同的神经网络架构中具有普遍性。
3. 根据遗忘动态，可以从训练数据集中省略相当大比例的样本，同时仍然保持最先进的泛化性能。

## 2. 相关工作
本节介绍了与本研究相关的先前工作，包括课程学习、样本加权、深度学习泛化等方面。

### 2.1 课程学习和样本加权
课程学习是一种从简单到复杂的示例顺序学习范式。Kumar等人(2010)将简单示例定义为具有较小损失的示例。Arpit等人(2017)也提出了简单示例的存在，并将其定义为在训练1个epoch后就能正确分类的示例。本文的实验验证了不可遗忘示例可以安全地从训练集中移除而不影响泛化性能。

### 2.2 深度学习泛化
近期的研究表明，泛化误差不仅取决于假设空间的复杂性。例如，参数数量远超训练样本数量的过参数化模型仍然可以达到较低的测试误差(Huang等，2017; Wang等，2018)。一个可能的解释是随机梯度下降(SGD)执行了一种隐式正则化:在线性可分情况下，通过SGD训练的深度神经网络已被证明会收敛到最大边际解(Soudry等，2017; Xu等，2018)。本文提供了经验证据，表明即使移除大量训练样本并且不限制假设类的复杂性，也可以保持泛化性能。这与Soudry等人(2017)提供的支持向量解释一致。

## 3. 定义和计算示例遗忘
### 3.1 基本设置
考虑标准分类设置。给定数据集 $ D = (x_i, y_i)_i $ 包含观测/标签对，目标是使用参数为 $ \theta $ 的深度神经网络学习条件概率分布 $ p(y|x; \theta) $。网络通过最小化经验风险进行训练:

$ R = \frac{1}{|D|}\sum_i L(p(y_i|x_i; \theta), y_i) $

其中 $ L $ 表示交叉熵损失，$ y_i \in \{1, ..., k\} $。最小化通过随机梯度下降的变体进行，从初始随机参数 $ \theta_0 $ 开始，通过从数据集 $ D $ 中随机采样示例。

### 3.2 遗忘和学习事件
记 $ \hat{y}_i^t = \arg\max_k p(y_{ik}|x_i; \theta_t) $ 为在 $ t $ 步 SGD 后对示例 $ x_i $ 的预测标签。令 $ acc_i^t = 1_{\hat{y}_i^t = y_i} $ 为一个二元变量，表示示例在时间步 $ t $ 是否被正确分类。当 $ acc_i^t $ 在两次连续更新之间减少时，即 $ acc_i^t > acc_i^{t+1} $，示例 $ i $ 发生遗忘事件。换言之，示例 $ i $ 在步骤 $ t+1 $ 被错误分类，而在步骤 $ t $ 被正确分类。相反，如果 $ acc_i^t < acc_i^{t+1} $，则发生学习事件。

### 3.3 分类边际
分类边际定义为正确类别的 logit 与其他类别中最大 logit 的差值:

$ m = \beta_k - \arg\max_{k' \neq k} \beta_{k'} $

其中 $ k $ 是正确类别的索引。

### 3.4 不可遗忘示例
如果一个示例在某个时刻被学习，并且在整个训练过程中没有发生遗忘事件，则将其称为不可遗忘示例。形式上，示例 $ i $ 是不可遗忘的，如果其首次被学习的时间 $ t^* $ 满足 $ t^* < \infty $，且对于所有 $ k \geq t^* $，有 $ acc_i^k = 1 $。根据这个定义，在训练过程中从未被学习的示例不被视为不可遗忘。至少被遗忘一次的示例被称为可遗忘示例。

### 3.5 程序描述和实验设置
监测遗忘事件需要在每次模型更新时计算数据集中所有示例的预测，这在计算上是昂贵的。在实践中，作者对每个示例的完整遗忘事件序列进行子采样，仅在示例包含在当前小批量中时计算遗忘统计。这给出了示例在训练过程中经历的遗忘事件数量的下界。

实验评估在三个复杂性递增的数据集上进行:MNIST、permutedMNIST(对所有示例的像素应用相同的固定排列)和CIFAR-10。使用了各种模型架构和训练方案，在各自的数据集上达到了与当前最先进水平相当的测试误差。具体来说:

+ MNIST实验使用了由两个卷积层和一个全连接层组成的网络，使用带动量的SGD和dropout进行训练，达到0.8%的测试误差。
+ CIFAR-10使用了带cutout的ResNet，使用带动量的SGD和特定学习率调度进行训练，达到3.99%的测试误差。

## 4. 示例遗忘的特征
### 4.1 遗忘事件数量
作者估计了三个不同数据集(MNIST、permutedMNIST和CIFAR-10)中所有训练示例的遗忘事件数量，跨5个随机种子进行。结果显示:

+ MNIST: 55,012个不可遗忘示例(91.7%的训练集)
+ permutedMNIST: 45,181个不可遗忘示例(75.3%的训练集)
+ CIFAR-10: 15,628个不可遗忘示例(31.3%的训练集)

较低复杂度和多样性的数据集(如MNIST)似乎包含明显更多的不可遗忘示例。permutedMNIST的复杂度介于MNIST(最简单)和CIFAR-10(最难)之间。这一发现似乎表明遗忘统计与学习问题的内在维度之间存在相关性。

### 4.2 跨种子的稳定性
为了测试指标相对于随机梯度下降产生的方差的稳定性，作者计算了10个不同随机种子下每个示例的遗忘事件数量，并测量它们的相关性。不同种子之间的平均Pearson相关系数为89.2%。将10个不同种子随机分成两组5个时，这两组内累积的遗忘事件数量显示出97.6%的高相关性。

### 4.3 首次学习事件
研究表明，不可遗忘和可遗忘示例需要不同次数的展示才能首次被学习。可遗忘示例集包含更多在训练后期才首次学习的示例。首次学习事件展示次数与遗忘事件数量之间的Spearman秩相关为0.56，表明存在中等程度的关系。

### 4.4 错分类边际
遗忘事件数量与平均错分类边际之间的Spearman秩相关为-0.74。这表明经常被遗忘的示例具有较大的错分类边际。

### 4.5 视觉检查
通过可视化CIFAR-10数据集中的不可遗忘示例和最常被遗忘的示例，发现:

+ 不可遗忘样本容易识别，包含最明显的类别属性或中心对象，例如晴朗天空中的飞机。
+ 最常被遗忘的示例表现出更模糊的特征，可能与该类别其他示例的常见学习信号不一致。

### 4.6 噪声示例检测
为了进一步研究高度可遗忘示例是否具有非典型类别特征，作者随机更改了20%的CIFAR-10标签，并记录了训练过程中噪声示例和常规示例的遗忘事件数量。结果显示:

+ 最常被遗忘的示例是那些带有噪声标签的示例。
+ 没有噪声示例是不可遗忘的。
+ 与原始标签相比，噪声标签的示例表现出更高程度的遗忘。

这些结果支持了高度可遗忘示例表现出非典型类别特征的假设。

## 5. 移除不可遗忘示例
作者研究了在训练过程中完全移除给定子集示例的可能性。实验结果显示:

+ 当随机移除数据集的子集时，性能迅速下降。
+ 通过按遗忘事件数量排序移除示例，可以移除30%的数据集而保持与基础模型相当的泛化性能，最多可移除35%而只有轻微降低(不到0.2%)。
+ 移除具有越来越多遗忘事件的5,000个示例会导致更差的泛化性能，但曲线最右端的上移表明一些最常被遗忘的示例实际上会损害性能。这些可能对应于异常值或标签错误的示例。

这些结果支持了深度神经网络作为最大边际分类器的解释，并表明一些数据点对于决策边界的学习比其他数据点更重要。遗忘事件数量是检测这种"支持向量"的相关指标，它与错分类边际(决策边界距离的代理)有很好的相关性。

## 6. 可转移的遗忘事件
作者研究了示例的遗忘统计在多大程度上依赖于特定的架构、优化器和训练轮数。

### 6.1 训练过程中的稳定性
计算了在训练结束时(200个epoch)获得的排序与不同epoch数后获得的排序之间的Spearman秩相关。结果显示:

+ 75个epoch后排序非常稳定
+ 25个epoch就可以获得良好的相关性

### 6.2 跨架构的稳定性
作者探讨了是否可以从更简单的架构(而不是残差网络)获得排序。他们训练了一个包含两个卷积层和两个全连接层的网络，并将结果排序与ResNet18获得的排序进行比较。结果显示:

+ 卷积神经网络和ResNet18的不可遗忘示例之间存在相当强的一致性。

作者还使用ResNet18的示例排序在截断的数据集上训练了一个WideResNet。结果显示:

+ 使用ResNet18的排序，WideResNet在移除30%数据集的情况下仍然接近最优性能。

这为使用较小架构计算遗忘统计开辟了有前景的途径。

## 7. 结论与未来工作
本文受灾难性遗忘现象的启发，研究了神经网络在单个分类任务训练过程中的学习动态。主要发现包括:

1. 即使在通常被认为是单个任务的情况下，也可能发生灾难性遗忘。
2. 任务内的一些示例更容易被遗忘，而其他示例则始终不可遗忘。
3. 遗忘统计似乎相对于各种训练特征相当稳定，这表明它们实际上揭示了数据的内在属性，而不是训练方案的特性。
4. 不可遗忘的示例似乎在分类器的最终性能中几乎不起作用，因为它们可以从训练集中移除而不影响泛化。

这些发现支持了将深度神经网络解释为线性情况下的最大边际分类器的最近研究。

未来工作包括:

+ 从理论角度更好地理解遗忘事件
+ 探索潜在的应用到监督学习的其他领域，如语音或文本
+ 应用到强化学习，其中由于底层分布的持续变化，遗忘普遍存在

总的来说，这项研究为理解深度神经网络的学习动态提供了新的见解，并为提高数据效率和模型性能开辟了潜在的途径。

