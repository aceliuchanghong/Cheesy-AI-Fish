> 原文：《<font style="color:rgb(41, 38, 27);background-color:rgb(245, 244, 239);">Investigating the Catastrophic Forgetting in Multimodal Large Language Models</font>》
>

## 1. 引言
随着GPT-4的成功，多模态大语言模型(MLLM)研究引起了广泛关注。这类研究主要集中在通过微调预训练的语言模型和视觉模型来开发通用LLM。然而，灾难性遗忘仍然是多模态LLM的一个固有问题。灾难性遗忘是指微调后的模型无法保持与预训练模型相似的性能。

本文提出了EMT(Evaluating MulTimodality)框架，用于评估MLLM中的灾难性遗忘现象。我们首先将EMT应用于评估几个开源的微调MLLM，发现几乎所有评估的MLLM在标准图像分类任务上都无法保持与其视觉编码器相同的性能水平。

此外，我们继续对LLaVA(一个MLLM)进行微调，并使用EMT评估整个微调过程中的性能。有趣的是，我们的结果表明，在图像数据集上进行早期微调通过增强文本和视觉特征的对齐来改善其他图像数据集的性能。然而，随着微调的进行，MLLM开始出现幻觉，导致泛化能力显著下降，即使图像编码器保持冻结。

我们的结果表明，MLLM在标准图像分类任务上尚未展示出与其视觉模型相当的性能，当前的MLLM微调程序仍有改进的空间。

## 2. 相关工作
### 微调和灾难性遗忘
微调大型预训练模型显著改变了自然语言处理领域。尽管微调LLM取得了显著成就，但仍然存在灾难性遗忘等核心机器学习问题。灾难性遗忘在LLM微调或上下文学习中广泛存在，因为LLM倾向于过拟合小规模微调数据集，导致在其他任务上的性能下降。为缓解LLM微调中的灾难性遗忘问题，提出了多种方法，包括预训练权重衰减、学习率衰减、正则化和对抗性微调。然而，在MLLM中，这种灾难性遗忘现象尚未得到深入研究。

### 多模态大语言模型
多模态大语言模型(MLLM)作为视觉语言模型的重要进展，显著提高了模型的推理能力。这些模型旨在处理和解释来自多个模态(如文本和图像)的信息，以执行需要全面理解上下文的复杂任务。最近的工作通过利用LLaMA等LLM的强大推理能力，为MLLM的开发和增强做出了贡献。LLaVA提出了一种在机器生成的多模态语言-图像指令跟随数据上进行指令调优的新方法，在多模态聊天能力和Science QA准确率方面取得了令人印象深刻的结果。

## 3. 图像分类的微调
为验证少数类崩溃理论启发的结果，我们首先对ResNet进行预训练和微调进行图像分类。接下来，为进一步研究视觉语言模型中的灾难性遗忘，我们对对比语言-图像预训练网络(CLIP)进行微调实验。

### 3.1 图像分类的预训练和微调
我们首先在传统图像分类基准上训练ResNet18。具体来说，我们首先在初始50%的类别上预训练100个epoch。然后，我们在剩余50%的类别上微调100个epoch，使得微调类别和预训练类别不重叠。由于NC理论主要关注分析训练损失，我们只呈现前50%预训练类别的平均训练准确率(见图2)。值得注意的是，当微调开始时，所有数据集上预训练类别的训练准确率迅速降至零。正如前面章节所讨论的，这种灾难性遗忘现象可以直接与少数类崩溃相关联，当多数类和少数类之间的不平衡比例趋于无穷大时，所有少数类的分类器收敛到一个单一顶点。因此，观察到的性能下降符合我们的预期。

![](https://i.imgur.com/QvXKQvY.png)

### 3.2 对比语言-图像预训练网络的微调
接下来，我们对CLIP ViT-L-14模型的视觉编码器进行微调，从OpenAI CLIP通过openCLIP提供的检查点开始。在我们的实验中，我们采用标准交叉熵损失，与CLIP预训练和神经崩溃分析以及少数类崩溃分析中使用的方法一致。文本输入是通过将标签与简短描述连接创建的。

![](https://i.imgur.com/QvXKQv7.png)

实验结果表明，视觉语言模型如CLIP在微调后容易出现神经崩溃。特别是，我们观察到域内性能显著提升，而域外数据集性能开始下降。到达15个epoch时，几乎所有域内性能指标都上升到接近99%，但域外性能已经受损。

## 4. EMT： 评估多模态大语言模型
由于先前的MLLM评估框架侧重于评估认知推理或幻觉，而不是从图像分类角度评估灾难性遗忘，我们提出了EMT，一个用于评估多模态LLM的框架。EMT的工作流程如下：

1. 我们首先输入来自分类任务的图像;
2. 然后我们提示测试MLLM，要求它根据提供的提示对输入图像进行分类并收集其输出;
3. 接下来，由于MLLM的输出可能不符合特定格式，我们应用GPT-3.5来评估分类准确率;
4. 最后，我们输出测试MLLM在不同数据集上的预测准确率。

EMT提示：

```plain
What is the number/object in the image? Please only answer a single
number/object in [class labels].
```

### 4.1 开源MLLM中的灾难性遗忘
在本小节中，我们首先应用EMT评估四个MLLM：LLaVA、Otter、InstructBLIP和LENS。如图4所示，大多数测试的开源MLLM都存在灾难性遗忘问题，无法保持与各自视觉编码器的零样本分类结果相似的分类性能。一个显著的例外是InstructBLIP-7b，它在CIFAR-10数据集上表现略好。尽管InstructBLIP的表现略优于其基础视觉模型，但InstructBLIP在CIFAR-100和miniImagenet上无法达到与LLaVA和Otter相似的性能。大多数测试的MLLM无法保持与其基础视觉模型相似的性能可能看起来令人惊讶，但事后看来，这种性能下降是可以预料的。这种性能下降可能源于MNIST、CIFAR-10、CIFAR-100和miniImagenet的分类未纳入评估MLLM的训练数据集。

![](https://i.imgur.com/QvXKQv8.png)

### 4.2 MLLM的失败模式分析
在使用EMT提示检查不同模型的输出后，我们确定了导致性能下降的三个主要问题：错误预测、内在幻觉和外在幻觉。显然，MLLM可能会像分类器一样产生错误预测。在下面的示例中，LLaVA-7B在MNIST分类中错误地将"0"预测为"8"。

```plain
img 
Label： 0 | LLaVA-7b
The number in the image is 8：
```

除了错误预测外，性能还受到幻觉的显著影响 - 测试的MLLM有时会生成看似相关但不正确或无法验证的内容。Ji等人进一步将幻觉分为两个不同的类别：内在幻觉和外在幻觉。内在幻觉被定义为生成的输出直接与源内容矛盾的情况。外在幻觉则是指输出与原始源内容没有可验证的联系。

内在幻觉：

```plain
img 
Label： horse | LENS
airplane， automobile， bird， cat， deer， dog， frog， horse，
```

外在幻觉：

```plain
img 
Label： aquarium_fish | InstructBLIP-7b
a picture of a fish in a tank
```

基础LM的重要性： 在所有测试的MLLM中，图4显示LENS在每个单独任务和总体性能上都达到了最差的性能。考虑到LENS的底层视觉编码器ViT-H-14并没有表现出显著的性能不足，我们假设观察到的性能差距归因于基础LM。这是因为Otter、LLaVA和InstructBLIP都采用LLaMA模型，而LENS使用Flan-T5模型，后者不如LLaMA强大。然而，我们的结果并不一定意味着更大的LM总是会产生更好的性能，因为我们的实验揭示了不同的结果。例如，虽然LLaVA-13b通常优于LLaVA-7b，但InstructBLIP-13b并未表现出优于InstructBLIP-7b的优势。因此，我们认为需要进行额外的实验来确定更大的LM是否可以改善MLLM中视觉和文本数据的集成。

## 5. EMT在多模态大语言模型微调中的应用
配备EMT后，我们现在研究MLLM微调中的幻觉。我们使用LLaVA-7b和LLaVA-13b作为我们的基础MLLM进行微调。我们分别在MNIST、CIFAR-10、CIFAR-100和miniImagenet上进行微调实验。所有微调实验都基于2023年7月4日发布的LLaVA模型进行。

线性和LoRA微调： 如Liu等人所讨论的，LLaVA模型包含一个冻结的基础视觉编码器g(·)和一个由ϕ参数化的预训练LLM f_ϕ(·)。对于输入图像X_v，LLaVA首先通过应用视觉编码器将X_v映射为视觉特征向量Z_v = g(X_v)。然后，LLaVA应用线性适应层W，将视觉特征映射到文本特征空间H_v = W · Z_v，并将H_v与语言查询的嵌入H_q连接成视觉和文本嵌入向量[H_v， H_q]。最后，LLaVA将[H_v， H_q]作为输入送入预训练的LLM f_ϕ(·)以获得响应。对于具体的微调方法：(1)线性微调方法只微调线性适应层W;(2)LoRA微调方法微调线性适应层W和预训练的LLM f_ϕ(·)，使用LoRA。

### 5.1 实验设置和概述
鉴于LLaVA依赖视觉和语言指令数据进行训练和微调，我们手动重新格式化了MNIST、CIFAR-10、CIFAR-100和miniImagenet等数据集，以符合微调所需的格式。所有微调实验都使用2个Nvidia A100 GPU进行。我们分别使用线性和LoRA微调对LLaVA-7b和LLaVA-13b进行微调，由于计算资源的限制，我们无法微调整个LLaMA模型。我们首先报告3个epoch线性和LoRA微调后LLaVA-7b和LLaVA-13b的EMT评估准确率(图5)。为评估训练期间的准确率变化，我们然后报告1-3个微调epoch的EMT评估结果(图6和7)。

### 5.2 过度微调导致遗忘
我们首先在图5中展示3个epoch的微调结果。虽然LLaVA在微调数据集上的性能确实有所提高，但图5揭示了MLLM微调的一个关键问题：

在一个数据集上微调MLLM会降低其在另一个非微调数据集上的性能。

这种现象虽然并不意外，但值得注意。由于模型没有接触到除了微调数据集之外的数据集，因此可以理解会观察到类似于灾难性遗忘的效果，如4.1节所讨论的。

![](https://i.imgur.com/QvXKQv9.png)

当我们检查微调后LLaVA的输出时，我们发现：微调MLLM会导致幻觉，通过输出与其微调数据集相关的文本，同时忽略与其原始提示相关的问题。

为进一步说明这种现象，我们提供了使用EMT提示对在不同数据集上微调的LLaVA-7b和LLaVA-13b进行分类的明确示例。

EMT提示：

```plain
What is the object in the image? Please only answer a single object in
airplane， automobile， bird， cat， deer， dog， frog， horse， ship， truck.
```

上述示例说明，当CIFAR-10微调模型在CIFAR-10上测试时，LLaVA确实成功识别了对象。然而，在其他数据集上微调后，LLaVA模型开始在CIFAR-10分类中产生幻觉。

img   
Label： airplane | LLaVA-7b-lora-ft-mnist  
The airplane is 8.

在前面的示例中，通过MNIST微调模型对CIFAR-10进行分类时，模型不仅部分生成了关键词"airplane"，还同时产生了幻觉输出，生成了数字"8"的表示。在CIFAR-100和miniImagenet微调模型中也观察到类似现象。具体来说，这些微调模型开始通过预测与"airplane"相似或相关的类别来产生幻觉，例如CIFAR-100模型中的"butterfly"和miniImagenet模型中的"aircraft carrier"。

img   
Label： airplane | LLaVA-7b-lora-ft-cifar100  
The object is a(n) butterfly.

img   
Label： airplane | LLaVA-7b-lora-ft-miniimagenet  
The object is a(n) aircraft carrier.

### 5.3 适度微调是有益的
在前一小节中，我们展示了3个epoch微调的LLaVA在微调数据集上实现了更好的性能，但代价是在其他数据集上测试时生成幻觉文本。然而，这个结果并不一定意味着微调会降低性能。值得注意的是，我们实际上观察到非微调数据集上的性能有所改善。例如，如图5所示，LLaVA-7b在CIFAR-10上进行3个epoch的微调后，在miniImagenet上表现有所改善。为了更好地理解微调中的泛化性，我们在所有四个数据集上进行了3个epoch的微调实验，并报告了每个epoch的准确率。

微调适配器改善特征对齐： 如图6所示，我们观察到线性微调的LLaVA在RGB数据集(即CIFAR-10、CIFAR-100和miniImagenet)上微调时实现了泛化性能。考虑到线性微调只影响连接视觉特征到文本嵌入空间的线性投影层，图6暗示早期微调有助于增强视觉和文本特征之间的对齐。然而，在后续微调epoch(2-3)中，LLaVA开始过拟合微调数据集，生成幻觉文本。

微调LLM和适配器导致幻觉： 与线性微调相反，图7暗示联合微调LLM和线性适配器直接导致过拟合微调数据集。这从LoRA微调模型在非微调数据集上的性能在仅仅一个epoch训练后就显著下降的事实得到证实。

![](https://i.imgur.com/QvXKQvB.png)

## 6. 结论
在本文中，我们研究了微调如何影响MLLM中的灾难性遗忘。为定量评估这个问题，我们提出了EMT，一个用于评估MLLM微调性能的框架。我们得出以下结论：

1. 几乎所有测试的开源MLLM都无法达到与其基础视觉编码器在零样本性能上相似的准确率水平。
2. 在一个数据集上过度微调后，LLaVA在非微调数据集上的性能会恶化，因为它开始过拟合和产生幻觉。
3. 适度微调实际上可以改善LLaVA在类似任务上的性能，因为微调有助于早期阶段的视觉和文本特征对齐。

## 7. 讨论和未来工作
数据集多样性对微调很重要： 图6显示，在CIFAR-10、CIFAR-100和miniImagenet上微调一个epoch的LLaVA可以泛化到其他两个数据集，而在MNIST上微调LLaVA导致所有剩余数据集的性能下降。这一观察表明，拥有多样化的微调数据集很重要。这是因为更多样化的数据集将具有更多模式的特征，从而使微调的MLLM受到灾难性遗忘的影响较小。

超越图像分类的灾难性遗忘： 作为起点，我们只从图像分类的角度研究MLLM中的灾难性遗忘，因为它是标准的分类问题。在未来，我们相信可以为其他场景开发类似的评估方法，例如减少对不安全输出的偏见、降低视觉定位推理能力，甚至幻觉。

后处理输出： 值得注意的是，在EMT的步骤(3)中，使用openaiAPI并不是评估MLLM生成输出正确性的唯一解决方案。未来有几种可能的解决方案：

1. 利用句子嵌入模型。可以将N个格式化的真实短语输入句子嵌入模型(如CLIP文本编码)，得到N个真实嵌入{e_i}，其中i∈{1，···，N}。对于测试样本生成的文本y，我们可以输入其CLIP文本嵌入e(y)，并使用argmin_i ||e_i - e(y)||_2计算匹配的真实值i。
2. 也可以硬编码(如找到标签名称的存在)处理幻觉的决策标准。

需要注意的是，为EMT找到一个完美的后处理方法并不容易，因为不同数据集的标签可能有许多同义词。例如，在评估LLaVA对miniImagenet中的African_hunting_dog标签时，很难确定"dog"的预测是否应该被认为是正确的。因此，我们认为在未来构建后处理方法时，也应该考虑到这种同义词的混淆。

总的来说，本研究为理解和改进MLLM中的灾难性遗忘问题提供了重要见解。未来的工作可以集中在开发更有效的微调策略，以及探索更多样化的评估方法，以全面理解MLLM的性能和局限性。

