> 原文：《<font style="color:rgb(41, 38, 27);background-color:rgb(245, 244, 239);">Fine-Grained Gradient Restriction： A Simple Approach for Mitigating Catastrophic Forgetting</font>》
>

## 1. 引言
连续学习(CL)的一个基本挑战是在学习新任务和保持先前获得的知识之间取得平衡。本文提出了一种名为细粒度梯度限制(Fine-Grained Gradient Restriction)的简单方法来改进梯度回放记忆(Gradient Episodic Memory, GEM)算法。

连续学习的主要挑战是在记住先前获得的知识和学习新任务知识之间取得平衡。在一个极端情况下,直接在新任务上使用梯度下降学习,往往会大幅降低模型在先前学习任务上的性能。这种现象被称为灾难性遗忘(catastrophic forgetting)。在另一个极端情况下,如果固定模型参数,显然不会忘记学过的任务,但也无法学习任何未来任务。这种现象被称为固执(intransigence),即无法为新任务更新知识。在内存有限的情况下,CL算法应用于固定大小的模型时,必须在相互冲突的遗忘和固执之间寻求最佳平衡。

GEM是一种在CL中权衡遗忘和固执的流行方法。直观地说,在梯度下降的每次迭代中,GEM在一个搜索空间中寻找更新方向,该空间中与过去任务梯度的内积为非负(见图1)。因此,该搜索空间中的每个方向都不会增加过去任务的损失。在该搜索空间内,GEM选择与当前学习任务梯度距离最小的更新方向来更新模型。由于无法存储所有观察到的数据,过去任务的梯度是通过计算从每个先前任务中子采样的数据点(称为回放记忆)上的梯度来近似的。

理想情况下,如果回放记忆大小无限,可以期望GEM能够在不遗忘的情况下学习。然而,在实践中,由于回放记忆大小有限,GEM只能确保在回放记忆上计算的损失不会增加,这并不一定意味着过去任务的损失不会增加。换句话说,由于回放记忆无法覆盖全部观察数据,存在泛化差距。

本文发现,通过对更新方向的搜索空间施加更强和非平凡的约束,可以有效减少这种泛化误差。具体来说,本文提出将存储在回放记忆中的数据点分成多个部分,并在每个部分上形成新的梯度约束,或者将GEM约束分别应用于底层模型参数的不同部分。该方法能够减少灾难性遗忘,而不会过度加剧固执,从而实现更好的权衡。为了减轻引入新约束带来的开销,本文提出了一种计算效率高的方法来近似求解具有更多约束的优化问题。该算法被称为模块化GEM(mGEM)。实验表明,mGEM在标准CL基准和多域数据集上都能持续实现比GEM更好的记住旧知识和学习新知识的帕累托前沿。

## 2. 背景
### 2.1 回放记忆梯度
在实践中,学习机器通常使用梯度下降进行训练。给定某个数据集D上的损失$ L_D[f_\theta] $,假设学习机器由参数$ \theta $参数化,使用梯度下降,参数迭代更新为：

$ \theta \leftarrow \theta - \epsilon g $

其中$ g = \nabla_\theta L_D $是当前迭代的损失梯度,$ \epsilon $是学习率。由于灾难性遗忘,直接将梯度下降应用于连续学习问题是次优的。为了缓解遗忘,GEM搜索一个不同的更新方向z,该方向不会增加先前任务的损失,同时尽可能减少当前任务的损失。

为了实现这一点,在学习任务t之前,GEM为每个过去的任务$ s \in [t-1] $分配一个"回放记忆"$ \hat{D}_s $,这是从$ D_s $中观察到的样本子集。在每次迭代中,GEM通过求解以下约束优化问题将g替换为修改后的更新方向z：

$ \min_z \|g_t - z\|^2 \quad \text{s.t.} \quad \langle \hat{g}_s, z \rangle \geq 0, \forall s < t $

这里定义$ g_t = \nabla_\theta L_{D_t}[f_\theta] $,是为当前任务t计算的梯度。此外,$ \hat{g}_s = \nabla_\theta L_{\hat{D}_s}[f_\theta] $是在过去任务s的回放记忆$ \hat{D}_s $上计算的梯度。最后,模型使用(1)的解$ z^* $代替普通梯度进行更新：

$ \theta \leftarrow \theta - \epsilon z $

### 2.2 前向和后向迁移的帕累托前沿
本文第4节的分析表明,(5)的原问题实际上等价于：

$ \min_{z \in Z} \|g_t - z\|^2 \quad \text{s.t.} \quad \langle \hat{g}_s, z \rangle \geq \gamma_s, \forall s \in [t-1] $

其中$ \gamma_s $是一些依赖于q的正常数。q较大的GEM对$ \langle \hat{g}_s, z \rangle $施加更强的约束,迫使其值更大,从而增加后向迁移,例如降低过去任务的损失。在第4节中,本文表明这种更强的约束很重要,因为它缓解了使用整个数据点子集作为回放记忆所导致的泛化差距。另一方面,随着约束变强,可行集变小,因此返回更大的目标解,例如新任务的损失减少更少。图2(蓝线)提供了这种权衡的一个例子。每条线都是通过改变记忆强度q获得的。

## 3. 模块化GEM
GEM能够通过引入记忆强度在后向和前向迁移之间实现良好的帕累托前沿。受此启发,本文提出了两种新的简单但有效的方法来更灵活地约束更新方向的搜索空间,这些方法被证明可以实现比具有记忆强度的GEM(统一)更好的帕累托前沿(见图2)。GEM在整个回放记忆上计算整个模型的梯度,这导致每个任务一个约束。本文的方法将该梯度分成几个梯度,这些梯度要么从模型的不同部分计算,要么从回放记忆的不同划分计算。由于本质上将梯度划分为多个模块,因此将该方法命名为模块化GEM(mGEM)。

### 参数式mGEM
第一种方案是将神经网络的参数$ \theta $划分为D个子坐标：$ \theta = [\theta_1, \theta_2, ..., \theta_D] $。然后将GEM分别应用于每个子坐标。这种方法被称为p-mGEM。

$ \min_z \|g_t - z\|^2 \quad \text{s.t.} \quad \langle \hat{g}_s^d, z \rangle \geq \gamma_s^d, \forall s \in [t-1], d \in [D] $

其中$ \hat{g}_s^d = \nabla_{\theta_d} L_{\hat{D}_s}[f_\theta] $。注意,所有$ \hat{g}_s^d $都可以通过对完整模型进行一次反向传播计算得到。

### 数据式mGEM
类似地,也可以将回放记忆划分为几个组：$ \hat{D}_s = \cup_{d=1}^D \tilde{D}_s^d $,然后分别应用GEM。这种方法被称为d-mGEM,考虑以下问题：

$ \min_z \|g_t - z\|^2 \quad \text{s.t.} \quad \langle \tilde{g}_s^d, z \rangle \geq \gamma_s^d, \forall s \in [t-1], d \in [D] $

其中$ \tilde{g}_s^d = \nabla_\theta L_{\tilde{D}_s^d}[f_\theta] $。对于数据式mGEM,计算时间变为D倍,因为需要为回放记忆的每个分割分别计算梯度。

总之,当D > 1时,参数式和数据式mGEM都会导致比原始GEM更受限的搜索空间,当D = 1时,退化为GEM。通过调整$ \gamma_s^d $的值(或对偶问题中的q),mGEM也可以结合记忆强度的思想。

### 3.1 mGEM在实践中的应用
尽管引入更多约束自然会导致更受限的搜索空间,从而有助于防止遗忘,但它也会带来计算开销。因此,本文提出了一种近似求解(7)和(8)中优化问题的方法。对于每个d,对应于d的优化模仿原始GEM方法。因此,类似地求解对偶问题,其形式为：

$ \min_v \frac{1}{2}\|\hat{G}^T v + g\|^2, \quad \text{s.t.} \quad v \geq q, \quad \text{where} \quad q > 0 $

本文提出在两个阶段近似求解优化问题,而不是用二次规划求解器精确求解。首先忽略约束,闭式求解优化问题,然后将解投影回可行空间。具体来说：

+ 在第一阶段,求解：

$ \min_\nu \frac{1}{2}\|\hat{G}^T \nu + g\|^2 $

最优解为$ \nu^* = -(\hat{G}\hat{G}^T)^{-1}\hat{G}g $。回顾任务t,$ \hat{G} = -[\hat{g}_1, ..., \hat{g}_{t-1}]^T \in \mathbb{R}^{(t-1) \times n} $,其中n表示模型$ f_\theta $的参数大小。这里计算$ (\hat{G}\hat{G}^T)^{-1} $项大约需要$ O(t^2n) $时间。由于随机高维向量的内积接近于零,我们通过用其对角矩阵近似$ (\hat{G}\hat{G}^T)^{-1} $来简化计算,得到解：

$ \tilde{\nu}^* = -H\hat{G}g, \quad \text{where} \quad H = \text{diag}((\hat{g}_1^T \hat{g}_1)^{-1}, ..., (\hat{g}_{t-1}^T \hat{g}_{t-1})^{-1}) $

注意,H可以使用标准深度学习库在一个批次中高效计算。

+ 在第二阶段,将解投影回可行空间并确保$ v \geq q $：

$ \tilde{v}^* = [v_1^*, ..., v_{t-1}^*]^T, \quad \text{where} \quad v_i^* = \max(\tilde{\nu}_i^*, q_i) $

总之,最终的更新方向由以下公式给出：

$ z = \hat{G}^T \max(-H\hat{G}g, q) + g_t $

然后将等式(10)应用于mGEM中考虑的所有模块。

## 4. 分析
本节提供了关于为什么提出的mGEM能够改进性能的分析。将这个问题分为三个步骤。为简单起见,考虑只有两个任务的情况：机器已经学习过的过去任务s,和机器正在学习的当前任务t。将分析推广到任意有限数量的任务是直接的。

### 4.1 GEM的泛化
尽管GEM保证防止$ L_{\hat{D}_s} $增加,但GEM无法确保$ L_{D_s} $不增加。原因是回放记忆只是观察到的样本的子集,因此$ \hat{D}_s $上的损失与$ D_s $上的损失之间存在泛化差距。

假设有$ \langle \hat{g}_s, z \rangle \geq \gamma $,均匀浓度不等式表明,对于任何$ \delta > 0 $,以概率$ 1-\delta $,有$ \langle g_s, z \rangle \geq \gamma - \Delta $,其中$ \Delta $是由z的搜索空间的复杂度和$ \delta $引起的一些偏差。具体来说,有以下结果：

**假设1** 对于所有先前任务,这些任务上的真实梯度范数是有界的：

$ \|g_s\|_{2,\infty} := \sup_{(x,y) \in D_s, \theta \in \Theta} \|\nabla_\theta \ell(f_\theta; x, y)\| < \infty $

**命题1** 给定z的某个搜索空间Z,假设$ z^* $是以下问题的解：

$ \min_{z \in Z} \|g_t - z\|^2 \quad \text{s.t.} \quad \langle \hat{g}_s, z \rangle \geq 0, \forall s \in [t-1] $

对于任何$ \delta > 0 $，以至少$ 1-\delta $的概率，我们有：

$ \langle g_s, z^* \rangle \geq \langle \hat{g}_s, z^* \rangle - \Delta $

其中，

$ \Delta = 2R_{|\hat{D}_s|}[Z] + \sup_{z \in Z} \|z\| \|g_s\|_{2,\infty} \sqrt{\frac{\log(1/\delta)}{|\hat{D}_s|}} $

这里$ \Delta $是泛化差距，$ R_{|\hat{D}_s|}[Z] $表示集合Z的Rademacher复杂度。

上述命题刻画了后向迁移的最坏情况泛化性质。我们可以看到，为了改善后向迁移，我们可以增加$ \langle \hat{g}_s, z^* \rangle $，减少泛化差距，或者同时做到这两点。

### 4.2 理解记忆强度
本文对泛化性质的分析解释了为什么记忆强度是GEM中一个有效的技巧。我们从改善后向迁移的最自然方式开始：增加$ \langle \hat{g}_s, z^* \rangle $。通过应用更强的约束，我们考虑前面提到的问题(6)：

$ \min_{z \in Z} \|g_t - z\|^2 \quad \text{s.t.} \quad \langle \hat{g}_s, z \rangle \geq \gamma_s, \forall s \in [t-1] $

设$ \gamma = [\gamma_1, ..., \gamma_{t-1}]^T $是给定的非负超参数。通过鼓励$ \langle \hat{g}_s, z \rangle $严格为正，我们能够根据命题1改善非负后向迁移的概率。(6)的对偶问题是：

$ \min_v \|\hat{G}_t^T v + g_t\|^2 - \gamma^T v, \quad \text{s.t.} \quad v \geq 0 $

与具有记忆强度的GEM的对偶问题(5)相比，(11)通过在目标中添加正则化项$ (-\gamma^T v) $来强制执行正的$ \gamma $(记忆强度)。从这个角度来看，具有记忆强度的GEM等价于问题(6)。为简单起见，在本文的其余部分，我们也将(11)称为具有记忆强度的GEM。

### 4.3 后向迁移的最坏情况分析
根据命题1中的分析，我们知道GEM通过鼓励更大的 $ \langle \hat{g}_s, z \rangle $ 来减少泛化差距。类似地，mGEM也鼓励更大的内积，因此能获得更好的泛化。具体来说，我们有以下命题：

**命题2** 假设 $ z^* $ 是(1)的解，$ z^*_{MS} $ 是具有记忆强度 $ \gamma_s $ 的(6)的解。对于参数式GEM，假设 $ \sum_{d=1}^D \gamma_s^d \geq \gamma_s $ 并返回解 $ z^*_{p-mGEM} $。对于数据式GEM，假设 $ \min_{d \in [D]} \gamma_s^d \geq \gamma_s $，并返回解 $ z^*_{d-mGEM} $。那么我们有：

$ \langle \hat{g}_s, z^*_{p-mGEM} \rangle \geq \langle \hat{g}_s, z^*_{MS} \rangle \geq \langle \hat{g}_s, z^* \rangle $

$ \langle \hat{g}_s, z^*_{d-mGEM} \rangle \geq \langle \hat{g}_s, z^*_{MS} \rangle \geq \langle \hat{g}_s, z^* \rangle $

因此，在减少泛化差距方面，p-mGEM和d-mGEM都比具有记忆强度的GEM表现更好，而后者又比原始GEM表现更好。

上述分析通过最坏情况分析提供了关于mGEM和具有记忆强度的GEM如何改善后向迁移的理论洞察。

### 4.4 mGEM实现更好的帕累托前沿
与具有记忆强度的GEM相比，mGEM提供了两种不同的方式来修改约束，因此可以在前向和后向迁移上实现更好的帕累托前沿。为了说明这一点，本文对Split CIFAR100基准应用了具有不同模块数和不同记忆强度的p-mGEM和d-mGEM。绘制了局部后向和前向迁移的帕累托前沿。如等式(2)和(3)所述，通过计算 $ \langle g_t, z \rangle $ 的平均值来衡量前向迁移。为了衡量后向迁移，考虑 $ \langle g_s, z \rangle $，其中过去任务的梯度是在完整训练集而不是回放记忆上计算的。详细信息请参阅附录。图2展示了结果。我们看到，当p-mGEM/d-mGEM有更多模块时，后向迁移更大，而当模块较少时，前向迁移更大。由于对应于更大后向迁移(因此更少遗忘)的区域对于典型的CL问题更重要，mGEM给出了明显的改进。注意，通过允许自适应数量的模块，mGEM实现了比GEM统一更好的帕累托前沿(图2中的黄线)。

## 5. 相关工作
为了防止深度学习中的灾难性遗忘，最近提出了三大类方法。

### 基于正则化的方法
基于正则化的方法引入额外的训练目标，限制模型参数接近先前学习的参数。流行的方法通常采用概率视角，将旧参数视为在学习新任务之前模型参数的先验。具体来说：

+ EWC (Kirkpatrick et al., 2017)使用从先前任务计算的Fisher信息矩阵来正则化学习。
+ PI (Zenke et al., 2017)计算每个神经元的局部"重要性"度量，并根据该重要性对更新进行正则化。
+ RWALK (Chaudhry et al., 2018)和VCL (Nguyen et al., 2017)使用KL散度作为正则化。

### 可扩展架构
可扩展架构不是对固定大小模型的更新方向进行正则化，而是尝试最大限度地重用从先前任务学习的部分参数，并在发生固执时引入新参数。

+ PROG-NN (Rusu et al., 2016)为网络的每一层引入固定数量的神经元，并学习侧向连接。
+ DEN (Yoon et al., 2017), Learn-to-grow (Li et al., 2019)和CPG (Hung et al., 2019)专注于通过允许动态扩展来实现网络的更有效增长。

### 基于记忆的方法
一种简单而有效的防止遗忘的方法是存储一小部分样本(即回放记忆)用于记忆巩固。

+ DGR (Shin et al., 2017)学习一个可以生成人工记忆的生成模型，但它引入了存储生成模型的内存开销。
+ GEM (Lopez-Paz & Ranzato, 2017)使用回放记忆设置一个可行空间来搜索新的梯度更新方向。
+ OGD (Farajtabar et al., 2020)将新任务上的梯度投影到一个子空间，在该子空间中，投影梯度不会影响模型在旧任务上的输出。
+ MER (Riemer et al., 2018)最近提出采用元学习目标来学习不遗忘。
+ 由于GEM的最优解是当前和先前任务梯度的线性组合，MEGA (Guo et al., 2019)研究了如何通过考虑任务损失来形成更好的线性组合。

本文提出的方法与GEM密切相关。然而，本文专注于解释缩小搜索新更新方向的可行空间的权衡。特别是，除了如何选择和使用回放记忆之外，本文还关注这些存储的记忆如何形成更好的可行空间，使得找到的更新方向能够实现更好的帕累托前沿。

## 6. 实验
在本节中，首先将mGEM应用于标准连续学习基准，并显示mGEM可以优于GEM。然后将mGEM进一步应用于具有更多非平稳性的数据集，其中每个子任务来自不同的域。将mGEM与以下相关基线进行比较：

+ Single：直接使用随机梯度下降(SGD)在任务序列上学习的单个模型。它对应于完全忽视遗忘并只专注于学习当前任务的一个极端。
+ Independent：每个任务的独立预测器，具有与任务数量成比例的较少隐藏神经元。
+ EWC：弹性权重巩固(Elastic Weight Consolidation, EWC) (Kirkpatrick et al., 2017)是一种流行的基于正则化的方法，采用Fisher信息矩阵来防止灾难性遗忘。
+ GEM：梯度回放记忆(Gradient Episodic Memory, GEM) (Lopez-Paz & Ranzato, 2017)是本文主要比较的对象。GEM使用回放记忆来计算可行空间以搜索新的更新方向。
+ MER：元回放记忆(Meta Episodic Memory, MER) (Riemer et al., 2018)是一种最先进的回放记忆基线，采用元学习目标来防止遗忘。

遵循Lopez-Paz & Ranzato (2017)的做法，本文报告最终保留精度(ACC)和知识的后向迁移(BWD)作为主要比较指标。此外，还报告平均学习精度，即每个任务在学习后的平均精度，作为模型能够向前学习新任务的程度(FWD)的衡量标准。具体来说，假设总共有T个任务，将 $ R_{i,j} $ 表示为学习到任务i后在任务j上的保留精度，那么：

$ \begin{aligned}
ACC &= \frac{1}{T} \sum_{i=1}^T R_{T,i} \\
BWD &= \frac{1}{T} \sum_{i=1}^T (R_{T,i} - R_{i,i}) \\
FWD &= \frac{1}{T} \sum_{i=1}^T R_{i,i}
\end{aligned} $

由此可得 $ ACC = BWD + FWD $，这意味着BWD和FWD自然地相互权衡，因此更好的算法将导致更好的ACC。

### 6.1 标准连续学习基准
首先将mGEM应用于Lopez-Paz & Ranzato (2017)中使用的三个标准连续学习基准。

1. MNIST Permutations：由20个任务组成的序列，每个任务由MNIST像素的固定排列生成。
2. MNIST Rotations：基于MNIST (LeCun et al., 1998)的20个连续任务的另一个变体。每个任务通过将MNIST数字旋转0到180度之间的固定角度生成。因此，MNIST Permutations和MNIST Rotations都有20个10类分类任务。
3. Split CIFAR100：将CIFAR数据集(Krizhevsky et al., 2009)中的100个类别分成20个子任务，每个子任务是一个5类分类任务。

对于MNIST Permutations和MNIST Rotations，在具有100个隐藏单元的两层神经网络上进行测试。此外，采用Lopez-Paz & Ranzato (2017)的原始设置，其中每个任务的256个随机样本被存储为回放记忆。对于每个任务，在进入下一个任务之前，用批量大小为10训练模型500次迭代。

对于Split CIFAR100，在由5个卷积层堆叠组成的更大网络上进行测试。从每个任务中采样64个样本作为回放记忆，并以25的批量大小训练每个任务100次迭代。

对于GEM和mGEM，从{0.0, 0.05, 0.1, 0.2, 0.3, 0.5, 0.8, 1.0}中选择最佳的q，使用验证集。更详细的架构和超参数信息在附录中提供。

表1显示了三个基准的结果。注意，在MNIST Permutations和MNIST Rotations上，MER实现了最佳的最终精度。但在全面搜索超参数后，发现MER在Split CIFAR100数据集上表现要差得多。本文认为主要有两个原因：

1. 由于MNIST Permutations和MNIST Rotations中的任务高度相关，MER的元训练目标有助于提高零样本泛化能力，因此MER可以实现更高的FWD。但Split CIFAR100数据集中的任务相关性较小，因此元学习目标变得不那么有效。
2. 众所周知，元学习需要大量数据。因此，在像Split CIFAR100这样更具挑战性但样本较少的数据集上，像MER这样的元学习算法变得更难学习。

另一方面,请注意在所有数据集上,mGEM都优于GEM并改善了BWD,这证实了添加更多限制有助于模型减少遗忘。这种效果在两个MNIST数据集上不太明显,因为架构的大小限制。但在Split CIFAR100上,mGEM将平均精度提高了1.93个百分点。

#### FWD和BWD之间的权衡
为了分析mGEM如何帮助改善整体性能,本文进行了具有不同模块数量的mGEM的消融研究。结果如图3所示。这里,x轴和y轴分别对应BWD和FWD。p-mGEM(n)表示将完整网络分成n个模块。例如,由于Split CIFAR100中考虑的网络有5个卷积层加4个批归一化层,p-mGEM(9)本质上将每个卷积和批归一化层视为单个模块。类似地,d-mGEM(n)表示将回放记忆分成n个相等的部分,形成n个梯度约束。从图2可以看出,随着n的增加,p-mGEM在FWD和BWD之间达到更好的权衡,当n大于9时,我们看不到进一步的改进。d-mGEM(2)的表现优于GEM,但d-mGEM(3)的性能下降。这可能是因为d-mGEM(3)对每个回放记忆有3个约束,过度缩小了搜索空间。

#### mGEM在不同架构上的表现
既然我们观察到mGEM比GEM有所改进,我们想知道其性能是否对所使用的架构敏感。因此,本文将mGEM应用于4种常用的深度架构：AlexNet (Krizhevsky et al., 2012)、带批归一化层的VGG-11 (VGG11-bn)、带批归一化层的VGG-16 (VGG16-bn) (Simonyan & Zisserman, 2014)和ResNet-18 (He et al., 2016)。由于这些架构规模较大,我们在Split CIFAR100的10路分割上进行实验,即CL问题由10个10路分类任务的序列组成。结果如图4所示。我们可以看到,md-GEM在所有架构上都始终优于GEM。同时,使用3.1节中的近似方法,approx-GEM导致与GEM相似或更少的计算时间,但ACC更高。

### 6.2 五位数字和DomainNet数据集
在上述所有连续学习基准中,任务序列最初都是从同一域中采样的。在连续学习的实际应用中,学习者更可能遇到来自不同域的任务。因此,在本节中,我们进一步将mGEM应用于具有更严重域偏移的数据集。特别是,我们考虑Digit-Five数据集和DomainNet数据集(Peng et al., 2019),这两个数据集都是域适应问题的标准基准。

+ "Digit-Five"数据集包括五个流行的数字数据集(MNIST (LeCun et al., 1998)、MNIST-M (Ganin & Lempitsky, 2015)、Synthetic Digits (Ganin & Lempitsky, 2015)、SVHN (Netzer et al., 2011)和USPS)。
+ DomainNet (Peng et al., 2019)由6个域(剪贴画、绘画、快速绘画、信息图、真实、素描)组成,每个域有345个常见物体类别。

示例数据如图5所示。

对于Digit-Five数据集,我们随机生成5个不同的5个数据集排列,每个数据集包含5K个随机采样的图像。然后我们按顺序将CL算法应用于5个数据集。对于每个数据集,我们以256的批量大小训练模型20个epoch。

对于DomainNet数据集,我们在任意两个不同域之间进行训练,这导致30 (6×5)种可能的迁移方式。对于每种迁移方式,我们随机抽样10个物体,形成2路5类分类任务,并在其上应用CL算法。我们对每种迁移方式重复此过程3次。因此,总共有90个连续学习问题。在训练期间,我们以32的批量大小在每个域上进行训练。

对于评估,我们报告ACC、FWD和BWD,所有这些都在运行次数上取平均(Digit-Five为5次,DomainNet为90次)。对于d-mGEM,我们始终将回放记忆分成2部分。对于p-mGEM,我们始终将每个卷积和批归一化层视为一个模块。

表2总结了结果。从表2中,我们可以看到所有mGEM方法都始终优于GEM和其他基线方法,显著改善了BWD。有趣的是,我们观察到mGEM不仅没有损害FWD,甚至还能改善FWD。

## 7. 结论
本文分析了梯度回放记忆(GEM)如何平衡记住旧知识和学习新知识。具体来说,本文表明,限制更新方向的搜索空间本质上减少了由回放记忆大小有限导致的泛化差距。基于这一分析,本文提出了两种引入额外梯度限制的新方法,以实现更好的帕累托前沿。在标准连续学习基准和多域数据集上的实验表明,所提出的方法始终优于GEM。

## 附录
### A. 实验细节
#### A.1 关于图2的详细说明
在实验部分(第6节),我们采用了先前连续学习文献中使用的常规指标来评估不同方法的性能。这些指标,如ACC、BWD和FWD,都是基于学习精度计算的,可能与基于梯度内积的训练目标不直接对应。因此,在图2中,我们直接绘制了使用更新方向与当前和先前任务梯度的计算内积来衡量的前向和后向迁移之间的权衡。具体来说,在图2中,我们在模型学习完第二个任务后计算这些内积,即s = 1且t = 2。因此,x轴对应于更新方向z与$ g_s $之间的平均内积,类似地,y轴对应于更新方向z与$ g_t $之间的平均内积。

#### A.2 数据集详细信息
对于Digit-Five数据集,我们将每个数据集中的每张图像调整为28×28的分辨率(与MNIST输入相同)。然后我们将所有图像像素归一化为均值为0,标准差为1。对于DomainNet数据集,我们将图像调整为96×96的分辨率,并将所有图像归一化到[0, 1]范围内。

#### A.3 网络架构
对于常规CL基准的实验,我们对MNIST Permutations和MNIST Rotations数据集都采用具有2个隐藏层、每层100个神经元的神经网络。对于Split CIFAR100,网络架构为Conv2d(3, 128, 4, 2, 1)、Conv2d(128, 256, 4, 2, 1)、Conv2d(256, 512, 4, 2, 1)、Conv2d(512, 1024, 4, 2, 1)、Conv2d(1024, 100, 2, 1, 0)。这里,我们用Conv2d(输入通道数,输出通道数,核大小,步长,填充)表示2D卷积层。在任意两个卷积层之间插入一个批归一化层,并使用ReLU激活函数。

Digit-Five数据集的架构为Conv2d(1,32,3,1,0)、Conv2d(32,64,3,1,0)、Fc(64*144, 128)、Fc(128, 10)。这里Fc(x, y)表示输入维度为x、输出维度为y的全连接层。

DomainNet数据集的架构为Conv2d(3, 64, 3, 2, 1)、Conv2d(64, 128, 3, 2, 1)、Conv2d(128, 256, 3,2, 1)、Conv2d(256, 512, 3, 2,1)、Conv2d(512, 512, 3,2,1)、Conv2d(512, 10, 3, 1, 0)。

### B. 证明
#### B.1 命题1的证明
注意到$ \langle g_s, z \rangle = \mathbb{E}_{(x,y)\sim D_s} \langle \nabla_\theta \ell(f_\theta, x, y), z \rangle $和$ \langle \hat{g}_s, z \rangle = \mathbb{E}_{(x,y)\sim \hat{D}_s} \langle \nabla_\theta \ell(f_\theta, x, y), z \rangle $。定义$ R = \sup_{z\in Z} \|z\| \|g_s\|_{2,\infty} $并考虑函数类

$ H = \left\{h_z(x, y) = \frac{\langle z, \nabla_\theta \ell(f_\theta, x, y)\rangle}{R} : z \in Z\right\} $

注意到$ \sup_{z\in Z,x,y} \langle z, \nabla_\theta \ell(f_\theta, x, y)\rangle \leq \sup_{z\in Z} \|z\| \|g_s\|_{2,\infty} $。使用均匀浓度不等式,对于任何概率,给定任何$ \delta > 0 $,以至少$ 1 - \delta $的概率,我们对任何$ h_z \in H $有

$ \mathbb{E}_{(x,y)\sim D_s} h_z(x, y) \geq \mathbb{E}_{(x,y)\sim \hat{D}_s} h_z(x, y) + 2R_{|\hat{D}_s|}[H] + \sqrt{\frac{\log(1/\delta)}{|\hat{D}_s|}} $

其中$ R_m[H] $是H的期望Rademacher复杂度,定义为

$ R_m[H] = \mathbb{E}\left[\frac{1}{m} \mathbb{E}_{\sigma_i}\left[\sup_{z\in Z}\sum_{i=1}^m \sigma_i \langle \nabla_\theta \ell(f_\theta, x_i, y_i), z\rangle / R\right]\right] $

两边同时乘以R得到

$ \langle g_s, z \rangle \geq \langle \hat{g}_s, z \rangle + 2R_{|\hat{D}_s|}[Z] + R\sqrt{\frac{\log(1/\delta)}{|\hat{D}_s|}} $

其中

$ R_{|\hat{D}_s|}[Z] = \mathbb{E}\left[\frac{1}{m} \mathbb{E}_{\sigma_i}\left[\sup_{z\in Z}\sum_{i=1}^m \sigma_i \langle \nabla_\theta \ell(f_\theta, x_i, y_i), z\rangle\right]\right] $

这给出了所需的结果。

#### B.2 命题2的证明
在开始证明命题2之前,我们先介绍以下引理：

**引理1** 给定参数$ \theta = [\theta_1, ..., \theta_D] $的任意分割。假设$ z^* $是p-mGEM约束优化问题的解：

$ \min_z \|g_t - z\|^2 \quad \text{s.t.} \quad \langle \hat{g}_s^d, z^d \rangle \geq \gamma_s^d, \forall d \in [D] $

假设$ \bar{z}^d $是以下约束问题的解：

$ \min_{z^d} \|g_t^d - z^d\|^2 \quad \text{s.t.} \quad \langle \hat{g}_s^d, z^d \rangle \geq \gamma_s^d $

其中$ g_t^d = \nabla_{\theta^d} L_{D_t}[f_\theta] $。我们有$ z^* = [\bar{z}^1, ..., \bar{z}^d] $。

**证明：** 不失一般性,我们假设所有约束问题都有唯一解。假设$ z^* \neq [\bar{z}^1, ..., \bar{z}^d] $。不失一般性,我们假设$ z^{*1} \neq \bar{z}^1 $,因此$ \|g_t^1 - \bar{z}^1\|^2 < \|g_t^1 - z^{*1}\|^2 $。我们定义$ z' = [\bar{z}^1, z^{*2}, ..., z^{*d}] $。注意到

$ \|g_t - z'\|^2 = \sum_{d=2}^D \|g_t^d - z^{*d}\|^2 + \|g_t^1 - \bar{z}^1\|^2 < \|g_t - z^*\|^2 $

且

$ \langle \hat{g}_s^d, z^{*d} \rangle \geq \gamma_s^d, \forall d \in \{2, 3, ..., D\} $

$ \langle \hat{g}_s^1, \bar{z}^1 \rangle \geq \gamma_s^1 $

这意味着$ z' $也在p-mGEM的可行集中,并且比$ z^* $更优。这导致矛盾。

现在我们开始证明命题2。我们首先证明第一个陈述。不失一般性,我们假设所有约束问题都有唯一解。

_证明 $\langle \hat{g}_s, z^___{MS} \rangle \geq \langle \hat{g}_s, z^_ \rangle$ :** 
我们从证明 $\langle \hat{g}_s, z^*_{MS} \rangle \geq \langle \hat{g}_s, z^* \rangle$ 开始,其中 $\gamma_s \geq 0$。我们考虑两种情况：

情况1： $ \langle \hat{g}_s, z^* \rangle \geq \gamma_s $。在这种情况下,$ z^*_{MS} = z^* $。否则,

$ \|g_t - z^*_{MS}\|^2 < \|g_t - z^*\|^2 $

且

$ \langle \hat{g}_s, z^*_{MS} \rangle \geq \gamma_s \geq 0 $

这意味着$ z^*_{MS} $也在GEM约束问题的可行集中,且$ z^*_{MS} $优于$ z^* $,这导致矛盾。

情况2： $ \langle \hat{g}_s, z^* \rangle < \gamma_s $,因此$ \langle \hat{g}_s, z^*_{MS} \rangle \geq \gamma_s > \langle \hat{g}_s, z^* \rangle $。

在这两种情况下,我们都有$ \langle \hat{g}_s, z^*_{MS} \rangle \geq \langle \hat{g}_s, z^* \rangle $。

_证明 $\langle \hat{g}_s, z^___{p-mGEM} \rangle \geq \langle \hat{g}_s, z^__{MS} \rangle$ :** 
我们然后证明 $\langle \hat{g}_s, z^*_{p-mGEM} \rangle \geq \langle \hat{g}_s, z^*_{MS} \rangle$。我们考虑两种情况：

情况1： $ \langle \hat{g}_s, z^*_{MS} \rangle = \gamma_s $。在这种情况下,我们有

$ \langle \hat{g}_s, z^*_{p-mGEM} \rangle = \sum_{d=1}^D \langle \hat{g}_s, z^{*d}_{p-mGEM} \rangle \geq \sum_{d=1}^D \gamma_s^d \geq \gamma_s $

情况2： $ \langle \hat{g}_s, z^*_{MS} \rangle > \gamma_s $。

注意到这个问题具有强对偶性,因此使用KKT条件,我们有

$ \nabla_z \left[\|g_t - z^*_{MS}\|^2 + v^* (\langle \hat{g}_s, z^*_{MS} \rangle - \gamma_s)\right] = 0 $

$ v^* (\langle \hat{g}_s, z^*_{MS} \rangle - \gamma_s) = 0 $

注意到由于$ \langle \hat{g}_s, z^*_{MS} \rangle > \gamma_s $,我们有$ v^* = 0 $,这意味着$ z^*_{MS} = g_t $。对于每个$ d \in [D] $,如果$ \langle \hat{g}_s^d, z^{*d}_{MS} \rangle \leq \gamma_s^d $(这里我们将$ z^*_{MS} $按$ z^*_{MS} = [z^{*1}_{MS}, ..., z^{*D}_{MS}] $分割),那么我们有

$ \langle \hat{g}_s^d, z^{*d}_{p-mGEM} \rangle \geq \gamma_s^d \geq \langle \hat{g}_s, z^{*d}_{MS} \rangle $

如果$ \langle \hat{g}_s, z^{*d}_{MS} \rangle > \gamma_s^d $,那么我们知道$ z^{*d}_{MS} = g_t^d $也是以下问题的解：

$ \min_{z^d} \|g_t^d - z^d\|^2 \quad \text{s.t.} \quad \langle \hat{g}_s^d, z^d \rangle \geq \gamma_s^d $

使用引理1,我们知道$ z^{*d}_{MS} = z^{*d}_{p-mGEM} $。对于这种情况,我们因此得出$ \langle \hat{g}_s^d, z^{*d}_{p-mGEM} \rangle \geq \langle \hat{g}_s, z^{*d}_{MS} \rangle $。

_证明 $\langle \hat{g}_s, z^___{d-mGEM} \rangle \geq \langle \hat{g}_s, z^__{MS} \rangle$ :** 
现在我们证明 $\langle \hat{g}_s, z^*_{d-mGEM} \rangle \geq \langle \hat{g}_s, z^*_{MS} \rangle$。我们考虑两种情况：

情况1： $ \langle \tilde{g}_s^d, z^*_{MS} \rangle \geq \gamma_s^d $对所有$ d \in [D] $成立。在这种情况下,使用类似的论证,我们可以证明$ z^*_{MS} = z^*_{d-mGEM} $。

情况2： 对某些$ d \in [D] $,$ \langle \tilde{g}_s^d, z^*_{MS} \rangle < \gamma_s^d $。在这种情况下

$ \langle \hat{g}_s, z^*_{MS} \rangle \leq \gamma_s \leq \min_{d \in [D]} \gamma_s^d \leq \min_{d \in [D]} \langle \tilde{g}_s^d, z^*_{d-mGEM} \rangle \leq \langle \hat{g}_s, z^*_{d-mGEM} \rangle $

结合这两种情况,我们得到了所需的结果。

**泛化差距陈述的证明：**  
对于具有记忆强度$ \gamma_s $的GEM,我们定义以下集合：

$ Z_{MS,n}(\gamma_s) = \cup_{\hat{D}_s} \{z : \langle \nabla_\theta L_{\hat{D}_s}[f_\theta], z \rangle \geq \gamma_s\} $

注意,没有记忆强度的GEM是$ Z_{MS,n}(0) $的情况。这里$ \cup_{\hat{D}_s} $表示所有可能的$ \hat{D}_s $的并集,其中$ \hat{D}_s $包含n个i.i.d.训练点。类似地,对于p-mGEM和d-mGEM,我们定义：

$ Z_{p-mGEM,n}(\gamma_s) = \cup_{\hat{D}_s} \{z : \langle \nabla_{\theta^d} L_{\hat{D}_s}[f_\theta], z^d \rangle \geq \gamma_s^d, \forall d \in [D]\} $

$ Z_{d-mGEM,n}(\gamma_s) = \cup_{\hat{D}_s} \{z : \langle \nabla_\theta L_{\hat{D}_s^d}[f_\theta], z \rangle \geq \gamma_s^d, \forall d \in [D]\} $

注意到我们有$ z^* \in Z_{MS,|\hat{D}_s|}(0) $, $ z^*_{MS} \in Z_{MS,|\hat{D}_s|}(\gamma_s) $, $ z^*_{p-mGEM} \in Z_{p-mGEM,|\hat{D}_s|}(\gamma_s) $和$ z^*_{d-mGEM} \in Z_{d-mGEM,|\hat{D}_s|}(\gamma_s) $。

同时注意到$ Z_{MS,n}(\gamma_s) \subseteq Z_{MS,n}(0) $, $ Z_{p-mGEM,n}(\gamma_s) \subseteq Z_{MS,n}(\gamma_s) $和$ Z_{d-mGEM,n}(\gamma_s) \subseteq Z_{MS,n}(\gamma_s) $。

这意味着：

$ R_{|\hat{D}_s|}[Z_{p-mGEM,|\hat{D}_s|}(\gamma_s)], R_{|\hat{D}_s|}[Z_{d-mGEM,|\hat{D}_s|}(\gamma_s)] \leq R_{|\hat{D}_s|}[Z_{MS,|\hat{D}_s|}(\gamma_s)] \leq R_{|\hat{D}_s|}[Z_{MS,|\hat{D}_s|}(0)] $

同时我们有：

$ \sup_{z \in Z_{p-mGEM,|\hat{D}_s|}(\gamma_s)} \|z\|, \sup_{z \in Z_{d-mGEM,|\hat{D}_s|}(\gamma_s)} \|z\| \leq \sup_{z \in Z_{MS,|\hat{D}_s|}(\gamma_s)} \|z\| \leq \sup_{z \in Z_{MS,|\hat{D}_s|}(0)} \|z\| $

这给出了所需的结果。

## 总结
本文提出了一种名为细粒度梯度限制(Fine-Grained Gradient Restriction)的简单方法来改进梯度回放记忆(Gradient Episodic Memory, GEM)算法,以解决连续学习中的灾难性遗忘问题。主要贡献包括：

1. 分析了GEM中常被忽视的超参数 - 记忆强度,并解释了它如何通过进一步约束更新方向来提高经验性能。
2. 提出了两种更灵活地约束更新方向的方法：参数式mGEM和数据式mGEM。这些方法能够在记住旧知识和学习新知识方面实现比使用记忆强度的GEM更好的帕累托前沿。
3. 提出了一种计算效率高的方法来近似求解具有更多约束的优化问题。
4. 在标准连续学习基准和多域数据集上的实验表明,所提出的方法始终优于GEM。
5. 提供了理论分析,解释了为什么mGEM能够改善性能,特别是在减少由有限大小回放记忆导致的泛化差距方面。

这项工作为改进连续学习算法提供了新的思路,特别是在如何更有效地利用回放记忆来平衡遗忘和学习新知识方面。未来的研究方向可能包括将这种细粒度梯度限制的思想扩展到其他连续学习算法,或探索更复杂的模块化策略。

