# 自蒸馏桥接了语言模型微调中的分布差距
> 原文：《Self-Distillation Bridges Distribution Gap in Language Model Fine-Tuning》
>

## 1. 引言
近年来，大型语言模型(LLMs)的发展成为自然语言处理(NLP)领域最具突破性的进展之一。GPT-3和PaLM等LLMs通过在海量文本语料上进行预训练，实现了在广泛任务上的出色少样本性能。监督微调(SFT)的引入进一步提升了LLMs的能力，特别是在增强指令跟随能力方面。

有趣的是，即使从相同的基础LLM开始，SFT数据集的微小变化也可能导致模型性能的显著差异。因此，开源社区见证了LLM变体的快速增长，融合了各种SFT数据集和技术，从而提高了它们的实用性和可访问性。

然而，SFT通常优先考虑改善通用指令跟随能力，这表明经过SFT的LLMs可能在特定下游任务中面临挑战。因此，将这些模型作为种子语言模型(seed LMs)进行后续针对特定下游任务的微调成为一种有吸引力的方法。

虽然这种方法看起来很有前景，但研究者的初步研究揭示了通过微调同时提高任务特定性能和保持通用指令跟随能力的挑战，主要是由于灾难性遗忘的问题。近期的研究也强调，即使使用良性数据集进行微调，也可能损害种子LMs的安全性。显然，旨在缓解灾难性遗忘的微调方法仍然缺乏。

## 2. 方法
为了缓解微调过程中的灾难性遗忘，本文提出了一种新的微调方法，称为自蒸馏微调(Self-Distillation Fine-Tuning， SDFT)。

### 2.1 微调LLMs
虽然LLMs在各种任务中表现出卓越的熟练程度，但在需要微调的下游任务中往往遇到限制。具体来说，需要进一步微调的LM被称为种子LM，表示为 $ f $ 并由 $ \theta $ 参数化。种子LM通常经过通用SFT，表明其能够将任何自然语言指令 $ x \in X $ (在任务描述 $ c \in C $ 的上下文中)映射到其相应的输出 $ y \in Y $。

$ f_\theta: C \times X \rightarrow Y $

种子LM的微调过程可以概述如下：对于目标任务 $ t $ 和上下文 $ c_t $，每个任务示例 $ (x_t, y_t) $ 用于更新模型参数。这个更新旨在最小化数据分布和LM分布之间的差异，表达如下：

$ L_{FT}(\theta) = -\log f_\theta(y_t | c_t, x_t) $

该公式寻求最小化给定上下文 $ c_t $ 和输入 $ x_t $ 的目标输出 $ y_t $ 的负对数似然，关于模型参数 $ \theta $。当生成的响应 $ \hat{y} $ 与 $ y_t $ 匹配时，即微调后的LM分布与任务数据集分布对齐时，$ L_{FT} $ 收敛。

### 2.2 自蒸馏微调
随着种子LM的分布向任务数据集的分布收敛，它自然会提高目标任务的性能。然而，常见微调方法容易导致通用指令跟随能力和安全对齐方面的灾难性遗忘。

为了解决这个问题，研究者提出了自蒸馏微调(SDFT)方法，以更好地将任务数据集的分布与种子LM的分布对齐。如图1所示，SDFT首先提示种子LM生成与任务数据集中原始响应在语义上等效的响应，从而产生蒸馏数据集。

![](https://cdn.nlark.com/yuque/0/2024/png/406504/1728545028541-59e669a2-304d-4f2e-8f5f-ed25d8855d62.png)

SDFT的初始步骤涉及提示种子LM将原始响应 $ y_t $ 重写为 $ \tilde{y} $：

$ \tilde{y} \sim f_\theta(y | c_t, x_t, y_t) $

这一步标志着SDFT与常见微调方法的主要区别，因为它涉及将原始响应映射到种子LM分布内的响应。为了完成重写，研究者使用自蒸馏模板，对种子LM施加最小要求，只需要它遵循重写响应的指令。

接下来，为了确保蒸馏响应的质量，研究者使用简单的启发式方法来评估蒸馏响应。例如，在数学推理问题中，从蒸馏响应 $ \tilde{y} $ 中提取最终答案，并将其与原始响应 $ y_t $ 中的答案进行比较。否则，保留原始响应。这个条件选择过程形式化为：

$ \tilde{y}' = \begin{cases} 
\tilde{y} & \text{if } \text{Extract}(\tilde{y}) = y_t \\
y_t & \text{otherwise}
\end{cases} $

最后，蒸馏响应用作原始响应 $ y_t $ 的替代品进行微调，即损失函数变为：

$ L_{SDFT}(\theta) = -\log f_\theta(\tilde{y}' | c_t, x_t) $

因此，通过使用蒸馏数据集而不是任务数据集，分布差距得到缓解，如图2右侧所示。

![](https://cdn.nlark.com/yuque/0/2024/png/406504/1728545109427-d2572785-1a0c-487d-bf6d-6e12839b6437.png)

### 2.3 蒸馏模板
在本研究中，蒸馏模板起着关键作用。它被设计为与任务无关，可以无缝应用于各种任务而无需修改。在这个框架内，模板将任务数据集中的原始响应指定为"参考答案"，并指导模型相应地生成响应。在大多数实验中使用的模板如图3所示。在处理涉及数学推理的数据集时，研究者略微调整了模板以更好地适应推理过程。

![](https://cdn.nlark.com/yuque/0/2024/png/406504/1728545136864-9a1f06c6-f1db-4381-90c7-9649633912b6.png)

## 3. 实验
### 3.1 实验设置
研究者在大多数实验中使用Llama-2-7b-chat模型作为种子LM，除非另有明确说明。由于计算资源有限，研究者在常见微调方法和提出的SDFT中都使用了低秩适应(LoRA)技术。

为确保公平比较，研究者在两种方法中保持了几乎所有超参数的一致性。对于包含超过10，000个示例的数据集，随机选择2，000个示例进行微调，以确保大多数数据集在规模上的可比性。对于OpenHermes数据集，随机选择20，000个示例以验证SDFT在更大、混合数据集上的效果。

### 3.2 用于微调和评估的数据集
研究者在各种数据集上微调种子LM，包括单任务和多任务场景。然后评估种子模型和微调模型在不同任务上的性能。用于微调和评估的数据集分为以下几类：

1. 单任务数据集：
    - 数学推理能力：GSM8K数据集（8.8k高质量小学水平算术词问题）
    - 工具使用能力：Gorilla OpenFunctions数据集
    - 代码生成技能：MagiCoder数据集（用于微调）和HumanEval数据集（用于评估）
2. 多任务数据集：
    - Alpaca、Dolly、LIMA和OpenHermes数据集
3. 安全性评估：
    - 使用Advbench数据集中的有害行为指令进行评估
    - 通过关键词匹配评估模型输出的安全性
    - 模拟越狱尝试，评估在对抗性后缀下的安全率
4. 有用性评估：
    - 使用AlpacaEval评估各种模型的有用性
    - 报告相对于Text-Davinci-003的胜率
5. 知识评估：
    - 使用OpenLLM Leaderboard的基准测试评估LMs的通用知识，包括MMLU、TruthfulQA、ARC、HellaSwag和Winogrande

### 3.3 SDFT在下游任务上取得更好的结果
![](https://cdn.nlark.com/yuque/0/2024/png/406504/1728545261815-2048a2a5-e61b-4bdd-b044-62774f8c33b7.png)

表1展示了在三个下游任务上微调的结果。结果表明，虽然常见微调方法可以提高模型在目标任务上的效果，但也导致其他任务性能的显著下降。例如，使用OpenFunctions数据集进行微调导致模型的编码能力下降，HumanEval上的性能从13.41降至9.76。数学推理能力也出现类似下降，GSM8K数据集上的准确率从29.42降至21.53。

相比之下，SDFT有效缓解了这种性能下降。在上述例子中，模型保持了数学推理能力，达到29.11的准确率，与种子模型的性能（29.42）非常接近。对于在HumanEval上评估的编码性能，有轻微改善，从种子模型的13.41提高到15.24。在目标任务OpenFunctions上，SDFT也优于常见微调方法，准确率为36.61，而常见微调方法为34.82。

### 3.4 SDFT保持对齐
表2的结果表明，在大多数数据集上进行微调会导致安全对齐和通用有用性的显著下降。例如，在GSM8K数据集上微调后，安全率从99.81降至82.12，越狱安全率从88.85降至54.81，AlpacaEval的胜率从66.04降至23.38。相比之下，SDFT方法有效缓解了这种下降，将原始安全率和越狱安全率分别提高了5和11个百分点。值得注意的是，与种子模型相比，胜率略有增加，得分为66.73对66.03。

![](https://cdn.nlark.com/yuque/0/2024/png/406504/1728545319527-5b9a7f97-58b7-4116-958a-45272782cd23.png)

表3展示了在包含多个任务的指令跟随数据集（Alpaca、Dolly、LIMA和OpenHermes）上微调后的评估结果。与表2中注意到的模式一致，在这些数据集上进行常见微调方法通常会导致安全性和有用性指标的显著降低。研究者观察到所有三个指标都明显下降，每个指标下降约20个百分点。相比之下，SDFT方法有效缓解了这种减少，将下降幅度限制在10个百分点以内。特别是在OpenHermes数据集上，SDFT将越狱安全率从61.54提高到87.50。

![](https://cdn.nlark.com/yuque/0/2024/png/406504/1728545329891-a479412b-bc45-4029-9d04-df3c17305f99.png)

### 3.5 通用知识保持完整
图4展示了通用知识的结果。虽然常见微调方法损害了下游性能和对齐性，但模型在通用知识方面的能力相对未受影响。例如，在OpenFunctions数据集上微调后，微调模型与种子LM之间的性能差异小于1。在使用SDFT进行微调后也观察到了这一点。

![](https://cdn.nlark.com/yuque/0/2024/png/406504/1728545466817-24895149-99d4-4728-baba-c527e6654bd5.png)

## 4. 分析
为了深入理解分布偏移对灾难性遗忘的影响，研究者进行了详细分析。除了第3节概述的评估指标外，还引入了四个补充指标来评估分布偏移的程度：

1. BLEU-4分数
2. ROUGE-L分数
3. 使用Sentence-BERT派生的句子嵌入之间的余弦相似度
4. 更新参数与种子模型参数之间的距离（作为参数偏移幅度的度量）

研究者使用种子模型和微调模型在Advbench数据集上生成响应，并对这些响应进行比较分析。BLEU-4、ROUGE-L和嵌入相似度分数越低，分布偏移越大。相反，参数偏移与参数变化的范数成正比。

### 4.1 分布偏移与灾难性遗忘的相关性
研究者通过两种方法诱导不同程度的分布偏移来研究其影响：

1. 通过采样不同数量的示例进行微调，其中用于微调的数据点数量增加对应于更大的分布偏移。
2. 通过混合常见微调方法和SDFT，这涉及用原始样本替换蒸馏样本。定义混合比例来表示使用的蒸馏样本的比例。混合比例为1表示仅使用SDFT，0表示常见微调方法。

图5和图6说明了不同样本大小的结果。随着样本大小的增加，BLEU-4、ROUGE-L和嵌入相似度分数明显下降，同时参数偏移幅度上升。这一趋势意味着分布偏移程度加剧。因此，可以观察到模型在GSM8K、MultiArith、Advbench和AlpacaEval等基准测试上的性能下降，表明灾难性遗忘加剧。

![](https://cdn.nlark.com/yuque/0/2024/png/406504/1728545568096-62d1912b-2ec4-424f-b53a-b3ca5db3b3e4.png)

同样，图7和图8展示了随着混合比例上升的结果。随着比例增加，BLEU-4、ROUGE-L和嵌入相似度分数呈上升趋势，而参数偏移规模减小，表示分布偏移得到缓解。相应地，基准测试性能在所有方面都有所改善，表明灾难性遗忘的严重程度降低。

![](https://cdn.nlark.com/yuque/0/2024/png/406504/1728545583439-adfe353b-0240-48bd-82a7-cba14737d98a.png)

图9说明了通过常见微调方法和SDFT获得的相似度分布。值得注意的是，使用SDFT时，微调模型与种子模型之间的相似度更高，表明分布偏移减少。

![](https://cdn.nlark.com/yuque/0/2024/png/406504/1728545626613-b1c8c2b7-b95f-4163-8dc2-6f0fe0ada931.png)

### 4.2 蒸馏模板的稳健性
研究者构建了两个模板来研究SDFT的稳健性。图3中说明的模板被标记为"Using"，其中短语"Using the reference answer as a guide"被替换为"Refer to the reference answer"，后者模板被称为"Refer"。表4详细列出了使用这两个模板进行微调后的结果。

表4：蒸馏模板的消融研究

| 微调数据集 | 模板 | OpenFunctions | HumanEval | GSM8K | 原始安全率 | 越狱安全率 | 胜率 |
| --- | --- | --- | --- | --- | --- | --- | --- |
| OpenFunctions | Vanilla FT | 34.82 | 9.76 | 21.53 | 98.27 | 87.31 | 35.49 |
|  | Refer | 35.71 | 13.41 | 27.37 | 98.85 | 89.81 | 68.45 |
|  | Using | 36.61 | 15.24 | 29.11 | 99.23 | 94.42 | 67.66 |
| Dolly | Vanilla FT | 8.04 | 17.07 | 15.92 | 81.73 | 26.54 | 22.09 |
|  | Refer | 17.86 | 14.02 | 24.26 | 96.35 | 69.62 | 61.60 |
|  | Using | 16.07 | 14.63 | 26.31 | 97.31 | 72.69 | 57.52 |


从表4中可以看出，SDFT的性能在不同的蒸馏模板下始终优于Vanilla FT。这表明SDFT方法具有良好的稳健性，不受模板细微变化的影响。

### 4.3 SDFT在不同模型规模和架构上的有效性
SDFT方法不受任何特定微调技术（如LoRA）或模型架构的限制，可以应用于全面微调过程和其他模型架构。为了证实这一点，研究者进行了补充实验，包括对Llama-2-7b-chat进行全面微调和LoRA微调。此外，还探索了最近发布的SOTA模型Llama3在OpenFunctions数据集上的微调。表5中的结果显示了这些实验的详细对比。

表5：SDFT在不同模型和微调设置下的性能比较

| 方法 | GSM8K | OpenFunctions | HumanEval | 原始安全率 | 越狱安全率 | 胜率 |
| --- | --- | --- | --- | --- | --- | --- |
| 微调数据集：GSM8K |  |  |  |  |  |  |
| 种子LM (7B) | 29.40 | 19.60 | 13.41 | 99.81 | 88.85 | 66.04 |
| Vanilla FT (full) | 34.87 | 5.36 | 13.41 | 84.62 | 37.31 | 23.04 |
| SDFT (Ours, full) | 35.03 ↑ 0.16 | 16.07 ↑ 10.71 | 15.85 ↑ 2.44 | 88.46 ↑ 3.84 | 63.46 ↑ 26.15 | 61.19 ↑ 38.15 |
| 微调数据集：GSM8K |  |  |  |  |  |  |
| 种子LM (13B) | 38.06 | 36.61 | 19.51 | 99.81 | 98.85 | 86.75 |
| Vanilla FT (LoRA) | 44.12 | 19.64 | 17.68 | 94.42 | 88.27 | 40.27 |
| SDFT (Ours, LoRA) | 45.59 ↑ 1.47 | 24.11 ↑ 4.47 | 18.28 ↑ 0.61 | 97.31 ↑ 2.89 | 94.42 ↑ 6.15 | 75.93 ↑ 35.66 |
| 微调数据集：OpenFunctions |  |  |  |  |  |  |
| Llama3-8B-Instruct | 81.58 | 41.07 | 59.76 | 95.58 | 94.81 | 75.34 |
| Vanilla FT (LoRA) | 77.79 | 42.86 | 54.27 | 88.85 | 79.81 | 79.75 |
| SDFT (Ours, LoRA) | 79.45 ↑ 1.66 | 43.75 ↑ 0.89 | 56.10 ↑ 1.83 | 92.12 ↑ 3.27 | 96.15 ↑ 16.34 | 82.24 ↑ 2.49 |


从表5中可以观察到，在所有情况下，SDFT不仅在目标任务上始终优于常见微调方法，而且还减少了所有其他任务上的遗忘，证明了其有效性。特别是：

1. 在GSM8K数据集上进行全面微调时，SDFT在保持OpenFunctions和HumanEval性能的同时，显著提高了安全性和AlpacaEval胜率。
2. 对于更大的13B模型使用LoRA微调时，SDFT在所有指标上都优于常见微调方法，尤其是在保持安全性和通用能力方面。
3. 在最新的Llama3模型上，SDFT同样展现出优越性，不仅提高了目标任务（OpenFunctions）的性能，还在其他任务和安全性指标上有所改善。

这些结果强烈支持SDFT方法的普适性和有效性，表明它可以在不同规模和架构的模型上成功应用。

## 5. 结论和局限性
本研究系统地评估了语言模型在下游任务微调过程中的灾难性遗忘问题。研究发现，微调过程中的分布偏移可能导致通用任务能力、模型的安全对齐和有用性的性能下降。为了在提高目标任务性能的同时保持LMs的广泛能力，研究者提出了一种即插即用的策略SDFT，以减少分布偏移并缓解灾难性遗忘。

SDFT的核心思想是通过自蒸馏过程生成与原始任务数据在语义上等价但更接近模型原始分布的新数据。这种方法有效地桥接了任务特定数据和模型原始知识之间的差距，从而在提高特定任务性能的同时，保持了模型的广泛能力。

大量实验表明，SDFT在多个方面展现出优越性：

1. 在目标任务上实现了与常见微调方法相当或更优的性能。
2. 有效地减少了对其他任务的遗忘。
3. 保持了模型的安全性和通用指令跟随能力。
4. 在不同规模和架构的模型上都表现出良好的适用性。

然而，本研究也存在一些局限性：

1. 计算资源限制：大多数实验都基于Llama-2-7b-chat模型和LoRA技术。虽然在更大模型上进行了一些验证，但涉及更多大规模模型和全面微调的进一步研究仍有待探索。
2. 安全性评估范围：安全性评估主要限于Advbench数据集和固定的对抗性后缀。对其他越狱策略和更广泛安全问题的鲁棒性还需要进一步研究。
3. 语言限制：本研究主要集中在英语数据集上，对多语言场景的适用性还需要进一步验证。
4. 任务多样性：虽然SDFT在多个任务和模型上展示了有效性，但其在更广泛的任务和领域中的泛化能力还需要更多研究。
5. 推理过程分析：本研究主要关注了模型性能和安全性，但对SDFT如何影响模型的内部表示和推理过程还需要更深入的分析。

未来的研究方向可能包括：

1. 探索SDFT在更大规模模型和更多样化任务上的应用，特别是在极大规模模型（如GPT-4级别）上的效果。
2. 研究SDFT与其他微调技术（如PEFT、P-tuning等）的结合，以进一步提高性能和泛化能力。
3. 深入分析SDFT对模型内部表示和推理过程的影响，以更好地理解其工作机制。
4. 探索SDFT在多语言和跨语言迁移学习中的潜力，特别是在低资源语言上的效果。
5. 研究如何进一步优化蒸馏模板和过程，以更好地平衡任务特定性能和通用能力的保持。
6. 探索SDFT在持续学习场景中的应用，研究如何使模型能够不断学习新任务而不遗忘旧任务。
7. 结合神经架构搜索（NAS）技术，自动优化SDFT的超参数和蒸馏策略。

SDFT为解决语言模型微调中的灾难性遗忘问题提供了一种有前景的方法，为未来的研究开辟了新的方向。

