# 解决持续学习中可塑性损失和灾难性遗忘问题
> 原文：《ADDRESSING LOSS OF PLASTICITY AND CATASTROPHIC FORGETTING IN CONTINUAL LEARNING》
>

## 1. 引言
持续学习是人工智能面临的一个重大挑战。尽管在自然语言处理、游戏和计算机视觉等领域取得了进展，但持续学习仍然是一个障碍。神经网络中的灾难性遗忘(catastrophic forgetting)被广泛认为是持续学习的主要挑战之一。这种现象表现为基于梯度的方法(如SGD或Adam)由于遗忘或覆盖先前学习的单元而无法保留或利用过去的知识。

在持续学习中，这些学习器经常重新学习重复出现的任务，与从头学习相比几乎没有任何收益。这个问题也引发了对重用大型实践模型的担忧，因为为新任务微调它们会导致预训练模型的显著遗忘。

缓解灾难性遗忘的方法主要针对特定设置设计，包括独立同分布(i.i.d.)样本、完全包含在一个批次或数据集中的任务、不断增长的内存需求、已知任务边界、存储过去样本和离线评估等。这些设置在持续学习至关重要的情况下通常是不切实际的，例如设备上学习。例如，由于计算资源的限制或数据隐私问题，可能无法保留样本。

在具有挑战性且实用的流式学习设置中，灾难性遗忘更为严重，而且在很大程度上尚未得到解决。在流式学习中，样本在产生时呈现给学习器，这在大多数实际问题中是非i.i.d.的。

学习器无法保留样本，因此需要立即从中学习。此外，评估在最近呈现的样本上在线进行。这种设置反映了动物学习，并且对许多应用(如机器人或自主设备上学习)都是实用的。在本文中，作者考虑了具有未知任务边界的流式学习。

流式学习为学习器提供了一个由非平稳目标函数$ f_t $生成的样本流$ (x_t, y_t) $，使得$ y_t = f_t(x_t) $。学习器观察输入$ x_t \in \mathbb{R}^d $，输出预测$ \hat{y}_t \in \mathbb{R}^m $，然后观察真实输出$ y_t \in \mathbb{R}^m $，严格按照这个顺序。然后根据在线指标$ E(y_t, \hat{y}_t) $立即评估学习器，例如分类中的准确率或回归中的平方误差。

学习器使用神经网络进行预测，并使用$ E $或相关损失立即学习网络参数，而不存储样本。目标函数$ f_t $在局部是静态的，其中$ f_t $的变化偶尔发生，创建由一系列静态任务组成的非平稳持续学习问题。

![](https://cdn.nlark.com/yuque/0/2024/png/406504/1728549303554-ac6cfe90-5965-40c7-9e55-fef8d654128a.png)

图1(a)说明了Adam在流式学习设置中的灾难性遗忘。这里，向学习器呈现了一系列基于标签置换EMNIST的任务。这些任务被设计为高度相干的，其中在一个任务中学习的特征在另一个任务中完全可重用。如果学习器能够记住并利用先前的学习，它应该随着更多任务的呈现而继续提高性能。

然而，图1(a)揭示了Adam几乎无法提高其性能，性能保持在较低的准确率水平，表明存在遗忘和重新学习。虽然灾难性遗忘通常在离线评估下研究(实线)，但这个问题在在线评估(虚线)中也表现出来。这个结果表明，当前的表示学习方法无法利用先前学习的有用特征，而是在后续任务中遗忘和重新学习它们。

持续学习的另一个严重挑战是可塑性损失，即学习器学习新事物的能力下降。最近的研究揭示，SGD或Adam随着更多任务的出现继续失去可塑性，主要是由于特征变得难以修改。存在几种维持可塑性的方法，但它们通常不解决灾难性遗忘。图1(b)和1(c)说明了可塑性损失，其中Adam呈现了一系列基于输入置换MNIST的新任务。Adam的性能随着更多任务而下降，变得比Adam-Restarts(在每个任务上从头学习)更差。Adam-Restarts的稳定性能表明任务具有相似的难度。然而，Adam随着时间的推移变得越来越慢，表明可塑性损失。

一种同时保留有用单元(如特征或权重)并保持其他单元可适应的方法可能会同时解决灾难性遗忘和可塑性损失。虽然有一些方法同时解决这两个问题，但这些方法需要已知的任务边界、维护重放缓冲区或需要预训练，这不适合流式学习。在本文中，作者旨在填补这一空白，并提出一种持续学习方法，在没有此类限制的情况下解决流式学习中的灾难性遗忘和可塑性损失。

## 2. 相关工作
### 2.1 解决灾难性遗忘
为了缓解灾难性遗忘，已经提出了不同的方法:

1. 基于重放的方法(例如，Chaudhry et al. 2019， Isele & Cosgun 2018， Rolnick et al. 2019)通过使用重放缓冲区来存储传入的非i.i.d.数据，然后从缓冲区采样i.i.d.样本来解决遗忘问题。
2. 参数隔离方法(例如，Rusu et al. 2016， Schwarz et al. 2018， Wortsman et al. 2020， Ge et al. 2023)可以扩展以适应新信息，而不会显著影响先前学习的知识。
3. 诱导稀疏性的方法(例如，Liu et al. 2019)通过维持稀疏连接工作，以便权重更新可以局部化，不影响许多先前有用的权重。
4. 基于正则化的方法使用惩罚来阻止学习器远离先前学习的权重(Kirkpatrick et al. 2017， Aljundi et al. 2018， Aljundi et al. 2019)或近似值(Lan et al. 2023)。惩罚量通常是基于权重对先前任务贡献的重要性的函数。

### 2.2 解决可塑性损失
Dohare等人(2023a)引入了一种生成和测试方法，通过不断替换不太有用的特征来维持可塑性，并表明具有持续注入噪声的方法(例如，Ash & Adams 2020)也能维持可塑性。后来提出了几种保持可塑性的方法。例如，Nikishin等人(2023)提出动态扩展网络，Abbas等人(2023)建议采用适应性激活函数，Kumar等人(2023)提出向初始权重正则化。

### 2.3 同时解决两个问题
Carpenter和Grossberg(1987)早期就概述了可塑性和遗忘之间的权衡，称之为稳定性-可塑性困境，这是在保持先前经验的性能和适应新经验之间的权衡。持续学习社区更多地关注通过克服遗忘来改善稳定性方面。然而，最近出现了同时解决这两个问题的新趋势。

Chaudhry等人(RWalk， 2018)利用基于正则化的方法，使用快速移动平均值来快速适应权重重要性的变化，同等强调现在和过去。Jung等人(2022)引入了不同的技术，包括结构性蒸馏损失和预训练，以平衡可塑性和遗忘。Gurbuz等人(2022)提出使用连接重布线来诱导稀疏神经网络中的可塑性。最后，Kim等人(2023)提出使用单独的网络来学习新任务，然后将其整合到第二个网络中以处理先前任务。

尽管在解决持续学习的两个问题方面取得了最新进展，但大多数现有方法不适合流式学习设置，因为它们需要了解任务边界、重放缓冲区或预训练。

### 2.4 神经网络剪枝中的重要性度量
神经网络剪枝需要一个重要性度量来确定要移除哪些权重。通常，网络使用不同的度量进行剪枝，例如权重幅度(例如，Han et al. 2015， Park et al. 2020)、一阶信息(例如，Mozer & Smolensky 1988， Hassibi & Stork 1992， Molchanov et al. 2016)、二阶信息(例如，LeCun et al. 1989， Dong et al. 2017)或两者结合(例如，Tresp et al. 1996， Molchanov et al. 2019)。与剪枝类似，解决灾难性遗忘的基于正则化的方法使用权重重要性度量(如Fisher信息对角线)来衡量它们的惩罚。

## 3. 方法
作者的方法是保留有用的单元同时修改其余部分，这需要一个度量来评估单元的效用或有用性。在本节中，作者引入了一种权重效用度量，并概述了一种计算它的有效方法。权重效用可以定义为将权重设置为零时损失的变化，本质上是移除其连接。移除重要权重应该会导致损失增加。理想情况下，即时损失和未来损失都很重要，但在当前步骤中只能评估即时损失。最后，作者设计了一种基于梯度的更新规则，根据这种效用度量来保护或修改权重。

为了精确定义效用，让我们考虑学习器使用参数化为权重集$ W = \{W_1, ..., W_L\} $的$ L $层神经网络产生预测输出$ \hat{y} $。这里$ W_l $是第$ l $层的权重矩阵，其在第$ i $行和第$ j $列的元素表示为$ W_{l,i,j} $。在每一层$ l $，我们通过对激活输入$ a_l $应用激活函数$ \sigma_a $来获得特征的激活输出$ h_l $:$ h_l = \sigma_a(a_l) $。我们简化记号，定义$ h_0 \stackrel{\text{.}}{=} x $。然后将激活输出$ h_l $乘以层$ l+1 $的权重矩阵$ W_{l+1} $以产生下一个激活输入:$ a_{l+1,i} = \sum_{j=1}^{d_l} W_{l+1,i,j} h_{l,j}, \forall i $，其中$ h_l \in \mathbb{R}^{d_l} $。这里，$ \sigma_a $对所有层都元素级应用激活，除了最后一层，它变成softmax函数。

层$ l $中权重$ i,j $和样本$ Z $的效用$ U_{l,i,j}(Z) $定义为:

$ U_{l,i,j}(Z) \stackrel{\text{.}}{=} L(W_{\neg[l,i,j]}, Z) - L(W, Z) $

其中$ L(W, Z) $是给定$ W $的样本损失，而$ L(W_{\neg[l,i,j]}, Z) $是一个反事实损失，其中$ W_{\neg[l,i,j]} $与$ W $相同，除了权重$ W_{l,i,j} $被设置为0。作者将其称为真实效用，以区别于其近似值，后者被称为近似效用或简单地称为效用。请注意，这种效用是一种全局度量，它根据权重的重要性提供了一个总排序。然而，计算它是禁止的，因为它需要额外的$ N_w $前向传递，其中$ N_w $是权重总数。

### 3.1 真实效用的可扩展近似
由于计算真实效用是禁止的，作者的目标是近似它，使得不需要额外的前向传递。为此，作者通过二阶Taylor近似来估计真实效用。作者在当前权重$ W_{l,i,j} $周围展开反事实损失$ L(W_{\neg[l,i,j]}, Z) $，并在权重为零时评估。因此，$ U_{l,i,j}(Z) $的二次近似可以写为:

$ \begin{aligned}
U_{l,i,j}(Z) &= L(W_{\neg[l,i,j]}, Z) - L(W, Z) \
&\approx L(W, Z) + \frac{\partial L(W, Z)}{\partial W_{l,i,j}}(0 - W_{l,i,j}) + \frac{1}{2}\frac{\partial2 L}{\partial W_{l,ij}2}(0 - W_{l,i,j})^2 - L(W, Z) \
&= - \frac{\partial L(W, Z)}{\partial W_{l,i,j}}W_{l,i,j} + \frac{1}{2}\frac{\partial2 L(W, Z)}{\partial W_{l,i,j}2}W_{l,i,j}^2.
\end{aligned} $

其中$ \xi \sim N(0, \sigma^2) $是噪声，$ \alpha $是步长参数，$ \bar{U}_{l,i,j} \in [0, 1] $是缩放后的效用。对于重要权重，效用$ \bar{U}_{l,i,j} = 1 $，权重甚至不会被梯度下降改变，而对于不重要的权重，效用$ \bar{U}_{l,i,j} = 0 $，权重会被扰动和梯度下降同时更新。

UPGD的另一种变体，作者称之为非保护UPGD，是将基于效用的扰动添加到梯度中，如下:

$ w_{l,i,j} \leftarrow w_{l,i,j} - \alpha[\partial L/\partial w_{l,i,j} + \xi(1 - \bar{U}_{l,i,j})] $

然而，这种更新规则只能帮助防止可塑性损失，而不能防止灾难性遗忘，因为有用的权重不受梯度变化的保护。作者在实验中包括了非保护UPGD，以验证使用效用信息作为扰动和梯度更新的门控对缓解灾难性遗忘是必要的。作者在附录A中提供了UPGD和非保护UPGD在非凸静态问题上的收敛分析。

效用缩放对UPGD更新规则很重要。作者在这里提出了一种全局缩放，并在附录E中提出了一种局部缩放变体。全局缩放的效用需要在每个时间步骤获取所有权重的最大效用(例如，瞬时或轨迹)，给出为$ \bar{U}_{l,i,j} = \phi(U_{l,i,j}/\eta) $。这里$ \eta $是权重的最大效用，$ \phi $是缩放函数，作者使用sigmoid函数。作者在算法1中展示了使用全局缩放效用的方法的伪代码，其中$ F_l $包含一阶导数，$ S_l $包含二阶导数近似(有关GetDerivatives函数的更多详细信息，请参见附录F)。作者在这里关注权重级UPGD，并在附录E中提供了特征级UPGD的类似伪代码。

UPGD更新规则可以与一些现有的更新规则相关联。当我们均匀地扰动所有权重时，即当所有缩放效用为零时，UPGD简化为一类称为扰动梯度下降(PGD)(Zhou等人2019)的著名算法。PGD学习规则给出为$ w_{l,i,j} \leftarrow w_{l,i,j} - \alpha [\partial L/\partial w_{l,i,j} + \xi] $。已经证明，具有权重衰减的PGD算法，称为收缩和扰动(S&P)(Ash & Adams 2020)，可以帮助在持续分类问题中维持可塑性(Dohare等人2023a)，因为保持小权重可以防止权重过度承诺，使其易于改变。收缩和扰动的学习规则可以写为$ w_{l,i,j} \leftarrow \rho w_{l,i,j} - \alpha (\partial L/\partial w_{l,i,j} + \xi) $，其中$ \rho = 1 - \lambda\alpha $，$ \lambda $是权重衰减因子。当不添加噪声时，更新简化为带有权重衰减的SGD(Loshchilov & Hutter 2019)，称为SGDW。将权重衰减的有用作用纳入UPGD，我们可以将带有权重衰减的UPGD(UPGD-W)更新规则写为$ w_{l,i,j} \leftarrow \rho w_{l,i,j} - \alpha\left(\frac{\partial L}{\partial w_{l,i,j}} + \xi\right)\left(1 - \bar{U}_{l,i,j}\right) $。

### 3.3 遗忘和可塑性评估指标
在这里，作者提出了两个指标来表征流式学习中的可塑性和遗忘。首先，作者引入了一个新的在线指标来量化可塑性。神经可塑性通常被定义为生物神经网络对某些刺激做出反应的能力(Konorski 1948， Hebb 1949)。同样，在人工神经网络中，可塑性可以被视为神经网络改变其预测以响应新信息的能力(Lyle等人2023)。作者提供了一个定义，捕捉了文献中现有的直觉。作者将学习器给定样本的可塑性定义为改变其预测以匹配目标的能力。如果学习器可以完全匹配目标，则给定样本的可塑性为1;如果与之前对同一样本的预测相比，学习器在向目标迈进方面取得零或负进展，则可塑性为0。形式上，作者将样本可塑性定义为:

$ p(Z) = \max\left(1 - \frac{L(W^\dagger,Z)}{\max(L(W,Z),\epsilon)}, 0\right) \in [0, 1] $

其中$ W^\dagger $是执行更新后的权重集，$ \epsilon $是一个小数，用于保持数值稳定性。请注意，项$ \left(1 - \frac{L(W^\dagger,Z)}{\max(L(W,Z),\epsilon)}\right) \in (-\infty, 1] $的上界为1，因为$ L(W, Z) \in [0, \infty), \forall W, Z $对于交叉熵和平方误差损失。作者使用这个指标直接测量可塑性，特别是因为大多数引入的度量(例如，权重范数)通常与可塑性不相关(见Lyle等人2023)。

这个指标可以看作是Lyle等人(2023)可塑性指标的基线归一化版本，其中基线是更新前的损失。作者测量可塑性损失为$ \Delta\bar{p}_{k+1} = \bar{p}_k - \bar{p}_{k+1} $，其中$ \bar{p}_k $是第$ k $个评估窗口中所有样本的平均可塑性。请注意，这个指标的范围是$ \Delta\bar{p}_k \in [-1, 1], \forall k $。负值表示学习器获得了可塑性，而正值表示学习器失去了可塑性。在实验中，作者报告了$ T $个评估窗口的总体可塑性损失:

$ \sum_{k=1}^{T-1} \Delta\bar{p}_{k+1} = \bar{p}_1 - \bar{p}_T $。

现有的灾难性遗忘指标主要基于离线评估。在流式学习中，遗忘先前学习的有用特征导致未来学习的恶化，而不是影响过去的性能。如果学习器不断改进其表示，那么新任务的平均在线准确率应该持续提高。另一方面，如果它无法改进表示，其平均在线准确率可能保持不变甚至下降(见图1(a))。

因此，作者提出使用不同的在线评估窗口来测量流式学习的遗忘。受De Lange等人(2023)引入的窗口遗忘指标的启发，作者提出指标$ F_{k+1} = A_k - A_{k+1} $，其中$ A_k $是第$ k $个评估窗口中所有样本的平均准确率。这个指标假设在一个任务中学习的表示对未来任务保持相关，并且所有任务具有相同的复杂性。请注意，这个指标的范围是$ F_k \in [-1, 1], \forall k $，其中负值表示学习器可以改进先前的表示，正值表示重新学习，因此表示遗忘。在实验中，作者报告了$ T $个评估窗口的总体遗忘:$ \sum_{k=1}^{T-1} F_{k+1} = A_1 - A_T $。

## 4. 实验
在这一节中，作者首先研究了近似效用的质量。然后，作者研究了UPGD在缓解可塑性损失和灾难性遗忘方面的有效性。对于后者，作者使用基于MNIST(LeCun等人1998)、EMNIST(Cohen等人2017)、CIFAR-10(Krizhevsky 2009)和ImageNet(Deng等人2009)数据集的非静态流式问题，学习器使用多层感知器、卷积神经网络(LeCun等人1998)和残差神经网络(He等人2016)(然而，请参见附录G以验证UPGD在静态任务上的表现)。作者还在扩展的强化学习实验中验证了UPGD。UPGD与适合流式学习设置的基线进行了比较，即没有重放、批次或任务边界。

持续学习器的性能基于分类问题的平均在线准确率进行评估。在以下每个实验中，都进行了彻底的超参数搜索(见附录I)。作者的标准是为每种方法找到最大化在线准确率曲线下面积的最佳超参数集。除非另有说明，否则作者对每种方法的性能进行了20次独立运行的平均。作者在这里专注于关键结果，并在附录I中给出完整的实验细节。

### 4.1 近似效用的质量
高质量的效用近似应该给出与真实效用相似的权重排序。作者使用Spearman的序数相关度量来量化效用近似的质量。使用具有ReLU激活的小型神经网络的SGD学习器在一个简单问题上最小化在线平方误差。

![](https://cdn.nlark.com/yuque/0/2024/png/406504/1728549458811-a4c2352f-944e-4ebd-ab58-f1d2e9c57ea5.png)

在每个时间步，计算一阶和二阶全局效用与随机排序、平方梯度效用和权重幅度效用的Spearman相关性。作者在图2中报告了真实效用和近似全局权重效用之间的相关性。二阶效用在整个学习过程中具有最高的相关性。另一方面，当学习器达到平稳状态时，一阶效用变得相关性较低，可能是由于解附近的梯度元素锯齿状变化。

权重幅度效用显示出与真实效用的小相关性，并且随时间变小。平方梯度效用的相关性随时间步增加，但仍小于一阶效用的相关性。作者使用随机排序作为基线，它与真实效用保持零相关，正如预期的那样。作者还在附录J中展示了近似局部效用与真实效用之间的相关性，以及使用其他激活函数的结果。

### 4.2 UPGD应对可塑性损失
在这一节中，作者使用输入置换MNIST，这是一个只存在可塑性损失的问题，并回答两个主要问题:1)UPGD和其他持续学习方法在这个问题上如何表现，2)性能是否足以指示这个任务中的可塑性。性能已经被用来在各种问题和设置中测量可塑性(Dohare等人2021， Nikishin等人2023， Kumar等人2023， Abbas等人2023)。性能下降通常被归因于可塑性损失。在这里，作者质疑在任意问题中使用性能来衡量可塑性，因为性能也可能受到其他问题(如灾难性遗忘)的影响(见Fedus等人2020)。

然而，作者假设如果唯一的潜在问题是可塑性损失，那么性能实际上可能反映可塑性。因此，有必要使用一个只存在可塑性损失的问题来测试这个假设。这种方法还允许作者研究UPGD在孤立于灾难性遗忘的情况下应对可塑性损失的有效性。在输入置换MNIST中，作者每5000步置换一次输入，每次置换时的时间步标志着新任务的开始。在每次置换之后，学习到的特征对新任务变得不相关，所以预期学习器会尽快覆盖先前学习的表示。因此，输入置换MNIST是研究可塑性损失的合适问题。

作者比较了SGDW、PGD、S&P(解决可塑性损失)、带有权重衰减的Adam(Loshchilov & Hutter 2019)(称为AdamW)、UPGD-W和非保护UPGD-W。作者还引入并比较了流式弹性权重整合(S-EWC)、流式突触智能(S-SI)和流式内存感知智能(S-MAS)。这些方法可以看作是EWC(Kirkpatrick等人2017)、SI(Zenke等人2017)和MAS(Aljundi等人2018)的自然扩展，它们是基于正则化的方法，用于缓解遗忘到流式学习设置。

最后，作者引入并比较了流式RWalk(S-RWalk)。这可以看作是RWalk(Chaudhry等人2018)的自然扩展，RWalk是一种旨在同时解决两个问题的方法，适用于流式学习。作者将最后四种方法在流式学习中的更新规则写为$ w_{l,i,j} \leftarrow w_{l,i,j} - \alpha [\partial L/\partial w_{l,i,j} + \kappa\Omega_{l,i,j} (w_{l,i,j} - \bar{w}_{l,i,j})] $，其中$ \kappa $是正则化因子，$ \Omega_{l,i,j} $是权重重要性，$ \bar{w}_{l,i,j} $是层$ l $中$ i,j $权重的轨迹。在S-EWC中，权重重要性被估计为平方梯度的轨迹，而在S-MAS中，它被估计为梯度幅度的轨迹。

S-RWalk与RWalk不同，因为它使用先前权重的轨迹而不是瞬时先前权重。作者在这里省略了S-SI和RWalk权重重要性估计的细节，并将其推迟到附录I.4。最后，由于作者比较的是使用一阶信息的方法，所以在这个和后续实验中使用全局一阶效用轨迹进行公平比较(然而，请参见附录H以了解使用二阶效用的实验)。

![](https://cdn.nlark.com/yuque/0/2024/png/406504/1728549436156-e581e2fc-b45c-4492-a7aa-48499e773451.png)

图3显示，只解决灾难性遗忘的方法(例如，S-EWC)的性能继续下降，而只解决可塑性损失的方法(例如，S&P)或同时解决两个问题的方法(例如，UPGD)，除了S-RWalk，都保持了它们的性能水平。作者绘制了平均在线准确率与任务数量的关系图。平均在线准确率是每个任务内正确预测的百分比，其中样本在线准确率为1表示正确预测，0表示错误预测。学习器的预测是通过对其输出概率进行argmax给出的。学习器被呈现了总共100万个例子，每个时间步一个例子，并且需要使用具有ReLU单元的多层(300×150)网络来最大化在线准确率。

![](https://cdn.nlark.com/yuque/0/2024/png/406504/1728549480332-e4cd3209-660a-43a5-a6de-6b5d348d57b0.png)

为了回答第二个问题，作者测量了每种方法的在线可塑性(如3.3节所定义)，并在图4中绘制了性能与测量的可塑性的关系。图4显示了每种方法的平均在线可塑性与最后100个任务的平均在线准确率的对比。作者注意到可塑性和准确率强烈相关，表明当学习器失去可塑性时，其准确率也会下降。这个结果证实，当唯一的潜在问题是可塑性损失时，性能确实反映了可塑性。请注意，当可塑性损失不是唯一的问题时，预期不会出现这种相关性，因此，可塑性指标通常可能更可靠。

![](https://cdn.nlark.com/yuque/0/2024/png/406504/1728549494786-f138e54c-2619-4460-8cf8-a8d3344a2a3e.png)

最后，在图5中，作者使用诊断统计来进一步分析每种方法达到的解。附录K.1中报告了这个问题和接下来问题的学习器的更多统计数据。值得注意的是，结果显示，对于所有方法，零激活的比例都显著增加，而ℓ_0梯度范数显著减小，除了UPGD-W以及非保护UPGD-W和S&P。

### 4.3 UPGD应对灾难性遗忘
现在，作者研究UPGD和其他持续学习方法如何解决遗忘问题，为此他们使用了标签置换CIFAR-10。CIFAR-10数据集包含60，000个32×32的RGB图像，属于10个类别;每个类别有6000个图像。每2500个时间步置换一次标签。每个学习器使用具有ReLU激活的卷积神经网络训练100万个样本，每个时间步一个样本。这种置换不应该使学习器改变其学习的表示，因为它可以简单地改变最后一层的权重来适应这种变化。

![](https://cdn.nlark.com/yuque/0/2024/png/406504/1728549541143-cebca6fc-d741-46a6-be8f-0059d426aa22.png)

这使得标签置换CIFAR10问题适合研究灾难性遗忘。然而，目前还不清楚是否存在可塑性损失的问题。作者假设在这个问题中不会出现可塑性损失问题，主要是由于其类别数量较少(Lesort等人2023)，导致标签置换后相同标签再次出现的概率为10%，结果是导致可塑性损失的非平稳性较少。

图6(a)显示，解决灾难性遗忘的方法持续改善其性能。作者使用可塑性损失指标来检查学习器是否经历任何可塑性损失。图7(b)显示大多数方法的值为负，反映没有可塑性损失，这也表明灾难性遗忘是这个问题中的主要问题。虽然所有学习器都能改善其性能，但根据它们的遗忘指标(见图7(a))，有些学习器的改善程度比其他学习器更大。作者观察到，没有明确机制解决遗忘的学习器(例如，AdamW)可以达到略高于40%的最大准确率，而解决灾难性遗忘的学习器则继续改善其性能。

### 4.4 UPGD应对可塑性损失和灾难性遗忘
在本节中，作者使用标签置换EMNIST问题研究灾难性遗忘和可塑性损失的相互作用。EMNIST数据集是MNIST的扩展形式，有47个类别，包括数字和字母，而不仅仅是10个数字。作者每2500个时间步置换一次输入，并向学习器呈现总共100万个例子，每个时间步一个例子，使用与第一个问题相同的网络架构。因此，这个问题也适合研究灾难性遗忘。由于EMNIST有更多的类别，标签再次出现的概率变得显著较小，导致更多的非平稳性。因此，作者预期在这个问题中可能存在可塑性损失。图7(b)显示大多数学习器确实suffer from可塑性损失。

![](https://cdn.nlark.com/yuque/0/2024/png/406504/1728549568759-a2993ca6-aea7-4b2b-bd21-cbb62f6a7a6a.png)

图6(b)显示，解决灾难性遗忘的方法，包括UPGD-W但除了S-RWalk和S-SI之外，都继续改善其性能，并优于只解决可塑性损失的方法。值得注意的是，作者观察到S-RWalk在前一个问题中解决了灾难性遗忘，但在这个问题中表现不佳，可能是由于额外的可塑性损失。另一方面，S-SI和其他方法的性能随着时间的推移继续恶化。

接下来，作者使用标签置换mini-ImageNet问题进行大规模实验，该问题具有大量的类别;因此，预期会出现可塑性损失和灾难性遗忘。mini-ImageNet(Vinyals等人2016)是ImageNet数据集的一个子集。mini-ImageNet数据集包含60，000个84×84的RGB图像，属于100个类别;每个类别有600个图像。在标签置换mini-ImageNet中，每2500个时间步置换一次标签。每个学习器在预训练的ResNet-50(He等人2016)上使用两层全连接网络，ResNet-50的权重固定。

图6(c)展现了与前一个问题相同的趋势，其中解决灾难性遗忘的方法(例如，S-EWC)表现最好，而解决可塑性损失的方法(例如，S&P)只能在较低水平维持其性能。图7(a)和图7(b)显示UPGD-W的两个指标在所有问题中都处于最佳整体值之列，表明遗忘和可塑性损失都有所减少。作者建议读者参考附录L以了解UPGD组件的消融研究。

### 4.5 UPGD应对策略崩溃
![](https://cdn.nlark.com/yuque/0/2024/png/406504/1728549594102-88136edf-87c0-4451-a2d0-612e3214e0fe.png)

最后，作者研究了UPGD在防止强化学习(RL)中的性能逐渐下降或策略崩溃(Dohare等人2023b)方面的作用。Dohare等人(2023b)显示RL中的非平稳性可能表现出两个持续学习问题，并证明PPO算法(Schulman等人2017)在长时间训练时可能经历策略崩溃。由于UPGD有助于解决灾难性遗忘和可塑性损失，作者测试UPGD是否可以解决PPO中的策略崩溃。作者设计了一种基于Adam归一化(Kingma & Ba 2015)的自适应UPGD变体，称为自适应UPGD(AdaUPGD)，使其步长在几个RL环境中具有鲁棒性，无需调整。作者建议读者参考算法5以获取完整描述，并参考附录I.6以了解实验细节。图8显示AdaUPGD持续改善其性能，而Adam则遭受策略崩溃。

## 5. 结论
在本文中，作者引入了一种新的方法来缓解可塑性损失和灾难性遗忘。作者设计了学习规则，保护有用的权重并扰动不太有用的权重，从而维持可塑性并减少遗忘。作者进行了一系列具有挑战性的流式学习实验，包括许多非平稳性，以及强化学习实验。作者的实验表明，UPGD保持网络可塑性并重用先前学习的有用特征，是少数几种能有效解决这两个问题的方法之一。

