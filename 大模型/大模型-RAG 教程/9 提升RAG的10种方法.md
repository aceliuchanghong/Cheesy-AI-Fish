# 9. 提升RAG的10种方法

![https://cdn.nlark.com/yuque/0/2023/png/406504/1695255765225-8535c0cf-1ad7-4ee3-989b-2e6fd3969102.png](https://cdn.nlark.com/yuque/0/2023/png/406504/1695255765225-8535c0cf-1ad7-4ee3-989b-2e6fd3969102.png)

LLM是一项了不起的发明，但容易出现一个关键问题就是编造一些东西。RAG（检索增强） 通过为LLM提供回答查询时使用的事实背景，使LLM变得更加实用。

使用 LangChain 或 LlamaIndex 等框架，可以使用大约五行代码就构建一个简单的 RAG 系统，例如文档的聊天机器人。

但是，用这五行代码构建的机器人效果就可能差强人意了。按照教程构建的系统可能仅仅是演示的demo，距离实际生产环境的落地应用之间还是存在一定的差异。

实际实践过程中，提升RAG的效果有许多的方向，这篇文章将常用的思路进行讨论，希望对RAG系统的优化和使用提供一些帮助。

**1. 数据清理**

RAG 将LLM的能力与特定数据联系起来。如果数据质量不高，那么整个系统将会受到影响。例如，使用的数据包含冲突或冗余信息，那么检索的过程将很难找到正确的上下文。当这种情况发生时，LLM执行的生成步骤可能不是最佳的。

假设基于某个产品的帮助文档构建一个聊天机器人，发现它运行不佳。那应该查看的第一件事就是输入系统的数据是否存在明显的不合理，包括文档切分是否合理？文档是否存在矛盾或冲突地方？文档是否过长或过短？文档是否存在多模态数据？如果作为人类无法轻松判断需要查看哪个文档来回答常见查询，那么检索系统也将无法做到这一点。

针对长文档、多文档的情况，常见的方法之一是使用LLM来创建所有文档的摘要。然后，检索步骤首先对这些摘要进行搜索，然后仅针对相关摘要，进一步检索更详细的信息，这种二阶检索的方式有点参考搜索引擎检索思路。

**2. 索引类型**

索引是LlamaIndex和LangChain的核心概念。它是保存检索系统的对象。RAG 的标准方法涉及embedding和相似性搜索。将上下文数据分块，做文本向量化，需要查询时，从上下文中找到向量相似的部分。

这种方法效果很好，但并不是适合所有的场景。例如，查询是包含特定名称的商品，就是基于关键字的搜索。词向量、关键词甚至传统机器学习指标，都是可以参考的。

从领域数据中，如何获取相关信息是决定RAG系统的上限，设计合理的、适配场景的索引值得花费一定的时间和精力。

**3. 分块方法**

将上下文数据分块（chunk）是构建 RAG 系统的核心部分。框架抽象了分块过程，但实际场景下应该考虑块的大小。块大小很重要。一般来说，较小的块通常可以改善检索，但可能会导致生成过程缺乏周围的上下文。有很多方法可以实现分块。这篇文章列出了一些需要考虑的策略。

**4. 提示工程**

常见的一个提示词是：

根据给定的上下文信息回答问题

在实际项目中，提示词是非常脆弱和敏感的，当前的大模型对提示具有非常高的依赖性，这种依赖性与模型的能力成反比，也就是模型的能力越弱，对提示的依赖越强。选择不同的模型、不同的数据，甚至不同的索引，都需要调整提示来得到一个比较优秀的结果。

**5. 元数据过滤。**

改进检索的一个非常有效的策略是将元数据添加到块中，然后使用它来帮助处理结果。日期是要添加的常见元数据标记，因为它允许按时间进行过滤。想象一下，在构建一个允许用户查询其电子邮件历史记录的应用程序。最近的电子邮件可能会更相关。但从词向量的角度来看，我们不知道它们是否与用户的查询最相似。这提出了构建 RAG 时要记住的一般概念：相似≠相关。可以将每封电子邮件的日期附加到其元数据中，然后在检索期间优先考虑最近的上下文。

**6. 使用查询路由**

对内容构建多个分支，将查询内容分门别类，查询经过判断逻辑后执行特定分支，而不是全部内容混为一谈。

拥有多个索引通常很有用。然后，当查询进入时，可以将查询路由到适当的索引。例如，可能有一个处理摘要问题的索引，另一个处理尖锐问题的索引，以及另一个适合日期敏感问题的索引。如果尝试将所有问题建模到一个索引上，可能在最终效果上反而有下降。相反，可以将查询路由到正确的索引。另一个用例是将一些查询定向到基于关键字的索引，如第 2 节中所述。

一旦构建了索引，只需在文本中定义每个索引的用途即可。然后在查询时，LLM将选择适当的选项。LlamaIndex 和 LangChain 都有这方面的工具。

**7.重新排名**

对结果进行重新排序，是解决相似性和相关性之间差异问题的一种解决方案。类似检索系统的精排和粗排逻辑，通过不同的排序方法，进一步缩小范围，获取更加相关的上下文信息。

**8. 多次查询**

思维链在一定程度上能够提升模型的效果，但对于比较复杂或者需要多次判断的任务，将步骤进行人为的拆解为多次执行，效果上比一次执行多个步骤要好一些。每个步骤都是简单的任务，模型能够更加理解输入，且对上下文长度的依赖有所降低。

**9. 微调模型**

基于向量化的相似性是 RAG 的标准检索机制。数据被分块并向量化到索引中。当查询进入时，它也会被嵌入以与

问题是，预训练模型关于嵌入空间中相似内容的概念可能与您的上下文中相似内容不太一致。想象一下正在处理法律文件。希望嵌入更多地基于您的领域特定术语（例如“知识产权”或“违反合同”）对相似性的判断，而不是基于“特此”和“协议”等一般术语。

可以通过微调嵌入模型来解决此问题。这样做可以将检索指标提高 5-10%。但这需要更多的时间和精力，但可以对检索性能产生显著的影响。这个过程比您想象的要容易，因为 LlamaIndex 可以帮助您生成训练集。

**10.重新思考任务**

如果通过上述的步骤，整个RAG系统距离目标还是有一定的差距，那么需要重新对任务进行思考和定义，包括数据是否被正确使用、上述方法是否可以进行组合以进一步提升效果等。

# 结论

使用 RAG 进行构建可能会让人非常折磨，因为它很容易工作，但很难很好地工作。希望上述策略能为你如何弥合能用和可用之间的差距提供一些启发。这些想法中没有一种是永远有效的，而且这个过程就是实验、尝试和错误的过程。在这篇文章中，没有深入探讨如何评估系统的性能。目前，评估更像是一门艺术，而不是一门科学，但重要的是建立某种类型的系统，可以持续检查。这是判断更改是否产生影响的唯一方法。