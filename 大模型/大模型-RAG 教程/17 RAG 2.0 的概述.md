### [提升RAG检索质量的三个高级技巧（查询扩展、交叉编码器重排序和嵌入适配器）](https://mp.weixin.qq.com/s/rjsymQQwgE78fNZ60opE0w)
这篇文章介绍了三种技术，旨在提升RAG（Retrieval-Augmented Generation）检索系统的性能，以提高生成答案的相关性和质量。以下是对这些技术的简要摘要：

1.  **查询扩展（Query expansion）**： 
    - 使用生成的答案进行查询扩展：通过让大型语言模型（LLM）提供一个假设答案，然后将其与原始查询结合，以增强检索到的文档与答案的相似度。
    - 用多个相关问题扩展查询：生成与原始查询相关的多个问题，并将它们与原始查询一起发送给检索系统，以检索更多相关文档。
2.  **交叉编码器重排序（Cross-encoder re-ranking）**： 
    - 利用交叉编码器对检索到的文档进行重排序，该编码器能够比较输入查询与文档的相关性，从而识别出最相关的文档。
3.  **嵌入适配器（Embedding adaptors）**： 
    - 通过训练适配器来调整嵌入查询，以更好地适应特定任务，提高检索结果的相关性。适配器是插入到预训练模型中的小型前馈神经网络，目的是根据文档相关性的反馈来优化嵌入查询。

文章还提供了一些代码示例，展示了如何使用交叉编码器进行文档重排序，以及如何训练嵌入适配器。这些技术可以应用于现有的RAG系统中，以提高检索和生成答案的准确性。

### [RAG 2.0架构详解：构建端到端检索增强生成系统](https://mp.weixin.qq.com/s/ZDlp_oOEF7vQFaLsU_CaDA)
文章详细介绍了RAG（Retrieval-Augmented Generation，检索增强生成）2.0的概念，旨在解决现有RAG系统中存在的问题，如各个子模块之间缺乏协调，以及系统脆弱和缺乏专业化等问题。以下是对文章内容的摘要：

1.  **RAG的概念**： 
    - RAG通过为大型语言模型（LLM）提供额外上下文，帮助生成更具体的回答。
    - LLM在公开数据上训练，智能但无法回答具体问题，因为缺乏上下文。
2.  **RAG的步骤**： 
    - 将文档分割成块。
    - 使用编码器为每个块生成嵌入并存储。
    - 检索最相似的编码块，并将原始文本作为上下文提供给生成器。
3.  **RAG 2.0**： 
    - RAG 2.0通过预训练、微调并对所有组件进行对齐，形成一个整体集成系统。
    - 通过双重反向传播最大化性能，改善了开放域问答、忠实度和新鲜度。
4.  **RAG如何解决智能问题**： 
    - RAG是一种半参数系统，参数部分是LLM，其余部分是非参数的。
    - 通过索引交换提供定制化，减少幻觉，并通过指向来源进行引用。
5.  **检索策略**： 
    - **稀疏检索**：使用TF-IDF和BM25等技术。
    - **密集检索**：使用BERT sentence embedding等技术，基于语义检索信息。
6.  **先进的检索算法**： 
    - **SPLADE**：结合稀疏与密集的查询扩展。
    - **DRAGON**：通过渐进式数据增强推广密集检索器。
    - **混合搜索**：在密集和稀疏搜索之间进行插值。
7.  **训练和优化**： 
    - **RePlug**：通过最小化KL散度损失来优化检索文档。
    - **In-Context RALM**：使用冻结模型RAG和BM25，通过重新排序专门化检索部分。
    - **组合上下文化检索器和生成器**：优化整个流程而不是单独优化LLM或检索器。
8.  **ATLAS**： 
    - ATLAS是一个经过预训练的RAG模型，通过极少的训练示例学习知识密集型任务。
9.  **RAG的类型**： 
    - 冻结模型RAG：作为概念验证。
    - 半冻结模型RAG：应用智能检索器并尝试适应。
    - 完全可训练的RAG：提供最佳性能但非常消耗资源。

文章强调，尽管RAG技术目前还处于初级阶段，但通过扩展语言模型的参数和令牌，以及有效地扩展检索器，可以进一步提升系统的性能。作者Vishal Rajput在文末提供了联系方式，并鼓励读者关注和交流。

### [LLM之RAG实战（二十八）| 探索RAG query重写](https://mp.weixin.qq.com/s/_esiWTwz37k0t0UAwDL4Rg)
