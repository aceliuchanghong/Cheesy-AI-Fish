_发表于2024年3月的这篇论文，为我们展示了一个强大的开源工具，它正在改变我们组合和增强大语言模型的方式。_

_原文：《Arcee’s MergeKit: A Toolkit for Merging Large Language Models》_

![](https://cdn.nlark.com/yuque/0/2024/png/406504/1731651477149-415f0f5d-fba7-45d3-874f-769cc3d2b070.png)

## 引言

	在当前蓬勃发展的AI领域，开源语言模型的数量呈爆炸式增长。通过Hugging Face模型库，我们能接触到越来越多的优秀模型。这些模型通常基于数万亿tokens的语料库训练，其参数规模从1亿到700亿不等。它们可以大致分为两类：一类是像Llama2这样的通用预训练基座模型，另一类则是针对特定领域（如代码生成、医疗诊断等）进行过专门对齐的模型。

	然而，这种繁荣背后隐藏着重大挑战。以广受关注的Mistral-7B为例，仅其训练成本就高达200-300万美元。这个数字令人望而生畏，直接限制了许多研究团队参与顶级模型研发的可能性。此外，当我们需要为不同任务开发专用模型时，每个任务都需要独立的存储和部署环境，这导致资源成本呈倍数增长。

	更为棘手的是"灾难性遗忘"(catastrophic forgetting)问题。当我们试图通过继续微调来增强模型的特定能力时，模型的原有通用能力往往会出现明显退化。这就像一个学生在专注提升某一学科成绩的同时，其他学科的水平可能会下降。这种能力的此消彼长让许多研究者感到困扰：如何才能在保持模型通用能力的同时，又能让它在特定领域展现卓越表现？

	正是在这样的背景下，模型合并技术应运而生，而MergeKit则是这一领域的重要突破。它的核心思想是：既然我们已经拥有了各种在不同领域表现出色的模型，为什么不能像拼图一样，将它们的优势组合起来呢？这个看似简单的想法，实际上开创了一种全新的模型开发范式。

## 技术背景与相关工作

	模型合并的理论基础源自多项开创性研究。首先是Garipov等人(2018)提出的模式连接性理论，该理论证明了神经网络优化过程中存在低损失连接路径，这为不同模型间的权重融合提供了理论可能性。随后，Entezari等人(2021)提出的线性模式连接性(LMC)理论，进一步证明了对于具有相同初始化的微调模型，简单的线性插值就能产生有效的合并结果。

## 模型合并方法详解

	MergeKit支持多种模型合并方法，这些方法根据模型的初始状态和架构特征可以分为三大类。让我们深入了解每种方法的特点和应用场景。

### 1. 相同架构和初始化的模型合并

	这是最基础也是最容易理解的合并场景。想象我们有两个都是基于Llama2-7B微调得到的模型，一个在医疗数据上训练，另一个在代码数据上训练。由于它们具有相同的"血统"，合并它们的过程相对直接。

	最简单的方法是线性权重平均，这源自Model Soups的思想。但实践表明，更复杂的方法往往能带来更好的效果。例如SLERP（球面线性插值）技术，通过在球面上而不是直线上进行插值，能更好地保持模型的几何特性。

	一个典型的真实案例是医疗领域的模型合并实验。研究者将专门的医疗模型Meditron-7B与通用的Llama2-7B Chat进行合并，实验结果令人振奋：

|   |   |   |   |
|---|---|---|---|
|模型/方法|USMLE医疗考试|MedMCQA|通用理解能力|
|原始医疗模型|38.40|24.07|较弱|
|通用模型|35.90|35.45|较强|
|合并后模型|39.20|36.91|保持良好|

	这个结果表明，合并后的模型不仅保持了原有模型的优势，甚至在某些指标上实现了超越。

这种情况最简单，主要包含以下方法：

1. **线性权重平均 (Linear Weight Averaging)**

- 原理：直接对模型参数进行线性插值
- 举例：假设有两个医疗领域的模型A和B

```
merged_weights = α * model_A.weights + (1-α) * model_B.weights 
# α是混合系数，一般取0.5
```

2. **Task Arithmetic (任务向量算术)**

- 原理：将模型间的差异视为任务向量，可以进行加减运算
- 举例：

```
医疗问答模型 = 基础模型 + 医疗知识向量
综合模型 = 基础模型 + 医疗向量 + 通用问答向量
```

3. **TIES/DARE 稀疏合并**

- 特点：通过稀疏化保留各模型的关键能力
- 实际应用：

```
模型A(医疗专家) + 模型B(通用对话) = 
保留模型A的医疗核心参数 + 模型B的对话能力
```

### 2. 相同架构但不同初始化的模型合并

	这种情况就复杂得多。即使两个模型的架构完全相同，如果它们的初始化不同，直接合并往往会导致灾难性的性能下降。这就像两个相同的城市，但街道命名完全不同，需要先建立正确的对应关系才能进行导航。

	Git-Rebasin技术提供了一个优雅的解决方案。它首先分析神经网络中的置换对称性，通过复杂的数学变换，将两个模型的权重空间对齐。这个过程可以类比为将两种不同语言写成的相同故事翻译成一种统一的语言，使它们可以进行有效的比较和融合。

	另一个值得关注的方法是ZipIt，它允许在特征层面进行选择性合并。这就像是在两个模型中分别挑选最优秀的"器官"进行移植，最终组合成一个更强大的整体。这种方法特别适合那些在不同任务上分别训练出色的模型。

这种情况较复杂，需要考虑参数对齐：

1. **Git-Rebasin方法**

	- 核心：通过置换对称性对齐参数
	- 步骤：
		- 找到功能等价的权重配置
		- 对齐神经元排列
		- 合并对齐后的参数

2. **OT Fusion (最优传输融合)**  

|   |   |   |
|---|---|---|
|方法|优势|劣势|
|Git-Rebasin|理论基础扎实|计算开销大|
|OT Fusion|自动寻找最优映射|需要额外训练数据|

3. **ZipIt合并法**

	- 创新点：支持部分层的合并
	- 应用场景：

```
场景1：合并底层特征提取能力
场景2：保留各自的任务特定层
```

### 3. 不同架构模型的融合

	这是技术难度最高的场景，也是最具创新性的研究方向。CALM（Composition to Augment Language Models）和FUSELLM提供了两种不同的解决思路：

	CALM通过设计特殊的跨注意力机制，让不同架构的模型能够进行特征层面的交互。这就像搭建了一座桥梁，让不同"语言"的模型可以进行有效沟通。

	FUSELLM则着眼于概率分布层面的融合，通过对齐不同模型的输出分布，实现能力的互补。这种方法虽然需要额外的训练过程，但能够在保持各模型特色的同时实现有效的能力整合。

这是最具挑战性的场景：

1. **CALM (Composition to Augment Language Models)**

- 原理：使用注意力机制融合不同模型的表示
- 示例架构：

```
Model A (7B参数) -----> 
                       Cross-Attention ---> 融合输出
Model B (13B参数) ---->
```

2. **FUSELLM方法**

	- 重点：对齐概率分布而非直接合并参数
	- 优势：

		- 可处理不同大小的模型
		- 保留各模型的独特优势
		- 不需要架构完全一致

### 关键思考与建议

1. 模型选择考虑因素：

	- 任务相关性
	- 计算资源限制
	- 期望的融合效果

2. 实践建议：

```
如果模型初始化相同 -> 优先考虑线性平均
如果只是初始化不同 -> 考虑Git-Rebasin
如果架构不同 -> 使用CALM或FUSELLM
```

3. 效果评估：

	- 在医疗任务上的实验表明，合并后的模型可以同时保持专业能力和通用能力
	- 例如：MediconLlama系列模型在USMLE等医疗测试和通用任务上都表现出色

---

## MergeKit的工程实现创新

	MergeKit的成功不仅在于其理论基础的扎实，更在于其精心设计的工程实现。作为一个面向实际应用的开源工具，它在多个层面都展现出了独特的创新。

### 用户友好的配置系统

	MergeKit采用YAML配置文件作为主要接口，这一设计大大降低了使用门槛。不论是初学者还是专业研究人员，都能通过简单的配置文件来定义复杂的合并操作。一个典型的合并配置示例如下：

```
base_model： /path/to/base
merge_method： slerp
models：
  - source： /path/to/model_a
    parameters：
      weight： 0.7
  - source： /path/to/model_b
    parameters：
      weight： 0.3
```

	这种配置方式不仅直观易懂，更重要的是它使得合并操作变得可复现、可分享。研究者可以轻松地分享他们的合并"配方"，促进社区协作和知识传播。

### 高效的内存管理

	大语言模型动辄数十甚至上百GB的模型权重，如何在有限的硬件资源下高效处理这些数据是一个巨大的挑战。MergeKit通过创新的计算图调度系统解决了这个问题。

	系统将合并操作表示为有向无环图（DAG），每个操作都是图中的一个节点。通过智能的调度算法，系统确保在任何时刻内存中只保留必要的数据。这就像是一个精明的资源管理者，精确地控制着每一份计算资源的使用。

### 模块化的架构设计

MergeKit的核心功能分布在几个关键模块中：

- graph.py 负责整体的调度和执行流程管理，它是系统的"指挥中心"
- merge_methods/base.py 定义了标准的合并方法接口，为新方法的添加提供了清晰的框架
- architecture.py 处理各种模型架构的兼容性问题，确保合并操作的正确执行

这种模块化设计不仅使得代码结构清晰，也让系统的扩展变得异常简单。任何研究者都可以基于这个框架实现新的合并方法，而不需要了解整个系统的复杂细节。

### 跨平台兼容性

MergeKit特别注重与现有的机器学习生态系统的兼容性，尤其是与Hugging Face Transformers库的无缝集成。这使得用户可以直接使用来自Hugging Face模型库的各种模型，大大扩展了工具的应用范围。

此外，系统还支持在不同的硬件配置下运行，从高性能计算集群到普通的个人电脑都能使用。这种广泛的兼容性使得MergeKit能够服务于更广泛的用户群体。

## 实际应用效果与影响力

MergeKit在实际应用中展现出了令人瞩目的成果。通过分析其在开源社区的影响和具体应用案例，我们可以更好地理解这个工具的实际价值。

### 在开源社区的突出表现

在Open LLM Leaderboard上，使用MergeKit合并的模型展现出了惊人的竞争力。统计数据显示：

- 在排行榜前50名中，合并模型占比达到20%
- 在前100名中，这一比例更是上升到34%
- 当前排名最高的3B和7B模型，以及排名第三的13B模型都是使用MergeKit合并的产物

这些数据充分证明了模型合并技术的实用价值，特别是考虑到这些合并模型往往能够在更小的参数规模下实现与大模型相当的性能。

### 医疗领域的成功案例

BioMistral项目是MergeKit应用的一个典型案例。研究团队将专门的医疗领域模型与Mistral的聊天模型进行合并，创造了一个在医疗领域表现卓越，同时保留了强大通用能力的新模型。实验数据显示：

- 在USMLE（美国医师执照考试）上的表现超过了单个医疗模型
- 在通用对话能力上保持了原有的水平
- 在医疗知识理解和诊断建议上展现出了显著的提升

这个成功案例告诉我们，通过精心设计的合并策略，我们确实可以实现"1+1>2"的效果。

### OpenPipe的实践经验

另一个值得关注的案例是OpenPipe的Mistral 7B Fine-Tune Optimized模型。这个项目证明了合并技术不仅可以用于提升模型性能，还可以作为创建更好的微调基础模型的有效手段。他们通过合并多个经过不同任务微调的模型，创造了一个更适合进一步微调的基础模型。

## 未来发展与挑战

虽然MergeKit已经取得了显著的成功，但团队并没有停止前进的脚步。他们正在积极推进多个方向的改进和扩展：

### 技术创新方向

目前，团队正在努力集成更多前沿的合并技术：

- ZipIt：用于特征层面的选择性合并
- OT Fusion：基于最优传输理论的模型融合
- Git Rebasin：改进权重对齐算法

同时，他们也在持续优化系统的核心功能：

- 改进内存管理策略
- 提升计算效率
- 扩展对更多模型架构的支持

### 社区建设

作为一个开源项目，MergeKit特别注重与社区的互动和协作：

- 提供详细的文档和教程
- 建立标准化的贡献流程
- 鼓励社区成员分享经验和创新

### 伦理考量

在推动技术发展的同时，团队也深知AI技术发展必须与伦理责任相结合。他们特别关注：

- 合并模型中可能存在的偏见问题
- 确保数据使用的合规性
- 维护信息的隐私和安全
- 推动负责任的AI技术发展

## 经验教训与最佳实践

通过深入研究MergeKit的实现和应用案例，我们可以总结出一些宝贵的经验和最佳实践建议。

### 选择合适的合并策略

在实际应用中，选择合适的合并策略至关重要：

- 对于来自同一基座模型的微调变体，SLERP方法通常能带来最好的效果。以医疗领域的实验为例，SLERP合并方法在USMLE、MedMCQA等专业评测上都取得了最好的成绩，同时也很好地保持了模型的通用能力。
- 对于不同初始化的模型，应该首先考虑使用Git-Rebasin等权重对齐技术。这个过程虽然计算开销较大，但对最终效果的提升至关重要。
- 当处理特定领域的模型合并时，可以考虑使用TIES（Trim， Elect Sign & Merge）等方法，它能更好地保持模型在特定领域的专业能力。

### 资源优化建议

在实际部署时，需要特别注意资源使用的优化：

- 使用MergeKit的计算图调度功能，合理安排合并操作的顺序
- 对于大型模型，建议使用分块处理策略
- 在有条件的情况下，利用GPU加速能显著提升处理效率

## 工具使用指南

对于想要开始使用MergeKit的开发者，这里提供一些实用建议：

1. 首先通过简单的配置文件开始尝试：

```
models：
  - source： "model_a_path"
    parameters：
      weight： 0.5
  - source： "model_b_path"
    parameters：
      weight： 0.5
merge_method： "slerp"
dtype： "bfloat16"
```

2. 在进行复杂合并之前，建议先使用小规模模型进行实验和验证
3. 密切关注内存使用情况，适时调整批处理大小

## 结论与展望

MergeKit的出现标志着大语言模型发展进入了一个新阶段。它不仅提供了一种高效的模型能力复用方案，更开创了一种全新的模型开发范式。通过合理的合并策略，我们可以在不增加计算成本的情况下，显著提升模型性能和通用性。

### 对AI领域的启示

1. 模型合并技术展示了一种更经济、更环保的AI发展路径。相比训练新模型，合并现有模型可以用更少的资源实现相似或更好的效果。
2. 开源协作的力量不容忽视。MergeKit的成功证明，通过社区协作，我们可以充分利用现有的模型资源，创造出更强大的AI系统。
3. 技术创新不仅体现在理论突破，也体现在工程实践。MergeKit优秀的工程设计为整个领域树立了标杆。

### 未来展望

展望未来，模型合并技术还有很大的发展空间：

- 探索更多的合并策略，特别是针对不同架构模型的融合方法
- 进一步优化合并过程的效率和资源利用
- 扩展到更多的应用场景，如多模态模型的合并

对于研究人员和开发者而言，MergeKit提供了一个绝佳的起点，让我们能够站在巨人的肩膀上，继续推动AI技术的发展。

个人建议感兴趣的读者可以：

1. 访问MergeKit的GitHub仓库：[https：//github.com/arcee-ai/mergekit](https://github.com/arcee-ai/mergekit)
2. 阅读项目文档和示例
3. 从简单的模型合并实验开始，逐步探索更复杂的应用场景